{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import functional\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "MAX_LENGTH = 5 #temp\n",
    "\n",
    "MAX_VOCAB_SIZE = 1000\n",
    "\n",
    "PAD_IDX = 0 \n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_IDX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.range(0, max_len - 1).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def masked_cross_entropy(logits, target, length):\n",
    "    length = Variable(torch.LongTensor(length))\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = functional.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Remove punctuation\n",
    "def removePunctuation(s):\n",
    "\n",
    "    to_remove = ('&lt;', '&gt;', '&amp;', '&apos;', '&quot;')\n",
    "    table = str.maketrans(dict.fromkeys('.!?:,'))\n",
    "    s = s.translate(table)\n",
    "    for i in to_remove:\n",
    "        s=s.replace(i,'')   \n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "\n",
    "from typing import List\n",
    "from collections import Counter, namedtuple\n",
    "from itertools import zip_longest\n",
    "\n",
    "def tokenize_13a(line):\n",
    "    \"\"\"\n",
    "    Tokenizes an input line using a relatively minimal tokenization that is however equivalent to mteval-v13a, used by WMT.\n",
    "    :param line: a segment to tokenize\n",
    "    :return: the tokenized line\n",
    "    \"\"\"\n",
    "\n",
    "    norm = line\n",
    "\n",
    "    # language-independent part:\n",
    "    norm = norm.replace('<skipped>', '')\n",
    "    norm = norm.replace('-\\n', '')\n",
    "    norm = norm.replace('\\n', ' ')\n",
    "    norm = norm.replace('&quot;', '\"')\n",
    "    norm = norm.replace('&amp;', '&')\n",
    "    norm = norm.replace('&lt;', '<')\n",
    "    norm = norm.replace('&gt;', '>')\n",
    "\n",
    "    # language-dependent part (assuming Western languages):\n",
    "    norm = \" {} \".format(norm)\n",
    "    norm = re.sub(r'([\\{-\\~\\[-\\` -\\&\\(-\\+\\:-\\@\\/])', ' \\\\1 ', norm)\n",
    "    norm = re.sub(r'([^0-9])([\\.,])', '\\\\1 \\\\2 ', norm)  # tokenize period and comma unless preceded by a digit\n",
    "    norm = re.sub(r'([\\.,])([^0-9])', ' \\\\1 \\\\2', norm)  # tokenize period and comma unless followed by a digit\n",
    "    norm = re.sub(r'([0-9])(-)', '\\\\1 \\\\2 ', norm)  # tokenize dash when preceded by a digit\n",
    "    norm = re.sub(r'\\s+', ' ', norm)  # one space only between words\n",
    "    norm = re.sub(r'^\\s+', '', norm)  # no leading space\n",
    "    norm = re.sub(r'\\s+$', '', norm)  # no trailing space\n",
    "\n",
    "    return norm\n",
    "\n",
    "def corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n",
    "                 use_effective_order=False):\n",
    "    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
    "    :param sys_stream: The system stream (a sequence of segments)\n",
    "    :param ref_streams: A list of one or more reference streams (each a sequence of segments)\n",
    "    :param smooth: The smoothing method to use\n",
    "    :param smooth_floor: For 'floor' smoothing, the floor to use\n",
    "    :param force: Ignore data that looks already tokenized\n",
    "    :param lowercase: Lowercase the data\n",
    "    :param tokenize: The tokenizer to use\n",
    "    :return: a BLEU object containing everything you'd want\n",
    "    \"\"\"\n",
    "\n",
    "    # Add some robustness to the input arguments\n",
    "    if isinstance(sys_stream, str):\n",
    "        sys_stream = [sys_stream]\n",
    "    if isinstance(ref_streams, str):\n",
    "        ref_streams = [[ref_streams]]\n",
    "\n",
    "    sys_len = 0\n",
    "    ref_len = 0\n",
    "\n",
    "    correct = [0 for n in range(NGRAM_ORDER)]\n",
    "    total = [0 for n in range(NGRAM_ORDER)]\n",
    "    \n",
    "\n",
    "    # look for already-tokenized sentences\n",
    "    tokenized_count = 0\n",
    "\n",
    "    fhs = [sys_stream] + ref_streams\n",
    "    for lines in zip_longest(*fhs):\n",
    "        if None in lines:\n",
    "            raise EOFError(\"Source and reference streams have different lengths!\")\n",
    "\n",
    "        if lowercase:\n",
    "            lines = [x.lower() for x in lines]\n",
    "            \n",
    "        tokenize= 'tokenize_13a'    \n",
    "\n",
    "        if not (force or tokenize == 'none') and lines[0].rstrip().endswith(' .'):\n",
    "            tokenized_count += 1\n",
    "\n",
    "            if tokenized_count == 100:\n",
    "                logging.warning('That\\'s 100 lines that end in a tokenized period (\\'.\\')')\n",
    "                logging.warning('It looks like you forgot to detokenize your test data, which may hurt your score.')\n",
    "                logging.warning('If you insist your data is detokenized, or don\\'t care, you can suppress this message with \\'--force\\'.')\n",
    "\n",
    "        output, *refs = [tokenize_13a(x.rstrip()) for x in lines]\n",
    "        \n",
    "\n",
    "        ref_ngrams, closest_diff, closest_len = ref_stats(output, refs)\n",
    "        \n",
    "\n",
    "        sys_len += len(output.split())\n",
    "        ref_len += closest_len\n",
    "\n",
    "        sys_ngrams = extract_ngrams(output)\n",
    "        for ngram in sys_ngrams.keys():\n",
    "            n = len(ngram.split())\n",
    "            correct[n-1] += min(sys_ngrams[ngram], ref_ngrams.get(ngram, 0))\n",
    "            total[n-1] += sys_ngrams[ngram]\n",
    "            \n",
    "\n",
    "    return compute_bleu(correct, total, sys_len, ref_len, smooth, smooth_floor, use_effective_order)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_ORDER = 4\n",
    "  \n",
    "def compute_bleu(correct: List[int], total: List[int], sys_len: int, ref_len: int, smooth = 'none', smooth_floor = 0.01,\n",
    "                 use_effective_order = False):\n",
    "    \"\"\"Computes BLEU score from its sufficient statistics. Adds smoothing.\n",
    "    :param correct: List of counts of correct ngrams, 1 <= n <= NGRAM_ORDER\n",
    "    :param total: List of counts of total ngrams, 1 <= n <= NGRAM_ORDER\n",
    "    :param sys_len: The cumulative system length\n",
    "    :param ref_len: The cumulative reference length\n",
    "    :param smooth: The smoothing method to use\n",
    "    :param smooth_floor: The smoothing value added, if smooth method 'floor' is used\n",
    "    :param use_effective_order: Use effective order.\n",
    "    :return: A BLEU object with the score (100-based) and other statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    precisions = [0 for x in range(NGRAM_ORDER)]\n",
    "\n",
    "    smooth_mteval = 1.\n",
    "    effective_order = NGRAM_ORDER\n",
    "    for n in range(NGRAM_ORDER):\n",
    "        if total[n] == 0:\n",
    "            break\n",
    "\n",
    "        if use_effective_order:\n",
    "            effective_order = n + 1\n",
    "\n",
    "        if correct[n] == 0:\n",
    "            if smooth == 'exp':\n",
    "                smooth_mteval *= 2\n",
    "                precisions[n] = 100. / (smooth_mteval * total[n])\n",
    "            elif smooth == 'floor':\n",
    "                precisions[n] = 100. * smooth_floor / total[n]\n",
    "        else:\n",
    "            precisions[n] = 100. * correct[n] / total[n]\n",
    "\n",
    "    # If the system guesses no i-grams, 1 <= i <= NGRAM_ORDER, the BLEU score is 0 (technically undefined).\n",
    "    # This is a problem for sentence-level BLEU or a corpus of short sentences, where systems will get no credit\n",
    "    # if sentence lengths fall under the NGRAM_ORDER threshold. This fix scales NGRAM_ORDER to the observed\n",
    "    # maximum order. It is only available through the API and off by default\n",
    "\n",
    "    brevity_penalty = 1.0\n",
    "    if sys_len < ref_len:\n",
    "        brevity_penalty = math.exp(1 - ref_len / sys_len) if sys_len > 0 else 0.0\n",
    "        \n",
    "\n",
    "    bleu = brevity_penalty * math.exp(sum(map(my_log, precisions[:effective_order])) / effective_order)\n",
    "\n",
    "    return bleu \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def ref_stats(output, refs):\n",
    "    ngrams = Counter()\n",
    "    closest_diff = None\n",
    "    closest_len = None\n",
    "    for ref in refs:\n",
    "        tokens = ref.split()\n",
    "        reflen = len(tokens)\n",
    "        diff = abs(len(output.split()) - reflen)\n",
    "        if closest_diff is None or diff < closest_diff:\n",
    "            closest_diff = diff\n",
    "            closest_len = reflen\n",
    "        elif diff == closest_diff:\n",
    "            if reflen < closest_len:\n",
    "                closest_len = reflen\n",
    "\n",
    "        ngrams_ref = extract_ngrams(ref)\n",
    "        for ngram in ngrams_ref.keys():\n",
    "            ngrams[ngram] = max(ngrams[ngram], ngrams_ref[ngram])\n",
    "\n",
    "    return ngrams, closest_diff, closest_len\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def extract_ngrams(line, min_order=1, max_order=NGRAM_ORDER) -> Counter:\n",
    "    \"\"\"Extracts all the ngrams (1 <= n <= NGRAM_ORDER) from a sequence of tokens.\n",
    "    :param line: a segment containing a sequence of words\n",
    "    :param max_order: collect n-grams from 1<=n<=max\n",
    "    :return: a dictionary containing ngrams and counts\n",
    "    \"\"\"\n",
    "\n",
    "    ngrams = Counter()\n",
    "    tokens = line.split()\n",
    "    for n in range(min_order, max_order + 1):\n",
    "        for i in range(0, len(tokens) - n + 1):\n",
    "            ngram = ' '.join(tokens[i: i + n])\n",
    "            ngrams[ngram] += 1\n",
    "\n",
    "    return ngrams  \n",
    "\n",
    "def my_log(num):\n",
    "    \"\"\"\n",
    "    Floors the log function\n",
    "    :param num: the number\n",
    "    :return: log(num) floored to a very low number\n",
    "    \"\"\"\n",
    "\n",
    "    if num == 0.0:\n",
    "        return -9999999999\n",
    "    return math.log(num)\n",
    "  \n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2index = {\"PAD\" : 0, \"<SOS>\" : 1, \"EOS\" : 2, \"UNK\" : 3}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"<SOS>\", 2: \"EOS\", 3: \"UNK\"}\n",
    "        self.n_words = 4  # Count SOS and EOS and Pad\n",
    "        self.all_words = []\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        'Add all words from all sentences'\n",
    "        for word in sentence.split(' '):\n",
    "            if word.strip(): #if not empty space\n",
    "                self.all_words.append(word)\n",
    "                \n",
    "                \n",
    "    def build_vocab(self, vocab_size=MAX_VOCAB_SIZE):\n",
    "        'Build vocabulary of vocab_size most common words'\n",
    "        \n",
    "        token_counter = Counter(self.all_words)\n",
    "        vocab, count = zip(*token_counter.most_common(vocab_size)) #* unzips the tuples\n",
    "        for word in vocab:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def remove_blanks(pair):\n",
    "    '''Remove empty lines'''\n",
    "    if len(pair[0]) == 0 and len(pair[1]) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def set_max_length(pair, max_length=MAX_LENGTH):\n",
    "    if len(pair[0].split(' ')) > max_length or len(pair[1].split(' '))>max_length:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def readLangs(filename1, filename2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    with open(filename1, encoding='utf-8') as f:\n",
    "        lines1 = f.read().strip().split('\\n')\n",
    "        \n",
    "    with open(filename2, encoding='utf-8') as f:\n",
    "        lines2 = f.read().strip().split('\\n')   \n",
    "        \n",
    "    # Remove punctuation\n",
    "    lines1 = [removePunctuation(l) for l in lines1]\n",
    "    lines2 = [removePunctuation(l) for l in lines2]\n",
    "              \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse: #change from english->french to french->english for example\n",
    "        pairs =list(zip(lines2, lines1))\n",
    "        input_lang = Lang(filename2[-2:]) #take last two letters\n",
    "        output_lang = Lang(filename1[-2:])\n",
    "    else:\n",
    "        pairs =list(zip(lines1, lines2))\n",
    "        input_lang = Lang(filename1[-2:])\n",
    "        output_lang = Lang(filename2[-2:])\n",
    "            \n",
    "        \n",
    "\n",
    "    pairs = list(filter(remove_blanks, pairs))  \n",
    "    pairs = list(filter(set_max_length, pairs))\n",
    "\n",
    "    return input_lang, output_lang, pairs \n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, num_sent=None, reverse=False):\n",
    "    \n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    pairs = pairs[:num_sent]\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    input_lang.build_vocab()\n",
    "    output_lang.build_vocab()\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "class VocabDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_tuple, word2id_lang1, word2id_lang2):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list1, self.data_list2 = zip(*data_tuple)\n",
    "        assert (len(self.data_list1) == len(self.data_list2))\n",
    "        self.word2id1 = word2id_lang1\n",
    "        self.word2id2 = word2id_lang2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list1)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        input_sentence = [self.word2id1[c] if c in self.word2id1.keys() \n",
    "                         else UNK_IDX for c in self.data_list1[key].split()][:MAX_LENGTH-1]\n",
    "        input_sentence.append(EOS_token)\n",
    "                                                                   \n",
    "        output_sentence = [self.word2id2[c] if c in self.word2id2.keys() \n",
    "                          else UNK_IDX for c in self.data_list2[key].split()][:MAX_LENGTH-1]\n",
    "        output_sentence.append(EOS_token)\n",
    "\n",
    "        return [input_sentence, output_sentence, len(input_sentence), len(output_sentence)]\n",
    "\n",
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    length_list1 = []\n",
    "    length_list2 = []\n",
    "     \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        x1 = datum[0]\n",
    "        x2 = datum[1]\n",
    "        len1 = datum[2]\n",
    "        len2 = datum[3]\n",
    "        \n",
    "        length_list1.append(len1)\n",
    "        length_list2.append(len2)\n",
    "        #Pad first sentences\n",
    "        padded_vec1 = np.pad(np.array(x1),\n",
    "                                pad_width=((0,MAX_LENGTH-len1)),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list1.append(padded_vec1)\n",
    "        \n",
    "        #Pad second sentences\n",
    "        padded_vec2 = np.pad(np.array(x2),\n",
    "                        pad_width=((0,MAX_LENGTH-len2)),\n",
    "                        mode=\"constant\", constant_values=0)\n",
    "        data_list2.append(padded_vec2)\n",
    "        \n",
    "    data_list1 = np.array(data_list1)\n",
    "    data_list2 = np.array(data_list2)\n",
    "    length_list1 = np.array(length_list1)\n",
    "    lenth_list2 = np.array(length_list2)\n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list1)), \n",
    "            torch.from_numpy(np.array(data_list2)),\n",
    "            torch.LongTensor(length_list1), \n",
    "            torch.LongTensor(length_list2)]\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, dropout=0):\n",
    "        '''Bidirectional RNN'''\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Embedding input: max_length x batch_size\n",
    "        # Embedding output: max_length x batch_size x hidden size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=0) #vocab size x hidden size\n",
    "        \n",
    "        # Input: (max_length x batch_size x hidden_size)\n",
    "        # Output: hidden - 2 x batch_size x hidden_size\n",
    "        # Output: outputs max_length x batch_size x hidden_size*2\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden\n",
    "    \n",
    "    \n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_weights = Variable(torch.zeros(this_batch_size, max_len)).to(device) # B x S\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_weights[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_weights, dim=1).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "            \n",
    "        weights = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "        weights = self.v.mm(weights.transpose(0,1))\n",
    "        return weights\n",
    "    \n",
    "\n",
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = MAX_LENGTH\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note that we will only be running forward for a single decoder time step, but will use all encoder outputs\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).unsqueeze(0) #so that we have 1 x batch x hidden\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Implement attention\n",
    "        attn_weights = self.attn(last_hidden, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)).transpose(0,1) # 1 x batch x hidden\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights \n",
    "        return output, hidden, attn_weights\n",
    "        \n",
    "    \n",
    "def train(inputs, input_lengths, targets, target_lengths, \n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH,\n",
    "         teacher_forcing_ratio=0.5, clip = 5):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 #\n",
    "    batch_size = inputs.size()[1]\n",
    "    #print('input size', inputs.size())\n",
    "    #print('batch size', batch_size)\n",
    "    max_targ_len = max_length\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(inputs, input_lengths, None)\n",
    "\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([SOS_token] * batch_size).to(device)\n",
    "    decoder_hidden = encoder_hidden[:1] # Use last (forward) hidden state from encoder\n",
    "    \n",
    "    #print('time 1 size', decoder_input.size())\n",
    "    #print('time 1 hidden size', decoder_hidden.size())\n",
    "    \n",
    "    #randomly use teacher forcing or not\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Run through decoder one time step at a time using TEACHER FORCING=1.0\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_targ_len, batch_size, output_lang.n_words))\n",
    "    \n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_targ_len):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "            decoder_input = targets[t]\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_targ_len):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "\n",
    "    loss = masked_cross_entropy(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    targets.transpose(0, 1).contiguous(),\n",
    "    target_lengths)\n",
    "        \n",
    "    loss.backward()\n",
    "        \n",
    "    # Clip gradient norms\n",
    "    clip = clip\n",
    "    ec = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    \n",
    "    \n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def trainIters(loader, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01,\n",
    "              teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    start = time.time()\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    plot_losses = []\n",
    "\n",
    "    counter = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while epoch < n_iters:\n",
    "        epoch += 1\n",
    "\n",
    "        # Get training data for this cycle\n",
    "        for i, (source, target, lengths1, lengths2) in enumerate(loader):\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            # Run the train function\n",
    "            loss = train(\n",
    "                source.long().transpose(0,1), lengths1, target.long().transpose(0,1), lengths2,\n",
    "                encoder, decoder,\n",
    "                encoder_optimizer, decoder_optimizer, criterion, teacher_forcing_ratio=teacher_forcing_ratio\n",
    "            )\n",
    "\n",
    "            # Keep track of loss\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "\n",
    "            if counter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_iters), epoch, \n",
    "                                                       epoch / n_iters * 100, print_loss_avg)\n",
    "                print(print_summary)\n",
    "\n",
    "\n",
    "            if counter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, input_lengths, translated, search='greedy', max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Function that generate translation.\n",
    "    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n",
    "    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n",
    "    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n",
    "    And collect the attention for each output words.\n",
    "    @param encoder: the encoder network\n",
    "    @param decoder: the decoder network\n",
    "    @param sentence: string, a sentence in source language to be translated\n",
    "    @param max_length: the max # of words that the decoder can return\n",
    "    @output decoded_words: a list of words in target language\n",
    "    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence.transpose(0,1)\n",
    "        input_length = sentence.size()[0]\n",
    "        \n",
    "        # encode the source lanugage\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor, input_lengths, None)\n",
    "\n",
    "        decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden[:1] # Use last (forward) hidden state from encoder \n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output)\n",
    "            \n",
    "            # hint: print out decoder_output and decoder_attention\n",
    "            # TODO: add your code here to populate decoded_words and decoder_attentions\n",
    "            # TODO: do this in 2 ways discussed in class: greedy & beam_search\n",
    "            \n",
    "            # GREEDY\n",
    "            topv, topi = decoder_output.data.topk(1) \n",
    "\n",
    "            if topi.item() == EOS_token:\n",
    "                #decoded_words.append('<EOS>')\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                if topi.item() not in [SOS_token, EOS_token, UNK_IDX, PAD_IDX]:\n",
    "                    decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            decoder_input = topi[0].detach()\n",
    "        \n",
    "        translation = []\n",
    "        for i in translated: #expected translation\n",
    "            if i.item() not in [SOS_token, EOS_token, UNK_IDX, PAD_IDX]:\n",
    "                translation.append(output_lang.index2word[i.item()])\n",
    "\n",
    "        return decoded_words, translation\n",
    "    \n",
    "    \n",
    "def evaluate_batch(loader, encoder, decoder):\n",
    "    \n",
    "    decoded_sentences = []\n",
    "    actual_sentences = []\n",
    "    \n",
    "    for i, (source, target, lengths1, lengths2) in enumerate(loader):\n",
    "        #iterate over batch\n",
    "        \n",
    "        for n in range(len(source)):\n",
    "            # Go sentence by sentence\n",
    "            \n",
    "            decoded, actual = evaluate(encoder, decoder, source[n].unsqueeze(0), lengths1[n], target[n])\n",
    "            decoded_sentences.append(decoded)\n",
    "            actual_sentences.append(actual)\n",
    "            \n",
    "    return decoded_sentences, actual_sentences\n",
    "\n",
    "\n",
    "def evaluate_bleu(translation_list, reference_list):\n",
    "     \n",
    "    translations = ' '.join(r for v in translation_list for r in v)\n",
    "    references = ' '.join(r for v in reference_list for r in v)\n",
    "    \n",
    "    return corpus_bleu(translations, references)\n",
    "\n",
    "#Plot results\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))    \n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    \"\"\"\n",
    "    Function that takes in attention and visualize the attention.\n",
    "    @param - input_sentence: string the represent a list of words from source language\n",
    "    @param - output_words: the gold translation in target language\n",
    "    @param - attentions: a numpy array\n",
    "    \"\"\"\n",
    "    # Set up figure with colorbar    \n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # TODO: Add your code here to visualize the attention\n",
    "    # look at documentation for imshow https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.matshow.html\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder, decoder, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_loc = 'iwslt-vi-en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 100 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 233\n",
      "en 216\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(en_loc+'/train.tok.vi', en_loc+'/train.tok.en', num_sent=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 61 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 130\n",
      "en 114\n"
     ]
    }
   ],
   "source": [
    "input_lang_v, output_lang_v, pairs_v = prepareData(en_loc+'/dev.tok.vi', en_loc+'/dev.tok.en', num_sent=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preetgandhi95/miniconda3/envs/nlpclass/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/preetgandhi95/miniconda3/envs/nlpclass/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 10s (- 27m 40s) (13 0%) 5.2526\n",
      "0m 20s (- 27m 23s) (25 1%) 4.7779\n",
      "0m 30s (- 26m 38s) (38 1%) 4.5291\n",
      "0m 41s (- 27m 11s) (50 2%) 4.3887\n",
      "0m 54s (- 27m 49s) (63 3%) 4.1977\n",
      "1m 6s (- 28m 21s) (75 3%) 4.0508\n",
      "1m 22s (- 29m 52s) (88 4%) 3.9402\n",
      "1m 34s (- 29m 48s) (100 5%) 3.8621\n",
      "1m 45s (- 29m 21s) (113 5%) 3.7717\n",
      "1m 56s (- 29m 14s) (125 6%) 3.7612\n",
      "2m 8s (- 28m 50s) (138 6%) 3.6902\n",
      "2m 18s (- 28m 23s) (150 7%) 3.6636\n",
      "2m 28s (- 27m 49s) (163 8%) 3.5899\n",
      "2m 38s (- 27m 33s) (175 8%) 3.5827\n",
      "2m 48s (- 27m 6s) (188 9%) 3.5677\n",
      "2m 58s (- 26m 48s) (200 10%) 3.4948\n",
      "3m 8s (- 26m 22s) (213 10%) 3.4585\n",
      "3m 18s (- 26m 4s) (225 11%) 3.4538\n",
      "3m 29s (- 25m 49s) (238 11%) 3.3749\n",
      "3m 42s (- 25m 55s) (250 12%) 3.3800\n",
      "3m 54s (- 25m 51s) (263 13%) 3.3298\n",
      "4m 6s (- 25m 46s) (275 13%) 3.3356\n",
      "4m 17s (- 25m 28s) (288 14%) 3.2524\n",
      "4m 28s (- 25m 23s) (300 15%) 3.1800\n",
      "4m 39s (- 25m 8s) (313 15%) 3.2200\n",
      "4m 51s (- 25m 0s) (325 16%) 3.1563\n",
      "5m 2s (- 24m 47s) (338 16%) 3.0806\n",
      "5m 13s (- 24m 38s) (350 17%) 3.1590\n",
      "5m 24s (- 24m 24s) (363 18%) 3.0168\n",
      "5m 35s (- 24m 14s) (375 18%) 2.9951\n",
      "5m 46s (- 24m 0s) (388 19%) 2.9576\n",
      "5m 58s (- 23m 53s) (400 20%) 2.9493\n",
      "6m 9s (- 23m 41s) (413 20%) 2.9533\n",
      "6m 21s (- 23m 32s) (425 21%) 2.7879\n",
      "6m 32s (- 23m 19s) (438 21%) 2.7947\n",
      "6m 43s (- 23m 10s) (450 22%) 2.7744\n",
      "6m 54s (- 22m 56s) (463 23%) 2.7058\n",
      "7m 5s (- 22m 46s) (475 23%) 2.7735\n",
      "7m 16s (- 22m 33s) (488 24%) 2.6843\n",
      "7m 27s (- 22m 22s) (500 25%) 2.6673\n",
      "7m 38s (- 22m 9s) (513 25%) 2.5558\n",
      "7m 49s (- 21m 59s) (525 26%) 2.6485\n",
      "8m 0s (- 21m 46s) (538 26%) 2.4909\n",
      "8m 11s (- 21m 36s) (550 27%) 2.5313\n",
      "8m 23s (- 21m 24s) (563 28%) 2.4602\n",
      "8m 34s (- 21m 13s) (575 28%) 2.5171\n",
      "8m 45s (- 21m 1s) (588 29%) 2.4805\n",
      "8m 56s (- 20m 52s) (600 30%) 2.4274\n",
      "9m 8s (- 20m 41s) (613 30%) 2.4359\n",
      "9m 20s (- 20m 33s) (625 31%) 2.3843\n",
      "9m 32s (- 20m 21s) (638 31%) 2.3732\n",
      "9m 42s (- 20m 9s) (650 32%) 2.3008\n",
      "9m 52s (- 19m 55s) (663 33%) 2.2023\n",
      "10m 3s (- 19m 45s) (675 33%) 2.1796\n",
      "10m 13s (- 19m 30s) (688 34%) 2.2863\n",
      "10m 24s (- 19m 20s) (700 35%) 2.1724\n",
      "10m 36s (- 19m 8s) (713 35%) 2.1562\n",
      "10m 46s (- 18m 56s) (725 36%) 2.1503\n",
      "10m 56s (- 18m 42s) (738 36%) 2.0333\n",
      "11m 6s (- 18m 31s) (750 37%) 2.0008\n",
      "11m 17s (- 18m 17s) (763 38%) 2.0285\n",
      "11m 27s (- 18m 7s) (775 38%) 1.9899\n",
      "11m 39s (- 17m 56s) (788 39%) 1.9415\n",
      "11m 52s (- 17m 48s) (800 40%) 1.8612\n",
      "12m 6s (- 17m 40s) (813 40%) 1.8345\n",
      "12m 17s (- 17m 29s) (825 41%) 1.9007\n",
      "12m 30s (- 17m 20s) (838 41%) 1.8804\n",
      "12m 42s (- 17m 11s) (850 42%) 1.7516\n",
      "12m 53s (- 16m 59s) (863 43%) 1.7346\n",
      "13m 4s (- 16m 48s) (875 43%) 1.6534\n",
      "13m 17s (- 16m 38s) (888 44%) 1.6898\n",
      "13m 33s (- 16m 33s) (900 45%) 1.6914\n",
      "13m 47s (- 16m 24s) (913 45%) 1.6132\n",
      "14m 3s (- 16m 20s) (925 46%) 1.5135\n",
      "14m 20s (- 16m 14s) (938 46%) 1.4758\n",
      "14m 36s (- 16m 8s) (950 47%) 1.5001\n",
      "14m 50s (- 15m 59s) (963 48%) 1.4932\n",
      "15m 6s (- 15m 52s) (975 48%) 1.4192\n",
      "15m 20s (- 15m 43s) (988 49%) 1.3998\n",
      "15m 32s (- 15m 32s) (1000 50%) 1.3508\n",
      "15m 44s (- 15m 20s) (1013 50%) 1.2871\n",
      "15m 56s (- 15m 10s) (1025 51%) 1.2507\n",
      "16m 9s (- 14m 58s) (1038 51%) 1.2929\n",
      "16m 21s (- 14m 48s) (1050 52%) 1.1885\n",
      "16m 34s (- 14m 36s) (1063 53%) 1.1469\n",
      "16m 46s (- 14m 25s) (1075 53%) 1.1536\n",
      "16m 57s (- 14m 13s) (1088 54%) 1.0622\n",
      "17m 8s (- 14m 1s) (1100 55%) 1.0818\n",
      "17m 20s (- 13m 49s) (1113 55%) 1.0563\n",
      "17m 33s (- 13m 39s) (1125 56%) 1.0057\n",
      "17m 47s (- 13m 28s) (1138 56%) 0.9571\n",
      "18m 0s (- 13m 18s) (1150 57%) 0.9559\n",
      "18m 13s (- 13m 7s) (1163 58%) 0.9215\n",
      "18m 27s (- 12m 57s) (1175 58%) 0.8857\n",
      "18m 41s (- 12m 46s) (1188 59%) 0.8377\n",
      "18m 57s (- 12m 38s) (1200 60%) 0.8296\n",
      "19m 10s (- 12m 26s) (1213 60%) 0.7566\n",
      "19m 23s (- 12m 16s) (1225 61%) 0.7665\n",
      "19m 34s (- 12m 3s) (1238 61%) 0.7052\n",
      "19m 45s (- 11m 51s) (1250 62%) 0.7031\n",
      "19m 57s (- 11m 38s) (1263 63%) 0.6757\n",
      "20m 11s (- 11m 29s) (1275 63%) 0.6386\n",
      "20m 27s (- 11m 18s) (1288 64%) 0.6596\n",
      "20m 44s (- 11m 10s) (1300 65%) 0.6071\n",
      "20m 57s (- 10m 58s) (1313 65%) 0.5882\n",
      "21m 10s (- 10m 47s) (1325 66%) 0.5819\n",
      "21m 24s (- 10m 35s) (1338 66%) 0.5618\n",
      "21m 40s (- 10m 26s) (1350 67%) 0.5344\n",
      "21m 57s (- 10m 15s) (1363 68%) 0.5135\n",
      "22m 11s (- 10m 5s) (1375 68%) 0.5128\n",
      "22m 28s (- 9m 54s) (1388 69%) 0.4966\n",
      "22m 43s (- 9m 44s) (1400 70%) 0.4843\n",
      "22m 57s (- 9m 32s) (1413 70%) 0.4699\n",
      "23m 9s (- 9m 20s) (1425 71%) 0.4402\n",
      "23m 22s (- 9m 8s) (1438 71%) 0.4415\n",
      "23m 36s (- 8m 57s) (1450 72%) 0.4273\n",
      "23m 52s (- 8m 45s) (1463 73%) 0.4098\n",
      "24m 8s (- 8m 35s) (1475 73%) 0.3978\n",
      "24m 24s (- 8m 23s) (1488 74%) 0.3849\n",
      "24m 40s (- 8m 13s) (1500 75%) 0.3853\n",
      "24m 59s (- 8m 2s) (1513 75%) 0.3771\n",
      "25m 20s (- 7m 53s) (1525 76%) 0.3649\n",
      "25m 45s (- 7m 44s) (1538 76%) 0.3552\n",
      "26m 6s (- 7m 34s) (1550 77%) 0.3483\n",
      "26m 28s (- 7m 24s) (1563 78%) 0.3284\n",
      "26m 56s (- 7m 16s) (1575 78%) 0.3307\n",
      "27m 23s (- 7m 6s) (1588 79%) 0.3099\n",
      "27m 57s (- 6m 59s) (1600 80%) 0.3078\n",
      "28m 31s (- 6m 50s) (1613 80%) 0.3091\n",
      "29m 5s (- 6m 42s) (1625 81%) 0.2955\n",
      "29m 36s (- 6m 32s) (1638 81%) 0.2901\n",
      "30m 10s (- 6m 23s) (1650 82%) 0.2867\n",
      "30m 36s (- 6m 12s) (1663 83%) 0.2726\n",
      "31m 6s (- 6m 2s) (1675 83%) 0.2585\n",
      "31m 43s (- 5m 51s) (1688 84%) 0.2627\n",
      "32m 18s (- 5m 42s) (1700 85%) 0.2590\n",
      "32m 49s (- 5m 29s) (1713 85%) 0.2486\n",
      "33m 12s (- 5m 17s) (1725 86%) 0.2461\n",
      "33m 40s (- 5m 4s) (1738 86%) 0.2414\n",
      "34m 4s (- 4m 52s) (1750 87%) 0.2328\n",
      "34m 33s (- 4m 38s) (1763 88%) 0.2284\n",
      "35m 4s (- 4m 26s) (1775 88%) 0.2239\n",
      "35m 35s (- 4m 13s) (1788 89%) 0.2166\n",
      "36m 4s (- 4m 0s) (1800 90%) 0.2197\n",
      "36m 27s (- 3m 45s) (1813 90%) 0.2137\n",
      "36m 42s (- 3m 31s) (1825 91%) 0.2083\n",
      "36m 52s (- 3m 15s) (1838 91%) 0.2068\n",
      "37m 2s (- 3m 0s) (1850 92%) 0.2028\n",
      "37m 12s (- 2m 44s) (1863 93%) 0.1983\n",
      "37m 22s (- 2m 29s) (1875 93%) 0.1888\n",
      "37m 32s (- 2m 13s) (1888 94%) 0.1936\n",
      "37m 41s (- 1m 59s) (1900 95%) 0.1881\n",
      "37m 51s (- 1m 43s) (1913 95%) 0.1834\n",
      "38m 1s (- 1m 28s) (1925 96%) 0.1764\n",
      "38m 11s (- 1m 13s) (1938 96%) 0.1707\n",
      "38m 22s (- 0m 59s) (1950 97%) 0.1741\n",
      "38m 33s (- 0m 43s) (1963 98%) 0.1652\n",
      "38m 44s (- 0m 29s) (1975 98%) 0.1657\n",
      "38m 56s (- 0m 14s) (1988 99%) 0.1653\n",
      "39m 7s (- 0m 0s) (2000 100%) 0.1656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "hidden_size=256\n",
    "\n",
    "train_dataset = VocabDataset(pairs, input_lang.word2index, output_lang.word2index)\n",
    "# 1 batch input dimension: num_sentences x max sentence length\n",
    "# 1 batch: source_sentences, target_sentences, source_lengths, target_lengths\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "encoder = EncoderRNN(hidden_size = hidden_size, vocab_size = input_lang.n_words )\n",
    "decoder = BahdanauAttnDecoderRNN(hidden_size, output_lang.n_words)\n",
    "\n",
    "plot_losses = trainIters(train_loader, encoder, decoder, n_iters=2000, \n",
    "                         print_every=50, plot_every=100, learning_rate=0.01, teacher_forcing_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Expected: ['Biohackers', 'work', 'alone']\n",
      "Actual: ['Biohackers', 'work', 'alone']\n",
      "\n",
      "\n",
      "Expected: ['Hundreds', 'of', 'people', 'were']\n",
      "Actual: ['Hundreds', 'of', 'people', 'were']\n",
      "\n",
      "\n",
      "Expected: ['And', 'everybody', 's', 'crying']\n",
      "Actual: ['And', 'everybody', 's', 'crying']\n",
      "\n",
      "\n",
      "Expected: ['All', 'right']\n",
      "Actual: ['Okay']\n",
      "\n",
      "\n",
      "Expected: ['There', 's', 'absolutely', 'no']\n",
      "Actual: ['There', 's', 'absolutely', 'no']\n",
      "\n",
      "\n",
      "Expected: ['The', 'effect', 'is', 'just']\n",
      "Actual: ['The', 'effect', 'is', 'just']\n",
      "\n",
      "\n",
      "Expected: ['He', 'was', 'looking', 'at']\n",
      "Actual: ['He', 'was', 'looking', 'at']\n",
      "\n",
      "\n",
      "Expected: ['And', 'this']\n",
      "Actual: ['And', 'this']\n",
      "\n",
      "\n",
      "Expected: ['Cows', 'with', 'a', 'view']\n",
      "Actual: ['Cows', 'with', 'a', 'view']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'very', 'much']\n",
      "Actual: ['Thank', 'you']\n",
      "\n",
      "\n",
      "Expected: ['The', 'outcome', 'immediate']\n",
      "Actual: ['The', 'outcome', 'immediate']\n",
      "\n",
      "\n",
      "Expected: ['So', 'life', 'had', 'to']\n",
      "Actual: ['So', 'life', 'had', 'to']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you']\n",
      "Actual: ['Thank', 'you']\n",
      "\n",
      "\n",
      "Expected: ['No', 'you', 'can', 't']\n",
      "Actual: ['No', 'you', 'can', 't']\n",
      "\n",
      "\n",
      "Expected: ['It', 's', 'adaptive']\n",
      "Actual: ['It', 's', 'adaptive']\n",
      "\n",
      "\n",
      "Expected: ['We', 'make', 'things', 'grow']\n",
      "Actual: ['We', 'make', 'things', 'grow']\n",
      "\n",
      "\n",
      "Expected: ['You', 'can', 'see', 'the']\n",
      "Actual: ['You', 'can', 'see', 'the']\n",
      "\n",
      "\n",
      "Expected: ['Actually', 'it', 's', 'very']\n",
      "Actual: ['Actually', 'it', 's', 'very']\n",
      "\n",
      "\n",
      "Expected: ['Grab', 'that', 'thumb']\n",
      "Actual: ['Grab', 'that', 'thumb']\n",
      "\n",
      "\n",
      "Expected: ['It', 's', 'a', 'massive']\n",
      "Actual: ['It', 's', 'a', 'massive']\n",
      "\n",
      "\n",
      "Expected: ['And', 'what', 'went', 'wrong']\n",
      "Actual: ['And', 'what', 'went', 'wrong']\n",
      "\n",
      "\n",
      "Expected: ['The', 'same', 'thing', 'happens']\n",
      "Actual: ['The', 'same', 'thing', 'happens']\n",
      "\n",
      "\n",
      "Expected: ['It', 's', 'smaller', 'than']\n",
      "Actual: ['It', 's', 'smaller', 'than']\n",
      "\n",
      "\n",
      "Expected: ['We', 'reverse', 'engineer', 'lab']\n",
      "Actual: ['We', 'reverse', 'engineer', 'lab']\n",
      "\n",
      "\n",
      "Expected: ['Umar', 'also', 'has', 'polio']\n",
      "Actual: ['Umar', 'also', 'has', 'polio']\n",
      "\n",
      "\n",
      "Expected: ['Think', 'about', 'the', 'following']\n",
      "Actual: ['Think', 'about', 'the', 'following']\n",
      "\n",
      "\n",
      "Expected: ['Of', 'course', 'they', 'would']\n",
      "Actual: ['Of', 'course', 'they', 'would']\n",
      "\n",
      "\n",
      "Expected: ['This', 'is', 'Mahler']\n",
      "Actual: ['This', 'is', 'Mahler']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you']\n",
      "Actual: ['Thank', 'you']\n",
      "\n",
      "\n",
      "Expected: ['We', 'like', 'to', 'build']\n",
      "Actual: ['We', 'like', 'to', 'build']\n",
      "\n",
      "\n",
      "Expected: ['It', 'could', 'be', 'anti-bacterial']\n",
      "Actual: ['It', 'could', 'be', 'anti-bacterial']\n",
      "\n",
      "\n",
      "Expected: ['Oh', 'my', 'God']\n",
      "Actual: ['Oh', 'my', 'God']\n",
      "\n",
      "\n",
      "Expected: ['And', 'you', 'become', 'friends']\n",
      "Actual: ['And', 'you', 'become', 'friends']\n",
      "\n",
      "\n",
      "Expected: ['This', 'is', 'a', 'great']\n",
      "Actual: ['This', 'is', 'a', 'great']\n",
      "\n",
      "\n",
      "Expected: ['This', 'is', 'Carnegie', 'Hall']\n",
      "Actual: ['This', 'is', 'Carnegie', 'Hall']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'very', 'much']\n",
      "Actual: ['Thank', 'you', 'very', 'much']\n",
      "\n",
      "\n",
      "Expected: ['So', 'curiosity']\n",
      "Actual: ['So', 'curiosity']\n",
      "\n",
      "\n",
      "Expected: ['I', 'start', 'it', 'myself']\n",
      "Actual: ['I', 'start', 'it', 'myself']\n",
      "\n",
      "\n",
      "Expected: ['This', 'is', 'La', 'Scala']\n",
      "Actual: ['This', 'is', 'La', 'Scala']\n",
      "\n",
      "\n",
      "Expected: ['I', 'was', 'burned', 'very']\n",
      "Actual: ['I', 'was', 'burned', 'very']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you']\n",
      "Actual: ['Thank', 'you']\n",
      "\n",
      "\n",
      "Expected: ['That', 's', 'the', 'stigma']\n",
      "Actual: ['That', 's', 'the', 'stigma']\n",
      "\n",
      "\n",
      "Expected: ['But', 'Wagner', 'made', 'an']\n",
      "Actual: ['But', 'Wagner', 'made', 'an']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'very', 'much']\n",
      "Actual: ['Thank', 'you', 'very', 'much']\n",
      "\n",
      "\n",
      "Expected: ['Let', 's', 'talk', 'trash']\n",
      "Actual: ['Let', 's', 'talk', 'trash']\n",
      "\n",
      "\n",
      "Expected: ['We', 'sing']\n",
      "Actual: ['We', 'sing']\n",
      "\n",
      "\n",
      "Expected: ['All', 'right']\n",
      "Actual: ['Okay']\n",
      "\n",
      "\n",
      "Expected: ['That', 'was', 'whistling']\n",
      "Actual: ['That', 'was', 'whistling']\n",
      "\n",
      "\n",
      "Expected: ['This', 'is', 'the', 'enemy']\n",
      "Actual: ['This', 'is', 'the', 'enemy']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'very', 'much']\n",
      "Actual: ['Thank', 'you', 'very', 'much']\n",
      "\n",
      "\n",
      "Expected: ['The', 'nervous', 'system', 'has']\n",
      "Actual: ['The', 'nervous', 'system', 'has']\n",
      "\n",
      "\n",
      "Expected: ['These', 'are', 'children', 'like']\n",
      "Actual: ['These', 'are', 'children', 'like']\n",
      "\n",
      "\n",
      "Expected: ['Oh', 'hah']\n",
      "Actual: ['Oh', 'hah']\n",
      "\n",
      "\n",
      "Expected: ['Okay']\n",
      "Actual: ['Okay']\n",
      "\n",
      "\n",
      "Expected: ['Please', 'keep', 'your', 'seat']\n",
      "Actual: ['Please', 'keep', 'your', 'seat']\n",
      "\n",
      "\n",
      "Expected: ['Just', 'raise', 'that', 'Exactly']\n",
      "Actual: ['Just', 'raise', 'that', 'Exactly']\n",
      "\n",
      "\n",
      "Expected: ['Was', 'the', 'tale', 'told']\n",
      "Actual: ['Was', 'the', 'tale', 'told']\n",
      "\n",
      "\n",
      "Expected: ['We', 'were', 'his', 'mirror']\n",
      "Actual: ['We', 'were', 'his', 'mirror']\n",
      "\n",
      "\n",
      "Expected: ['Now', 'it', 's', 'anonymous']\n",
      "Actual: ['Now', 'it', 's', 'anonymous']\n",
      "\n",
      "\n",
      "Expected: ['but', 'mostly', 'bottle', 'caps']\n",
      "Actual: ['but', 'mostly', 'bottle', 'caps']\n",
      "\n",
      "\n",
      "Expected: ['This', 'is', 'the', 'picture']\n",
      "Actual: ['This', 'is', 'the', 'picture']\n",
      "\n",
      "\n",
      "Expected: ['And', 'it', 'was', 'also']\n",
      "Actual: ['And', 'it', 'was', 'also']\n",
      "\n",
      "\n",
      "Expected: []\n",
      "Actual: []\n",
      "\n",
      "\n",
      "Expected: ['Perfect']\n",
      "Actual: ['Perfect']\n",
      "\n",
      "\n",
      "Expected: ['It', 's', 'really', 'cool']\n",
      "Actual: ['It', 's', 'really', 'cool']\n",
      "\n",
      "\n",
      "Expected: ['Here', 'is', 'the', 'thing']\n",
      "Actual: ['Here', 'is', 'the', 'thing']\n",
      "\n",
      "\n",
      "Expected: ['What']\n",
      "Actual: ['What']\n",
      "\n",
      "\n",
      "Expected: ['Yes', 'Awesome', 'Okay']\n",
      "Actual: ['Yes', 'Awesome', 'Okay']\n",
      "\n",
      "\n",
      "Expected: ['A', 'very', 'different', 'feeling']\n",
      "Actual: ['A', 'very', 'different', 'feeling']\n",
      "\n",
      "\n",
      "Expected: ['Okay', 'here', 'it', 'is']\n",
      "Actual: ['Okay', 'here', 'it', 'is']\n",
      "\n",
      "\n",
      "Expected: ['Okay']\n",
      "Actual: ['Okay']\n",
      "\n",
      "\n",
      "Expected: ['This', 'is', 'Chet', 'Baker']\n",
      "Actual: ['This', 'is', 'Chet', 'Baker']\n",
      "\n",
      "\n",
      "Expected: ['Don', 't', 'cry']\n",
      "Actual: ['Don', 't', 'cry']\n",
      "\n",
      "\n",
      "Expected: ['It', 's', 'happening']\n",
      "Actual: ['Okay']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'very', 'much']\n",
      "Actual: ['Thank', 'you', 'very', 'much']\n",
      "\n",
      "\n",
      "Expected: ['Wooo']\n",
      "Actual: ['Wooo']\n",
      "\n",
      "\n",
      "Expected: ['Okay', 'Africa']\n",
      "Actual: ['Okay', 'Africa']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'very', 'much']\n",
      "Actual: ['Thank', 'you', 'very', 'much']\n",
      "\n",
      "\n",
      "Expected: ['Not', 'anymore']\n",
      "Actual: ['Not', 'anymore']\n",
      "\n",
      "\n",
      "Expected: ['So', 'congratulations']\n",
      "Actual: ['So', 'congratulations']\n",
      "\n",
      "\n",
      "Expected: ['I', 'lost', 'my', 'face']\n",
      "Actual: ['I', 'lost', 'my', 'face']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you']\n",
      "Actual: ['Thank', 'you']\n",
      "\n",
      "\n",
      "Expected: ['Mario']\n",
      "Actual: ['Mario']\n",
      "\n",
      "\n",
      "Expected: ['Steaming', 'piles', 'of', 'humus']\n",
      "Actual: ['Steaming', 'piles', 'of', 'humus']\n",
      "\n",
      "\n",
      "Expected: ['So', 'that', 'became', 'a']\n",
      "Actual: ['So', 'that', 'became', 'a']\n",
      "\n",
      "\n",
      "Expected: ['Something', 'crazy', 'also', 'happened']\n",
      "Actual: ['Something', 'crazy', 'also', 'happened']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'guys']\n",
      "Actual: ['Thank', 'you', 'guys']\n",
      "\n",
      "\n",
      "Expected: ['The', 'press', 'started', 'calling']\n",
      "Actual: ['The', 'press', 'started', 'calling']\n",
      "\n",
      "\n",
      "Expected: ['Porous', 'nonporous']\n",
      "Actual: ['Porous', 'nonporous']\n",
      "\n",
      "\n",
      "Expected: ['Crazy', 'yes']\n",
      "Actual: ['Crazy', 'yes']\n",
      "\n",
      "\n",
      "Expected: ['Don', 't', 'start', 'wrestling']\n",
      "Actual: ['Don', 't', 'start', 'wrestling']\n",
      "\n",
      "\n",
      "Expected: ['Thank', 'you', 'very', 'much']\n",
      "Actual: ['Thank', 'you', 'very', 'much']\n",
      "\n",
      "\n",
      "Expected: ['We', 'adapt']\n",
      "Actual: ['We', 'adapt']\n",
      "\n",
      "\n",
      "Expected: ['This', 'disease', 'was', 'terrifying']\n",
      "Actual: ['This', 'disease', 'was', 'terrifying']\n",
      "\n",
      "\n",
      "Expected: ['Charles', 'Moore', 'Thank', 'you']\n",
      "Actual: ['Charles', 'Moore', 'Thank', 'you']\n",
      "\n",
      "\n",
      "Expected: ['I', 'thought', 'so']\n",
      "Actual: ['I', 'thought', 'so']\n",
      "\n",
      "\n",
      "Expected: ['It', 'was', 'terribly', 'dangerous']\n",
      "Actual: ['It', 'was', 'terribly', 'dangerous']\n",
      "\n",
      "\n",
      "Expected: ['Francesca', 'Fedeli', 'Ciao']\n",
      "Actual: ['Francesca', 'Fedeli', 'Ciao']\n",
      "\n",
      "\n",
      "Expected: ['It', 's', 'diddly-point-squat']\n",
      "Actual: ['It', 's', 'diddly-point-squat']\n",
      "\n",
      "\n",
      "Expected: ['Umar', 'was', 'paralyzed', 'for']\n",
      "Actual: ['Umar', 'was', 'paralyzed', 'for']\n"
     ]
    }
   ],
   "source": [
    "decoded, actual = evaluate_batch(train_loader, encoder, decoder)\n",
    "\n",
    "for i in zip(decoded, actual):\n",
    "    if i == 100:\n",
    "        break\n",
    "    print('\\n')\n",
    "    print('Expected:', i[1])\n",
    "    print('Actual:' ,i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.43900451104247"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bleu(decoded, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
