{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU encoder and GRU decoder for translating from English to Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Import libraries\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import \n",
    "\n",
    "import torch\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from typing import List\n",
    "from collections import Counter, namedtuple\n",
    "from itertools import zip_longest\n",
    "\n",
    "\n",
    "import io\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "MAX_LENGTH = 30 #temp\n",
    "\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "\n",
    "PAD_IDX = 0 \n",
    "SOS_IDX = 1\n",
    "EOS_IDX = 2\n",
    "UNK_IDX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Code references: https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb?fbclid=IwAR0LRHAIXhvRqewTXayFLEdr3Pw6temcC2d0SaNE6KZ_sXPyaCvvHC-tasQ\n",
    "\n",
    "### CALCULATE BLEU FUNCTIONS ###\n",
    "def tokenize_13a(line):\n",
    "    \"\"\"\n",
    "    Tokenizes an input line using a relatively minimal tokenization that is however equivalent to mteval-v13a, used by WMT.\n",
    "    :param line: a segment to tokenize\n",
    "    :return: the tokenized line\n",
    "    \"\"\"\n",
    "\n",
    "    norm = line\n",
    "\n",
    "    # language-independent part:\n",
    "    norm = norm.replace('<skipped>', '')\n",
    "    norm = norm.replace('-\\n', '')\n",
    "    norm = norm.replace('\\n', ' ')\n",
    "    norm = norm.replace('&quot;', '\"')\n",
    "    norm = norm.replace('&amp;', '&')\n",
    "    norm = norm.replace('&lt;', '<')\n",
    "    norm = norm.replace('&gt;', '>')\n",
    "\n",
    "    # language-dependent part (assuming Western languages):\n",
    "    norm = \" {} \".format(norm)\n",
    "    norm = re.sub(r'([\\{-\\~\\[-\\` -\\&\\(-\\+\\:-\\@\\/])', ' \\\\1 ', norm)\n",
    "    norm = re.sub(r'([^0-9])([\\.,])', '\\\\1 \\\\2 ', norm)  # tokenize period and comma unless preceded by a digit\n",
    "    norm = re.sub(r'([\\.,])([^0-9])', ' \\\\1 \\\\2', norm)  # tokenize period and comma unless followed by a digit\n",
    "    norm = re.sub(r'([0-9])(-)', '\\\\1 \\\\2 ', norm)  # tokenize dash when preceded by a digit\n",
    "    norm = re.sub(r'\\s+', ' ', norm)  # one space only between words\n",
    "    norm = re.sub(r'^\\s+', '', norm)  # no leading space\n",
    "    norm = re.sub(r'\\s+$', '', norm)  # no trailing space\n",
    "\n",
    "    return norm\n",
    "\n",
    "def corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n",
    "                 use_effective_order=False):\n",
    "    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
    "    :param sys_stream: The system stream (a sequence of segments)\n",
    "    :param ref_streams: A list of one or more reference streams (each a sequence of segments)\n",
    "    :param smooth: The smoothing method to use\n",
    "    :param smooth_floor: For 'floor' smoothing, the floor to use\n",
    "    :param force: Ignore data that looks already tokenized\n",
    "    :param lowercase: Lowercase the data\n",
    "    :param tokenize: The tokenizer to use\n",
    "    :return: a BLEU object containing everything you'd want\n",
    "    \"\"\"\n",
    "\n",
    "    # Add some robustness to the input arguments\n",
    "    if isinstance(sys_stream, str):\n",
    "        sys_stream = [sys_stream]\n",
    "    if isinstance(ref_streams, str):\n",
    "        ref_streams = [[ref_streams]]\n",
    "\n",
    "    sys_len = 0\n",
    "    ref_len = 0\n",
    "\n",
    "    correct = [0 for n in range(NGRAM_ORDER)]\n",
    "    total = [0 for n in range(NGRAM_ORDER)]\n",
    "    \n",
    "    # look for already-tokenized sentences\n",
    "    tokenized_count = 0\n",
    "\n",
    "    fhs = [sys_stream] + ref_streams\n",
    "    for lines in zip_longest(*fhs):\n",
    "        if None in lines:\n",
    "            raise EOFError(\"Source and reference streams have different lengths!\")\n",
    "\n",
    "        if lowercase:\n",
    "            lines = [x.lower() for x in lines]\n",
    "            \n",
    "        tokenize= 'tokenize_13a'    \n",
    "\n",
    "        if not (force or tokenize == 'none') and lines[0].rstrip().endswith(' .'):\n",
    "            tokenized_count += 1\n",
    "\n",
    "            if tokenized_count == 100:\n",
    "                logging.warning('That\\'s 100 lines that end in a tokenized period (\\'.\\')')\n",
    "                logging.warning('It looks like you forgot to detokenize your test data, which may hurt your score.')\n",
    "                logging.warning('If you insist your data is detokenized, or don\\'t care, you can suppress this message with \\'--force\\'.')\n",
    "\n",
    "        output, *refs = [tokenize_13a(x.rstrip()) for x in lines]\n",
    "        \n",
    "        ref_ngrams, closest_diff, closest_len = ref_stats(output, refs)\n",
    "        sys_len += len(output.split())\n",
    "        ref_len += closest_len\n",
    "\n",
    "        sys_ngrams = extract_ngrams(output)\n",
    "        for ngram in sys_ngrams.keys():\n",
    "            n = len(ngram.split())\n",
    "            correct[n-1] += min(sys_ngrams[ngram], ref_ngrams.get(ngram, 0))\n",
    "            total[n-1] += sys_ngrams[ngram]\n",
    "            \n",
    "    return compute_bleu(correct, total, sys_len, ref_len, smooth, smooth_floor, use_effective_order)\n",
    "  \n",
    "  \n",
    "# n-gram order. Don't change this.\n",
    "NGRAM_ORDER = 4\n",
    "  \n",
    "def compute_bleu(correct: List[int], total: List[int], sys_len: int, ref_len: int, smooth = 'none', smooth_floor = 0.01,\n",
    "                 use_effective_order = False):\n",
    "    \"\"\"Computes BLEU score from its sufficient statistics. Adds smoothing.\n",
    "    :param correct: List of counts of correct ngrams, 1 <= n <= NGRAM_ORDER\n",
    "    :param total: List of counts of total ngrams, 1 <= n <= NGRAM_ORDER\n",
    "    :param sys_len: The cumulative system length\n",
    "    :param ref_len: The cumulative reference length\n",
    "    :param smooth: The smoothing method to use\n",
    "    :param smooth_floor: The smoothing value added, if smooth method 'floor' is used\n",
    "    :param use_effective_order: Use effective order.\n",
    "    :return: A BLEU object with the score (100-based) and other statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    precisions = [0 for x in range(NGRAM_ORDER)]\n",
    "\n",
    "    smooth_mteval = 1.\n",
    "    effective_order = NGRAM_ORDER\n",
    "    for n in range(NGRAM_ORDER):\n",
    "        if total[n] == 0:\n",
    "            break\n",
    "\n",
    "        if use_effective_order:\n",
    "            effective_order = n + 1\n",
    "\n",
    "        if correct[n] == 0:\n",
    "            if smooth == 'exp':\n",
    "                smooth_mteval *= 2\n",
    "                precisions[n] = 100. / (smooth_mteval * total[n])\n",
    "            elif smooth == 'floor':\n",
    "                precisions[n] = 100. * smooth_floor / total[n]\n",
    "        else:\n",
    "            precisions[n] = 100. * correct[n] / total[n]\n",
    "\n",
    "    # If the system guesses no i-grams, 1 <= i <= NGRAM_ORDER, the BLEU score is 0 (technically undefined).\n",
    "    # This is a problem for sentence-level BLEU or a corpus of short sentences, where systems will get no credit\n",
    "    # if sentence lengths fall under the NGRAM_ORDER threshold. This fix scales NGRAM_ORDER to the observed\n",
    "    # maximum order. It is only available through the API and off by default\n",
    "\n",
    "    brevity_penalty = 1.0\n",
    "    if sys_len < ref_len:\n",
    "        brevity_penalty = math.exp(1 - ref_len / sys_len) if sys_len > 0 else 0.0\n",
    "        \n",
    "\n",
    "    bleu = brevity_penalty * math.exp(sum(map(my_log, precisions[:effective_order])) / effective_order)\n",
    "    return bleu \n",
    "\n",
    "\n",
    "def ref_stats(output, refs):\n",
    "    ngrams = Counter()\n",
    "    closest_diff = None\n",
    "    closest_len = None\n",
    "    for ref in refs:\n",
    "        tokens = ref.split()\n",
    "        reflen = len(tokens)\n",
    "        diff = abs(len(output.split()) - reflen)\n",
    "        if closest_diff is None or diff < closest_diff:\n",
    "            closest_diff = diff\n",
    "            closest_len = reflen\n",
    "        elif diff == closest_diff:\n",
    "            if reflen < closest_len:\n",
    "                closest_len = reflen\n",
    "\n",
    "        ngrams_ref = extract_ngrams(ref)\n",
    "        for ngram in ngrams_ref.keys():\n",
    "            ngrams[ngram] = max(ngrams[ngram], ngrams_ref[ngram])\n",
    "\n",
    "    return ngrams, closest_diff, closest_len\n",
    "\n",
    "\n",
    "def extract_ngrams(line, min_order=1, max_order=NGRAM_ORDER) -> Counter:\n",
    "    \"\"\"Extracts all the ngrams (1 <= n <= NGRAM_ORDER) from a sequence of tokens.\n",
    "    :param line: a segment containing a sequence of words\n",
    "    :param max_order: collect n-grams from 1<=n<=max\n",
    "    :return: a dictionary containing ngrams and counts\n",
    "    \"\"\"\n",
    "\n",
    "    ngrams = Counter()\n",
    "    tokens = line.split()\n",
    "    for n in range(min_order, max_order + 1):\n",
    "        for i in range(0, len(tokens) - n + 1):\n",
    "            ngram = ' '.join(tokens[i: i + n])\n",
    "            ngrams[ngram] += 1\n",
    "\n",
    "    return ngrams  \n",
    "\n",
    "def my_log(num):\n",
    "    \"\"\"\n",
    "    Floors the log function\n",
    "    :param num: the number\n",
    "    :return: log(num) floored to a very low number\n",
    "    \"\"\"\n",
    "\n",
    "    if num == 0.0:\n",
    "        return -9999999999\n",
    "    return math.log(num)\n",
    "\n",
    "### Loss functions ###\n",
    "\n",
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.range(0, max_len - 1).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def masked_cross_entropy(logits, target, length):\n",
    "    length = Variable(torch.LongTensor(length))\n",
    "\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1)).to(device)\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    #log_probs_flat = functional.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(logits_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1)).to(device)\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum().to(device)\n",
    "    return loss\n",
    "\n",
    "  \n",
    "    \n",
    "### MODEL INPUTS PROCESSING ###   \n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 4  # Count SOS and EOS and Pad\n",
    "        self.all_words = []\n",
    "        \n",
    "    def build_vocab(self, embedding, max_vocab_size = 100000):\n",
    "    # save index 1 for unk and 0 for pad\n",
    "    # Returns:\n",
    "    # id2word: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # word2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "        unique_words = list(embedding.keys())[0:max_vocab_size]\n",
    "\n",
    "        index2word =  unique_words #list of words available in embedding\n",
    "        index2word = ['<pad>', '<sos>', '<eos>','<unk>'] + index2word #add pad and unknown to the beginning\n",
    "\n",
    "        word2index = dict(zip(unique_words, range(4,4+len(unique_words)))) # dictionary of words and indices \n",
    "        word2index['<pad>'] = PAD_IDX  #add pad symbol to the dictionary\n",
    "        word2index['<unk>'] = UNK_IDX  #add unkown symbol to the dictionary\n",
    "        word2index['<eos>'] = EOS_IDX\n",
    "        word2index['<sos>'] = SOS_IDX\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.index2word = index2word\n",
    "        self.n_words = len(self.word2index)\n",
    "\n",
    "        return word2index, index2word \n",
    "    \n",
    "    \n",
    "\n",
    "### PREPROCESSING FUNCTIONS ###\n",
    "\n",
    "def removePunctuation(s):\n",
    "    to_remove = ('&lt;', '&gt;', '&amp;', '&apos;', '&quot;')\n",
    "    table = str.maketrans(dict.fromkeys('.!?:,'))\n",
    "    s = s.translate(table)\n",
    "    for i in to_remove:\n",
    "        s=s.replace(i,'')   \n",
    "    s = s.strip()\n",
    "    return s    \n",
    "            \n",
    "def remove_blanks(pair):\n",
    "    '''Remove empty lines'''\n",
    "    if len(pair[0]) == 0 or len(pair[1]) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def set_max_length(pair, max_length=MAX_LENGTH):\n",
    "    if len(pair[0].split(' ')) > max_length or len(pair[1].split(' '))>max_length:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def readLangs(filename1, filename2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    with open(filename1, encoding='utf-8') as f:\n",
    "        lines1 = f.read().strip().split('\\n')\n",
    "        \n",
    "    with open(filename2, encoding='utf-8') as f:\n",
    "        lines2 = f.read().strip().split('\\n')   \n",
    "        \n",
    "    # Remove punctuation\n",
    "    lines1 = [removePunctuation(l) for l in lines1]\n",
    "    lines2 = [removePunctuation(l) for l in lines2]\n",
    "              \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse: \n",
    "        pairs =list(zip(lines2, lines1))\n",
    "        input_lang = Lang(filename2[-2:]) #take last two letters\n",
    "        output_lang = Lang(filename1[-2:])\n",
    "    else:\n",
    "        pairs =list(zip(lines1, lines2))\n",
    "        input_lang = Lang(filename1[-2:])\n",
    "        output_lang = Lang(filename2[-2:])\n",
    "            \n",
    "    pairs = list(filter(remove_blanks, pairs))  \n",
    "    pairs = list(filter(set_max_length, pairs))\n",
    "\n",
    "    return input_lang, output_lang, pairs \n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, embedding_in, embedding_out, num_sent=None, reverse=False):\n",
    "    \n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    pairs = pairs[:num_sent]\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "           \n",
    "    input_lang.build_vocab(embedding_in)\n",
    "    output_lang.build_vocab(embedding_out)\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "### PREPROCESS DATA FOR INPUT INTO LOADERS ### \n",
    "\n",
    "class VocabDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_tuple, word2id_lang1, word2id_lang2):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list1, self.data_list2 = zip(*data_tuple)\n",
    "        assert (len(self.data_list1) == len(self.data_list2))\n",
    "        self.word2id1 = word2id_lang1\n",
    "        self.word2id2 = word2id_lang2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list1)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        input_sentence = [self.word2id1[c] if c in self.word2id1.keys() \n",
    "                         else UNK_IDX for c in self.data_list1[key].split()][:MAX_LENGTH-1]\n",
    "        input_sentence.append(EOS_IDX)\n",
    "                                                                   \n",
    "        output_sentence = [self.word2id2[c] if c in self.word2id2.keys() \n",
    "                          else UNK_IDX for c in self.data_list2[key].split()][:MAX_LENGTH-1]\n",
    "        output_sentence.append(EOS_IDX)\n",
    "\n",
    "        return [input_sentence, output_sentence, len(input_sentence), len(output_sentence)]\n",
    "\n",
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    length_list1 = []\n",
    "    length_list2 = []\n",
    "     \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        x1 = datum[0]\n",
    "        x2 = datum[1]\n",
    "        len1 = datum[2]\n",
    "        len2 = datum[3]\n",
    "        \n",
    "        length_list1.append(len1)\n",
    "        length_list2.append(len2)\n",
    "        #Pad first sentences\n",
    "        padded_vec1 = np.pad(np.array(x1),\n",
    "                                pad_width=((0,MAX_LENGTH-len1)),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list1.append(padded_vec1)\n",
    "        \n",
    "        #Pad second sentences\n",
    "        padded_vec2 = np.pad(np.array(x2),\n",
    "                        pad_width=((0,MAX_LENGTH-len2)),\n",
    "                        mode=\"constant\", constant_values=0)\n",
    "        data_list2.append(padded_vec2)\n",
    "        \n",
    "    data_list1 = np.array(data_list1)\n",
    "    data_list2 = np.array(data_list2)\n",
    "    length_list1 = np.array(length_list1)\n",
    "    lenth_list2 = np.array(length_list2)\n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list1)), \n",
    "            torch.from_numpy(np.array(data_list2)),\n",
    "            torch.LongTensor(length_list1), \n",
    "            torch.LongTensor(length_list2)]\n",
    "\n",
    "### MODELS ###\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, emb_weights, dropout=0):\n",
    "        '''Bidirectional RNN'''\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        weight_size = emb_weights.size()[1]\n",
    "        \n",
    "        # Embedding input: max_length x batch_size\n",
    "        # Embedding output: max_length x batch_size x hidden size\n",
    "        self.embedding = nn.Embedding(vocab_size, weight_size, padding_idx=0).from_pretrained(emb_weights, \n",
    "                                                                freeze=True).to(device) #vocab size x hidden size\n",
    "        # Input: (max_length x batch_size x hidden_size)\n",
    "        # Output: hidden - 2 x batch_size x hidden_size\n",
    "        # Output: outputs max_length x batch_size x hidden_size*2\n",
    "        self.gru = nn.GRU(weight_size, hidden_size, dropout=self.dropout, bidirectional=False)\n",
    "\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        #outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden\n",
    "    \n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, emb_weights):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        weight_size = emb_weights.size()[1]\n",
    "        self.embedding = nn.Embedding(vocab_size, weight_size, padding_idx=0).from_pretrained(emb_weights, \n",
    "                                                                freeze=True).to(device)\n",
    "        \n",
    "        self.gru1 = nn.GRU(weight_size, hidden_size)\n",
    "        self.gru2 = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        embedded = self.embedding(inp).unsqueeze(0) #so that we have 1 x batch x hidden\n",
    "        output, hidden = self.gru1(embedded, hidden)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru2(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    \n",
    "### TRAIN THE MODEL ###\n",
    "\n",
    "def train(inputs, input_lengths, targets, target_lengths, \n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH,\n",
    "         teacher_forcing_ratio=0.5, clip = 50):\n",
    "    '''Train one batch'''\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 #\n",
    "    batch_size = inputs.size()[1]\n",
    "    max_targ_len = max_length\n",
    "\n",
    "    # Run sentences through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(inputs, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([SOS_IDX] * batch_size).to(device)\n",
    "    decoder_hidden = encoder_hidden#[:1] \n",
    "    \n",
    "    #randomly use teacher forcing or not\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Run through decoder one time step at a time \n",
    "    all_decoder_outputs = Variable(torch.zeros(max_targ_len, batch_size, output_lang.n_words)).to(device)\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_targ_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "            decoder_input = targets[t]\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_targ_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "\n",
    "    loss = masked_cross_entropy(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    targets.transpose(0, 1).contiguous(),\n",
    "    target_lengths)\n",
    "        \n",
    "    loss.backward()\n",
    "        \n",
    "    # Clip gradient norms to prevent gradient explosion\n",
    "    clip = clip\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    \n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item\n",
    "\n",
    "\n",
    "def trainIters(loader, encoder, decoder, encoder_optimizer, decoder_optimizer, n_iters, print_every=1000, \n",
    "               validate_every = 100,\n",
    "               plot_every=100, learning_rate=0.01,\n",
    "              teacher_forcing_ratio=0.5):\n",
    "    '''Train batches'''\n",
    "    \n",
    "    start = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    plot_losses = []\n",
    "\n",
    "    counter = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while epoch < n_iters:\n",
    "        epoch += 1\n",
    "\n",
    "        # Get training data for this cycle\n",
    "        for i, (source, target, lengths1, lengths2) in enumerate(loader):\n",
    "            counter += 1\n",
    "            \n",
    "            # Run the train function\n",
    "            loss = train(\n",
    "                source.long().transpose(0,1).to(device), lengths1, target.long().transpose(0,1).to(device), lengths2,\n",
    "                encoder, decoder,\n",
    "                encoder_optimizer, decoder_optimizer, criterion, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "\n",
    "            # Keep track of loss\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if counter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_iters), epoch, \n",
    "                                                       epoch / n_iters * 100, print_loss_avg)\n",
    "                print(print_summary)\n",
    "\n",
    "            if counter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "                # Save models\n",
    "                torch.save(encoder.state_dict(), en_loc  + '/' +'encoder_embed4.pt')\n",
    "                torch.save(decoder.state_dict(), en_loc  + '/' +'decoder_embed4.pt')\n",
    "                torch.save(encoder_optimizer.state_dict(), en_loc + '/' + 'encoder_opt4.pt')\n",
    "                torch.save(decoder_optimizer.state_dict(), en_loc + '/' + 'decoder_opt4.pt')\n",
    "                \n",
    "                with open(en_loc + '/loss_embed.p', 'wb') as fp:\n",
    "                    pickle.dump(plot_losses, fp)\n",
    "                \n",
    "            if counter % validate_every == 0:\n",
    "                bleu = validate(encoder, decoder, val_loader)\n",
    "                print('Bleu ', bleu)\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses\n",
    "\n",
    "\n",
    "### EVALUATING RESULTS ###\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, input_lengths, translated, search='greedy', max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Function that evaluates translation.\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence.transpose(0,1)\n",
    "        input_length = sentence.size()[0]\n",
    "        \n",
    "        # encode the source lanugage\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor, input_lengths, None)\n",
    "\n",
    "        decoder_input = torch.tensor([SOS_IDX], device=device)  #\n",
    "        decoder_hidden = encoder_hidden#[:1]  Use last (forward) hidden state from encoder \n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            \n",
    "            # GREEDY\n",
    "            topv, topi = decoder_output.data.topk(1) \n",
    "\n",
    "            if topi.item() == EOS_IDX:\n",
    "                #decoded_words.append('<EOS>')\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                if topi.item() not in [SOS_IDX, EOS_IDX, UNK_IDX, PAD_IDX]:\n",
    "                    decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi[0].detach()\n",
    "        \n",
    "        translation = []\n",
    "        for i in translated: #expected translation\n",
    "            if i.item() not in [SOS_IDX, EOS_IDX, UNK_IDX, PAD_IDX]:\n",
    "                translation.append(output_lang.index2word[i.item()])\n",
    "\n",
    "        return decoded_words, translation\n",
    "    \n",
    "    \n",
    "def evaluate_batch(loader, encoder, decoder):\n",
    "    \n",
    "    decoded_sentences = []\n",
    "    actual_sentences = []\n",
    "    \n",
    "    for i, (source, target, lengths1, lengths2) in enumerate(loader):\n",
    "        #iterate over batch\n",
    "        \n",
    "        for n in range(len(source)):\n",
    "            # Go sentence by sentence\n",
    "            \n",
    "            decoded, actual = evaluate(encoder, decoder, source[n].unsqueeze(0).to(device), lengths1[n], target[n])\n",
    "            decoded_sentences.append(decoded)\n",
    "            actual_sentences.append(actual)\n",
    "            \n",
    "    return decoded_sentences, actual_sentences\n",
    "\n",
    "\n",
    "def evaluate_bleu(translation_list, reference_list):\n",
    "    '''Compute BLEU score''' \n",
    "    translations = [' '.join(v) for v in translation_list]\n",
    "    references = [' '.join(v) for v in reference_list]\n",
    "    \n",
    "    return corpus_bleu(translations, [references])\n",
    "\n",
    "\n",
    "def validate(encoder, decoder, val_loader):\n",
    "    '''Periodically evaluate results'''\n",
    "    decoded_sentences, actual_sentences = evaluate_batch(val_loader, encoder, decoder)\n",
    "    bleu = evaluate_bleu(decoded_sentences, actual_sentences)\n",
    "    \n",
    "    return bleu\n",
    "\n",
    "\n",
    "#Plot results\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))    \n",
    "\n",
    "### PREPROCESS FASTEXT EMBEDDINGS ###\n",
    "\n",
    "def embed_to_tensor(embeddings):\n",
    "    y=np.array([np.array(list(xi)) for xi in embeddings.values()])\n",
    "    padding = np.zeros((1, y.shape[1]))\n",
    "    unknown = np.random.rand(1, y.shape[1]) # to account for Padding and Unknown\n",
    "    sos = np.random.rand(1, y.shape[1])\n",
    "    eos = np.random.rand(1, y.shape[1])\n",
    "    full_size = np.concatenate([padding, sos, eos, unknown, y], axis=0)\n",
    "    emb_weights = torch.from_numpy(full_size)\n",
    "    \n",
    "    return emb_weights   \n",
    "\n",
    "\n",
    "def load_embedding(fname, max_count=None):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    counter=0\n",
    "    for line in fin:\n",
    "        counter+=1\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "        if counter==max_count:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of files\n",
    "en_loc = 'iwslt-vi-en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIrst, load the pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### VIETNAMESE\n",
    "#Read in pretrained embedding vectors \n",
    "embeddings_map_vi = load_embedding(en_loc + '/cc.vi.300.vec', max_count=50000)\n",
    "\n",
    "#Convert embedding values to lists\n",
    "embeddings_vi = {}\n",
    "\n",
    "for key, value in embeddings_map_vi.items():\n",
    "    embeddings_vi[key] = list(value)\n",
    "    \n",
    "### ENGLISH    \n",
    "#Read in pretrained embedding vectors\n",
    "embeddings_map_en = load_embedding(en_loc + '/wiki-news-300d-1M.vec', max_count=50000)\n",
    "\n",
    "#Convert embedding values to lists\n",
    "embeddings_en = {}\n",
    "\n",
    "for key, value in embeddings_map_en.items():\n",
    "    embeddings_en[key] = list(value)\n",
    "    \n",
    "embed_vi_tensor = embed_to_tensor(embeddings_vi).float()\n",
    "embed_en_tensor = embed_to_tensor(embeddings_en).float()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and process training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 108159 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 50004\n",
      "en 50004\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(en_loc+'/train.tok.vi', en_loc+'/train.tok.en', \n",
    "                                             embedding_in = embeddings_vi,\n",
    "                                             embedding_out = embeddings_en, num_sent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 995 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 50004\n",
      "en 50004\n"
     ]
    }
   ],
   "source": [
    "input_lang_v, output_lang_v, pairs_v = prepareData(en_loc+'/dev.tok.vi', en_loc+'/dev.tok.en', \n",
    "                                                   embedding_in = embeddings_vi,\n",
    "                                                   embedding_out = embeddings_en,\n",
    "                                                   num_sent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Khoa_học đằng_sau một tiêu_đề về khí_hậu',\n",
       "  'Rachel Pike  The science behind a climate headline'),\n",
       " ('Tôi muốn cho các bạn biết về sự to_lớn của những nỗ_lực khoa_học đã góp_phần làm_nên các dòng tít bạn thường thấy trên báo',\n",
       "  'I d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper'),\n",
       " ('Có những dòng trông như thế_này khi bàn về biến_đổi khí_hậu  và như thế_này khi nói về chất_lượng không_khí hay khói bụi',\n",
       "  'Headlines that look like this when they have to do with climate change  and headlines that look like this when they have to do with air quality or smog'),\n",
       " ('Cả hai đều là một nhánh của cùng một lĩnh_vực trong ngành khoa_học khí_quyển',\n",
       "  'They are both two branches of the same field of atmospheric science'),\n",
       " ('Các tiêu_đề gần_đây trông như thế_này khi Ban Điều_hành Biến_đổi khí_hậu Liên_chính_phủ  gọi tắt là IPCC đưa ra_bài nghiên_cứu của họ về hệ_thống khí_quyển',\n",
       "  'Recently the headlines looked like this when the Intergovernmental Panel on Climate Change  or IPCC  put out their report on the state of understanding of the atmospheric system')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input\n",
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size=1000\n",
    "learning_rate=0.001\n",
    "\n",
    "encoder = EncoderRNN(hidden_size = hidden_size, vocab_size = input_lang.n_words,\n",
    "                    emb_weights = embed_vi_tensor).to(device)\n",
    "decoder = DecoderRNN(hidden_size = hidden_size, vocab_size = output_lang.n_words,\n",
    "                    emb_weights = embed_en_tensor).to(device)\n",
    "#encoder.load_state_dict(torch.load(en_loc + '/encoder_embed2.pt'))\n",
    "#decoder.load_state_dict(torch.load(en_loc + '/decoder_embed2.pt'))\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "#encoder_optimizer.load_state_dict(torch.load(en_loc + '/encoder_opt.pt'))\n",
    "#decoder_optimizer.load_state_dict(torch.load(en_loc + '/decoder_opt.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "\n",
    "train_dataset = VocabDataset(pairs, input_lang.word2index, output_lang.word2index)\n",
    "# 1 batch input dimension: num_sentences x max sentence length\n",
    "# 1 batch: source_sentences, target_sentences, source_lengths, target_lengths\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = VocabDataset(pairs_v, input_lang.word2index, output_lang.word2index)\n",
    "# 1 batch input dimension: num_sentences x max sentence length\n",
    "# 1 batch: source_sentences, target_sentences, source_lengths, target_lengths\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 47s (- 7m 5s) (1 10%) 7.3854\n",
      "1m 34s (- 14m 13s) (1 10%) 6.7155\n",
      "2m 24s (- 21m 44s) (1 10%) 6.4161\n",
      "3m 12s (- 28m 54s) (1 10%) 6.1060\n",
      "4m 2s (- 36m 26s) (1 10%) 5.9020\n",
      "4m 50s (- 43m 35s) (1 10%) 5.6992\n",
      "5m 40s (- 51m 6s) (1 10%) 5.5956\n",
      "6m 28s (- 58m 13s) (1 10%) 5.4599\n",
      "7m 18s (- 65m 46s) (1 10%) 5.4437\n",
      "8m 6s (- 72m 54s) (1 10%) 5.3996\n",
      "Bleu  0.7729285000024209\n",
      "9m 41s (- 87m 17s) (1 10%) 5.2812\n",
      "10m 29s (- 94m 26s) (1 10%) 5.2942\n",
      "11m 19s (- 101m 58s) (1 10%) 5.2537\n",
      "12m 7s (- 109m 6s) (1 10%) 5.1162\n",
      "12m 57s (- 116m 39s) (1 10%) 5.1108\n",
      "13m 45s (- 123m 48s) (1 10%) 5.0495\n",
      "14m 35s (- 131m 21s) (1 10%) 5.0777\n",
      "15m 23s (- 138m 30s) (1 10%) 5.0313\n",
      "16m 13s (- 146m 3s) (1 10%) 5.0515\n",
      "17m 1s (- 153m 13s) (1 10%) 4.9099\n",
      "Bleu  1.1609990790113085\n",
      "18m 43s (- 168m 34s) (1 10%) 4.9582\n",
      "19m 31s (- 175m 43s) (1 10%) 4.8895\n",
      "20m 22s (- 183m 18s) (1 10%) 4.8620\n",
      "21m 9s (- 190m 28s) (1 10%) 4.8372\n",
      "22m 0s (- 198m 5s) (1 10%) 4.8636\n",
      "22m 48s (- 205m 15s) (1 10%) 4.8290\n",
      "23m 38s (- 212m 50s) (1 10%) 4.7478\n",
      "24m 26s (- 220m 0s) (1 10%) 4.7063\n",
      "25m 17s (- 227m 37s) (1 10%) 4.7221\n",
      "26m 5s (- 234m 46s) (1 10%) 4.7198\n",
      "Bleu  1.3302890660831879\n",
      "27m 44s (- 249m 38s) (1 10%) 4.7162\n",
      "28m 32s (- 256m 49s) (1 10%) 4.6476\n",
      "29m 23s (- 264m 27s) (1 10%) 4.6595\n",
      "30m 10s (- 271m 37s) (1 10%) 4.6409\n",
      "31m 1s (- 279m 11s) (1 10%) 4.6280\n",
      "31m 48s (- 286m 20s) (1 10%) 4.6133\n",
      "32m 39s (- 293m 54s) (1 10%) 4.5725\n",
      "33m 27s (- 301m 3s) (1 10%) 4.5682\n",
      "34m 17s (- 308m 37s) (1 10%) 4.5535\n",
      "35m 5s (- 315m 45s) (1 10%) 4.5928\n",
      "Bleu  2.005351525143726\n",
      "36m 41s (- 330m 16s) (1 10%) 4.5229\n",
      "37m 29s (- 337m 24s) (1 10%) 4.4905\n",
      "38m 19s (- 344m 59s) (1 10%) 4.5307\n",
      "39m 7s (- 352m 9s) (1 10%) 4.5140\n",
      "39m 58s (- 359m 46s) (1 10%) 4.4985\n",
      "40m 46s (- 366m 55s) (1 10%) 4.4978\n",
      "41m 36s (- 374m 31s) (1 10%) 4.4732\n",
      "42m 24s (- 381m 42s) (1 10%) 4.3945\n",
      "Bleu  2.1243357745678426\n",
      "45m 41s (- 411m 11s) (1 10%) 4.3545\n",
      "46m 28s (- 418m 20s) (1 10%) 4.3737\n",
      "47m 19s (- 425m 56s) (1 10%) 4.3866\n",
      "48m 7s (- 433m 5s) (1 10%) 4.3327\n",
      "48m 57s (- 440m 41s) (1 10%) 4.3505\n",
      "49m 45s (- 447m 49s) (1 10%) 4.3368\n",
      "50m 36s (- 455m 24s) (1 10%) 4.3498\n",
      "51m 23s (- 462m 34s) (1 10%) 4.3194\n",
      "52m 14s (- 470m 11s) (1 10%) 4.2976\n",
      "53m 2s (- 477m 21s) (1 10%) 4.3106\n",
      "Bleu  2.475373435960482\n",
      "54m 43s (- 492m 29s) (1 10%) 4.3416\n",
      "55m 31s (- 499m 39s) (1 10%) 4.2996\n",
      "56m 21s (- 507m 14s) (1 10%) 4.3025\n",
      "57m 9s (- 514m 22s) (1 10%) 4.3245\n",
      "57m 59s (- 521m 55s) (1 10%) 4.2860\n",
      "58m 47s (- 529m 3s) (1 10%) 4.2781\n",
      "59m 37s (- 536m 37s) (1 10%) 4.2582\n",
      "60m 25s (- 241m 40s) (2 20%) 4.0891\n",
      "61m 15s (- 245m 2s) (2 20%) 3.8769\n",
      "62m 3s (- 248m 13s) (2 20%) 3.9147\n",
      "Bleu  2.8045374887810164\n",
      "63m 37s (- 254m 28s) (2 20%) 3.9331\n",
      "64m 24s (- 257m 39s) (2 20%) 3.8485\n",
      "65m 15s (- 261m 1s) (2 20%) 3.8822\n",
      "66m 3s (- 264m 12s) (2 20%) 3.8414\n",
      "66m 53s (- 267m 33s) (2 20%) 3.9070\n",
      "67m 41s (- 270m 44s) (2 20%) 3.8801\n",
      "68m 31s (- 274m 6s) (2 20%) 3.9056\n",
      "69m 19s (- 277m 17s) (2 20%) 3.8994\n",
      "70m 10s (- 280m 40s) (2 20%) 3.9192\n",
      "70m 57s (- 283m 50s) (2 20%) 3.8329\n",
      "Bleu  3.3085947529284483\n",
      "72m 35s (- 290m 20s) (2 20%) 3.8945\n",
      "73m 22s (- 293m 31s) (2 20%) 3.8646\n",
      "74m 13s (- 296m 53s) (2 20%) 3.9232\n",
      "75m 1s (- 300m 5s) (2 20%) 3.8662\n",
      "75m 52s (- 303m 28s) (2 20%) 3.8529\n",
      "76m 39s (- 306m 39s) (2 20%) 3.8826\n",
      "77m 30s (- 310m 2s) (2 20%) 3.8430\n",
      "78m 18s (- 313m 13s) (2 20%) 3.8960\n",
      "79m 8s (- 316m 35s) (2 20%) 3.8577\n",
      "79m 56s (- 319m 46s) (2 20%) 3.8760\n",
      "Bleu  2.9872196285119776\n",
      "81m 37s (- 326m 28s) (2 20%) 3.8871\n",
      "82m 24s (- 329m 38s) (2 20%) 3.8503\n",
      "83m 15s (- 333m 1s) (2 20%) 3.8246\n",
      "84m 3s (- 336m 12s) (2 20%) 3.8400\n",
      "84m 53s (- 339m 34s) (2 20%) 3.8485\n",
      "85m 41s (- 342m 46s) (2 20%) 3.8426\n",
      "86m 31s (- 346m 7s) (2 20%) 3.8392\n",
      "87m 19s (- 349m 18s) (2 20%) 3.8583\n",
      "88m 10s (- 352m 41s) (2 20%) 3.8680\n",
      "88m 58s (- 355m 52s) (2 20%) 3.8043\n",
      "Bleu  3.295303765626937\n",
      "90m 32s (- 362m 11s) (2 20%) 3.8200\n",
      "91m 20s (- 365m 23s) (2 20%) 3.8435\n",
      "92m 11s (- 368m 46s) (2 20%) 3.8604\n",
      "92m 59s (- 371m 57s) (2 20%) 3.8247\n",
      "93m 50s (- 375m 20s) (2 20%) 3.8909\n",
      "94m 37s (- 378m 31s) (2 20%) 3.8443\n",
      "95m 28s (- 381m 55s) (2 20%) 3.8667\n",
      "96m 16s (- 385m 6s) (2 20%) 3.8373\n",
      "97m 7s (- 388m 28s) (2 20%) 3.8047\n",
      "97m 54s (- 391m 39s) (2 20%) 3.8362\n",
      "Bleu  3.893500711972095\n",
      "99m 33s (- 398m 12s) (2 20%) 3.7781\n",
      "100m 20s (- 401m 23s) (2 20%) 3.7934\n",
      "101m 11s (- 404m 46s) (2 20%) 3.8040\n",
      "101m 59s (- 407m 57s) (2 20%) 3.7733\n",
      "102m 50s (- 411m 20s) (2 20%) 3.8289\n",
      "103m 38s (- 414m 32s) (2 20%) 3.8155\n",
      "104m 28s (- 417m 54s) (2 20%) 3.7896\n",
      "105m 16s (- 421m 5s) (2 20%) 3.7710\n",
      "106m 6s (- 424m 27s) (2 20%) 3.8302\n",
      "106m 54s (- 427m 37s) (2 20%) 3.7414\n",
      "Bleu  3.629146646464249\n",
      "108m 28s (- 433m 53s) (2 20%) 3.7777\n",
      "109m 16s (- 437m 4s) (2 20%) 3.8026\n",
      "110m 6s (- 440m 24s) (2 20%) 3.7336\n",
      "110m 53s (- 443m 35s) (2 20%) 3.7931\n",
      "111m 44s (- 446m 58s) (2 20%) 3.7875\n",
      "112m 32s (- 450m 9s) (2 20%) 3.7614\n",
      "113m 22s (- 453m 31s) (2 20%) 3.7780\n",
      "114m 10s (- 456m 41s) (2 20%) 3.7854\n",
      "115m 1s (- 460m 4s) (2 20%) 3.7748\n",
      "115m 48s (- 463m 15s) (2 20%) 3.7751\n",
      "Bleu  3.8061713352823774\n",
      "117m 30s (- 470m 1s) (2 20%) 3.7721\n",
      "118m 18s (- 473m 13s) (2 20%) 3.7427\n",
      "119m 8s (- 476m 35s) (2 20%) 3.7753\n",
      "119m 56s (- 479m 46s) (2 20%) 3.7516\n",
      "120m 47s (- 483m 8s) (2 20%) 3.7872\n",
      "121m 34s (- 283m 41s) (3 30%) 3.2389\n",
      "122m 25s (- 285m 39s) (3 30%) 3.1154\n",
      "123m 13s (- 287m 31s) (3 30%) 3.1305\n",
      "124m 4s (- 289m 29s) (3 30%) 3.1335\n",
      "124m 51s (- 291m 21s) (3 30%) 3.1332\n",
      "Bleu  3.9285935767159916\n",
      "126m 29s (- 295m 9s) (3 30%) 3.1284\n",
      "127m 17s (- 297m 1s) (3 30%) 3.1502\n",
      "128m 8s (- 299m 0s) (3 30%) 3.1306\n",
      "128m 56s (- 300m 52s) (3 30%) 3.1851\n",
      "129m 47s (- 302m 50s) (3 30%) 3.1827\n",
      "130m 35s (- 304m 41s) (3 30%) 3.1965\n",
      "131m 25s (- 306m 39s) (3 30%) 3.1696\n",
      "132m 13s (- 308m 30s) (3 30%) 3.1726\n",
      "133m 3s (- 310m 28s) (3 30%) 3.2191\n",
      "133m 51s (- 312m 19s) (3 30%) 3.2225\n",
      "Bleu  3.9884239035462703\n",
      "135m 25s (- 316m 0s) (3 30%) 3.2093\n",
      "136m 13s (- 317m 51s) (3 30%) 3.2194\n",
      "137m 4s (- 319m 50s) (3 30%) 3.2027\n",
      "137m 52s (- 321m 41s) (3 30%) 3.2184\n",
      "138m 43s (- 323m 40s) (3 30%) 3.1998\n",
      "139m 30s (- 325m 31s) (3 30%) 3.2610\n",
      "140m 21s (- 327m 30s) (3 30%) 3.2122\n",
      "141m 9s (- 329m 21s) (3 30%) 3.2276\n",
      "142m 0s (- 331m 20s) (3 30%) 3.2368\n",
      "142m 48s (- 333m 12s) (3 30%) 3.2367\n",
      "Bleu  4.413231033123548\n",
      "144m 23s (- 336m 55s) (3 30%) 3.2677\n",
      "145m 11s (- 338m 47s) (3 30%) 3.2420\n",
      "146m 2s (- 340m 45s) (3 30%) 3.2494\n",
      "146m 50s (- 342m 37s) (3 30%) 3.2316\n",
      "147m 40s (- 344m 35s) (3 30%) 3.2405\n",
      "148m 28s (- 346m 26s) (3 30%) 3.2205\n",
      "149m 19s (- 348m 24s) (3 30%) 3.2529\n",
      "150m 6s (- 350m 15s) (3 30%) 3.2427\n",
      "150m 57s (- 352m 14s) (3 30%) 3.1859\n",
      "151m 45s (- 354m 6s) (3 30%) 3.2762\n",
      "Bleu  4.183011608050553\n",
      "153m 22s (- 357m 51s) (3 30%) 3.2630\n",
      "154m 9s (- 359m 43s) (3 30%) 3.2981\n",
      "155m 0s (- 361m 41s) (3 30%) 3.2736\n",
      "155m 48s (- 363m 32s) (3 30%) 3.2615\n",
      "156m 38s (- 365m 30s) (3 30%) 3.2675\n",
      "157m 26s (- 367m 21s) (3 30%) 3.2813\n",
      "158m 16s (- 369m 19s) (3 30%) 3.2863\n",
      "159m 4s (- 371m 10s) (3 30%) 3.2842\n",
      "159m 55s (- 373m 8s) (3 30%) 3.2844\n",
      "160m 42s (- 374m 59s) (3 30%) 3.2631\n",
      "Bleu  4.5260906814642565\n",
      "162m 18s (- 378m 42s) (3 30%) 3.2785\n",
      "163m 5s (- 380m 33s) (3 30%) 3.3319\n",
      "163m 56s (- 382m 32s) (3 30%) 3.3246\n",
      "164m 44s (- 384m 23s) (3 30%) 3.3072\n",
      "165m 34s (- 386m 20s) (3 30%) 3.2656\n",
      "166m 22s (- 388m 12s) (3 30%) 3.2972\n",
      "167m 13s (- 390m 10s) (3 30%) 3.3218\n",
      "168m 0s (- 392m 2s) (3 30%) 3.2745\n",
      "168m 51s (- 394m 0s) (3 30%) 3.3255\n",
      "169m 39s (- 395m 52s) (3 30%) 3.2918\n",
      "Bleu  3.9395037669202444\n",
      "171m 15s (- 399m 35s) (3 30%) 3.2734\n",
      "172m 3s (- 401m 27s) (3 30%) 3.3263\n",
      "172m 53s (- 403m 25s) (3 30%) 3.3126\n",
      "173m 41s (- 405m 17s) (3 30%) 3.2709\n",
      "174m 32s (- 407m 15s) (3 30%) 3.2973\n",
      "175m 20s (- 409m 7s) (3 30%) 3.2884\n",
      "176m 10s (- 411m 4s) (3 30%) 3.3085\n",
      "176m 58s (- 412m 55s) (3 30%) 3.2767\n",
      "177m 48s (- 414m 53s) (3 30%) 3.2679\n",
      "178m 36s (- 416m 45s) (3 30%) 3.2922\n",
      "Bleu  4.5343779286712955\n",
      "180m 14s (- 420m 34s) (3 30%) 3.3259\n",
      "181m 2s (- 422m 26s) (3 30%) 3.2988\n",
      "181m 52s (- 272m 49s) (4 40%) 3.1473\n",
      "182m 40s (- 274m 1s) (4 40%) 2.5500\n",
      "183m 30s (- 275m 15s) (4 40%) 2.5402\n",
      "184m 17s (- 276m 26s) (4 40%) 2.5467\n",
      "185m 8s (- 277m 42s) (4 40%) 2.5935\n",
      "185m 56s (- 278m 54s) (4 40%) 2.5604\n",
      "186m 46s (- 280m 10s) (4 40%) 2.5642\n",
      "187m 34s (- 281m 22s) (4 40%) 2.5747\n",
      "Bleu  4.4208535402590226\n",
      "189m 10s (- 283m 45s) (4 40%) 2.5650\n",
      "189m 58s (- 284m 57s) (4 40%) 2.6376\n",
      "190m 49s (- 286m 13s) (4 40%) 2.6173\n",
      "191m 36s (- 287m 25s) (4 40%) 2.6712\n",
      "192m 27s (- 288m 41s) (4 40%) 2.6369\n",
      "193m 15s (- 289m 53s) (4 40%) 2.6533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194m 6s (- 291m 9s) (4 40%) 2.6568\n",
      "194m 53s (- 292m 20s) (4 40%) 2.6641\n",
      "195m 44s (- 293m 36s) (4 40%) 2.6555\n",
      "196m 32s (- 294m 48s) (4 40%) 2.6923\n",
      "Bleu  4.341323540532607\n",
      "198m 8s (- 297m 13s) (4 40%) 2.6819\n",
      "198m 56s (- 298m 24s) (4 40%) 2.7034\n",
      "199m 47s (- 299m 40s) (4 40%) 2.6975\n",
      "200m 35s (- 300m 52s) (4 40%) 2.6886\n",
      "201m 25s (- 302m 8s) (4 40%) 2.6792\n",
      "202m 13s (- 303m 20s) (4 40%) 2.7079\n",
      "203m 4s (- 304m 36s) (4 40%) 2.7645\n",
      "203m 52s (- 305m 48s) (4 40%) 2.7244\n",
      "204m 42s (- 307m 4s) (4 40%) 2.7307\n",
      "205m 30s (- 308m 16s) (4 40%) 2.7679\n",
      "Bleu  4.384203142826175\n",
      "207m 6s (- 310m 39s) (4 40%) 2.7463\n",
      "207m 54s (- 311m 51s) (4 40%) 2.7770\n",
      "208m 44s (- 313m 7s) (4 40%) 2.7877\n",
      "209m 32s (- 314m 18s) (4 40%) 2.7751\n",
      "210m 22s (- 315m 33s) (4 40%) 2.7506\n",
      "211m 9s (- 316m 44s) (4 40%) 2.7452\n",
      "212m 0s (- 318m 0s) (4 40%) 2.7641\n",
      "212m 48s (- 319m 12s) (4 40%) 2.7389\n",
      "213m 39s (- 320m 28s) (4 40%) 2.7942\n",
      "214m 26s (- 321m 40s) (4 40%) 2.7992\n",
      "Bleu  4.180153808351634\n",
      "216m 3s (- 324m 5s) (4 40%) 2.7764\n",
      "216m 51s (- 325m 17s) (4 40%) 2.7776\n",
      "217m 42s (- 326m 33s) (4 40%) 2.7969\n",
      "218m 29s (- 327m 44s) (4 40%) 2.7991\n",
      "219m 19s (- 328m 59s) (4 40%) 2.8161\n",
      "220m 7s (- 330m 10s) (4 40%) 2.8459\n",
      "220m 57s (- 331m 26s) (4 40%) 2.8280\n",
      "221m 45s (- 332m 38s) (4 40%) 2.8025\n",
      "222m 35s (- 333m 53s) (4 40%) 2.8111\n",
      "223m 23s (- 335m 4s) (4 40%) 2.8241\n",
      "Bleu  4.558343040802283\n",
      "225m 0s (- 337m 31s) (4 40%) 2.8497\n",
      "225m 48s (- 338m 42s) (4 40%) 2.8826\n",
      "226m 39s (- 339m 58s) (4 40%) 2.8334\n",
      "227m 27s (- 341m 10s) (4 40%) 2.8575\n",
      "228m 17s (- 342m 26s) (4 40%) 2.8449\n",
      "229m 5s (- 343m 38s) (4 40%) 2.8838\n",
      "229m 56s (- 344m 54s) (4 40%) 2.8575\n",
      "230m 43s (- 346m 5s) (4 40%) 2.8751\n",
      "231m 34s (- 347m 21s) (4 40%) 2.8597\n",
      "232m 22s (- 348m 33s) (4 40%) 2.8865\n",
      "Bleu  4.570641205050632\n",
      "233m 59s (- 350m 58s) (4 40%) 2.8730\n",
      "234m 46s (- 352m 10s) (4 40%) 2.8691\n",
      "235m 37s (- 353m 26s) (4 40%) 2.8552\n",
      "236m 24s (- 354m 37s) (4 40%) 2.8733\n",
      "237m 15s (- 355m 53s) (4 40%) 2.9058\n",
      "238m 3s (- 357m 4s) (4 40%) 2.8507\n",
      "238m 53s (- 358m 19s) (4 40%) 2.8756\n",
      "239m 41s (- 359m 31s) (4 40%) 2.8449\n",
      "240m 31s (- 360m 47s) (4 40%) 2.8727\n",
      "241m 19s (- 361m 59s) (4 40%) 2.8794\n",
      "Bleu  4.09276518123555\n",
      "242m 54s (- 242m 54s) (5 50%) 2.4431\n",
      "243m 42s (- 243m 42s) (5 50%) 2.1505\n",
      "244m 32s (- 244m 32s) (5 50%) 2.1533\n",
      "245m 20s (- 245m 20s) (5 50%) 2.1374\n",
      "246m 11s (- 246m 11s) (5 50%) 2.1783\n",
      "246m 59s (- 246m 59s) (5 50%) 2.1833\n",
      "247m 49s (- 247m 49s) (5 50%) 2.1826\n",
      "248m 37s (- 248m 37s) (5 50%) 2.2159\n",
      "249m 28s (- 249m 28s) (5 50%) 2.1889\n",
      "250m 15s (- 250m 15s) (5 50%) 2.2129\n",
      "Bleu  3.754166445666492\n",
      "251m 54s (- 251m 54s) (5 50%) 2.2619\n",
      "252m 41s (- 252m 41s) (5 50%) 2.1976\n",
      "253m 32s (- 253m 32s) (5 50%) 2.2420\n",
      "254m 20s (- 254m 20s) (5 50%) 2.3041\n",
      "255m 10s (- 255m 10s) (5 50%) 2.2801\n",
      "255m 58s (- 255m 58s) (5 50%) 2.2784\n",
      "256m 49s (- 256m 49s) (5 50%) 2.2888\n",
      "257m 36s (- 257m 36s) (5 50%) 2.2991\n",
      "258m 27s (- 258m 27s) (5 50%) 2.2906\n",
      "259m 15s (- 259m 15s) (5 50%) 2.2880\n",
      "Bleu  4.086974867808438\n",
      "260m 52s (- 260m 52s) (5 50%) 2.3233\n",
      "261m 40s (- 261m 40s) (5 50%) 2.3019\n",
      "262m 30s (- 262m 30s) (5 50%) 2.3090\n",
      "263m 17s (- 263m 17s) (5 50%) 2.3331\n",
      "264m 8s (- 264m 8s) (5 50%) 2.3529\n",
      "264m 56s (- 264m 56s) (5 50%) 2.3580\n",
      "265m 46s (- 265m 46s) (5 50%) 2.3824\n",
      "266m 34s (- 266m 34s) (5 50%) 2.3816\n",
      "267m 25s (- 267m 25s) (5 50%) 2.3701\n",
      "268m 13s (- 268m 13s) (5 50%) 2.3974\n",
      "Bleu  3.8381937226902627\n",
      "269m 50s (- 269m 50s) (5 50%) 2.4057\n",
      "270m 37s (- 270m 37s) (5 50%) 2.3842\n",
      "271m 28s (- 271m 28s) (5 50%) 2.4098\n",
      "272m 16s (- 272m 16s) (5 50%) 2.4213\n",
      "273m 6s (- 273m 6s) (5 50%) 2.3993\n",
      "273m 54s (- 273m 54s) (5 50%) 2.4469\n",
      "274m 45s (- 274m 45s) (5 50%) 2.3948\n",
      "275m 32s (- 275m 32s) (5 50%) 2.4293\n",
      "276m 23s (- 276m 23s) (5 50%) 2.4281\n",
      "277m 11s (- 277m 11s) (5 50%) 2.4708\n",
      "Bleu  4.066707124843137\n",
      "278m 48s (- 278m 48s) (5 50%) 2.4358\n",
      "279m 35s (- 279m 35s) (5 50%) 2.4485\n",
      "280m 26s (- 280m 26s) (5 50%) 2.4586\n",
      "281m 14s (- 281m 14s) (5 50%) 2.4798\n",
      "282m 5s (- 282m 5s) (5 50%) 2.4944\n",
      "282m 52s (- 282m 52s) (5 50%) 2.4884\n",
      "283m 43s (- 283m 43s) (5 50%) 2.4978\n",
      "284m 31s (- 284m 31s) (5 50%) 2.4617\n",
      "285m 21s (- 285m 21s) (5 50%) 2.5027\n",
      "286m 9s (- 286m 9s) (5 50%) 2.5239\n",
      "Bleu  4.200897917319877\n",
      "287m 42s (- 287m 42s) (5 50%) 2.4934\n",
      "288m 29s (- 288m 29s) (5 50%) 2.4973\n",
      "289m 20s (- 289m 20s) (5 50%) 2.4941\n",
      "290m 8s (- 290m 8s) (5 50%) 2.4848\n",
      "290m 59s (- 290m 59s) (5 50%) 2.4966\n",
      "291m 46s (- 291m 46s) (5 50%) 2.5088\n",
      "292m 37s (- 292m 37s) (5 50%) 2.5047\n",
      "293m 25s (- 293m 25s) (5 50%) 2.5265\n",
      "294m 15s (- 294m 15s) (5 50%) 2.5154\n",
      "295m 3s (- 295m 3s) (5 50%) 2.5457\n",
      "Bleu  4.222063283909732\n",
      "296m 41s (- 296m 41s) (5 50%) 2.5523\n",
      "297m 28s (- 297m 28s) (5 50%) 2.5295\n",
      "298m 18s (- 298m 18s) (5 50%) 2.5516\n",
      "299m 6s (- 299m 6s) (5 50%) 2.5808\n",
      "299m 57s (- 299m 57s) (5 50%) 2.5559\n",
      "300m 45s (- 300m 45s) (5 50%) 2.5552\n",
      "301m 35s (- 301m 35s) (5 50%) 2.5275\n",
      "302m 23s (- 302m 23s) (5 50%) 2.5572\n",
      "303m 14s (- 202m 9s) (6 60%) 1.9089\n",
      "304m 2s (- 202m 41s) (6 60%) 1.8686\n",
      "Bleu  4.28934139907299\n",
      "305m 37s (- 203m 45s) (6 60%) 1.8627\n",
      "306m 25s (- 204m 17s) (6 60%) 1.8898\n",
      "307m 16s (- 204m 51s) (6 60%) 1.9139\n",
      "308m 4s (- 205m 22s) (6 60%) 1.9218\n",
      "308m 54s (- 205m 56s) (6 60%) 1.9031\n",
      "309m 42s (- 206m 28s) (6 60%) 1.9267\n",
      "310m 33s (- 207m 2s) (6 60%) 1.9448\n",
      "311m 20s (- 207m 33s) (6 60%) 1.9453\n",
      "312m 11s (- 208m 7s) (6 60%) 1.9612\n",
      "312m 58s (- 208m 39s) (6 60%) 1.9629\n",
      "Bleu  4.041311728163065\n",
      "314m 35s (- 209m 43s) (6 60%) 2.0155\n",
      "315m 23s (- 210m 15s) (6 60%) 1.9849\n",
      "316m 14s (- 210m 49s) (6 60%) 1.9776\n",
      "317m 2s (- 211m 21s) (6 60%) 2.0458\n",
      "317m 53s (- 211m 55s) (6 60%) 1.9929\n",
      "318m 40s (- 212m 27s) (6 60%) 2.0490\n",
      "319m 31s (- 213m 1s) (6 60%) 2.0426\n",
      "320m 19s (- 213m 33s) (6 60%) 2.0430\n",
      "321m 10s (- 214m 7s) (6 60%) 2.0424\n",
      "321m 58s (- 214m 38s) (6 60%) 2.1122\n",
      "Bleu  3.7369969085727464\n",
      "323m 35s (- 215m 43s) (6 60%) 2.0914\n",
      "324m 23s (- 216m 15s) (6 60%) 2.0740\n",
      "325m 14s (- 216m 49s) (6 60%) 2.0734\n",
      "326m 1s (- 217m 21s) (6 60%) 2.0947\n",
      "326m 52s (- 217m 54s) (6 60%) 2.1017\n",
      "327m 40s (- 218m 26s) (6 60%) 2.0663\n",
      "328m 30s (- 219m 0s) (6 60%) 2.1184\n",
      "329m 18s (- 219m 32s) (6 60%) 2.1264\n",
      "330m 8s (- 220m 5s) (6 60%) 2.1247\n",
      "330m 56s (- 220m 37s) (6 60%) 2.1605\n",
      "Bleu  4.27787600311565\n",
      "332m 32s (- 221m 41s) (6 60%) 2.1414\n",
      "333m 19s (- 222m 13s) (6 60%) 2.1409\n",
      "334m 10s (- 222m 46s) (6 60%) 2.1694\n",
      "334m 57s (- 223m 18s) (6 60%) 2.1741\n",
      "335m 48s (- 223m 52s) (6 60%) 2.1831\n",
      "336m 35s (- 224m 23s) (6 60%) 2.1952\n",
      "337m 26s (- 224m 57s) (6 60%) 2.1948\n",
      "338m 13s (- 225m 29s) (6 60%) 2.2339\n",
      "339m 4s (- 226m 2s) (6 60%) 2.2166\n",
      "339m 51s (- 226m 34s) (6 60%) 2.1913\n",
      "Bleu  3.9553099828844793\n",
      "341m 28s (- 227m 38s) (6 60%) 2.2135\n",
      "342m 15s (- 228m 10s) (6 60%) 2.2084\n",
      "343m 6s (- 228m 44s) (6 60%) 2.2357\n",
      "343m 54s (- 229m 16s) (6 60%) 2.2110\n",
      "344m 44s (- 229m 49s) (6 60%) 2.2700\n",
      "345m 32s (- 230m 21s) (6 60%) 2.2601\n",
      "346m 22s (- 230m 54s) (6 60%) 2.2318\n",
      "347m 10s (- 231m 26s) (6 60%) 2.2498\n",
      "348m 0s (- 232m 0s) (6 60%) 2.2398\n",
      "348m 48s (- 232m 32s) (6 60%) 2.2798\n",
      "Bleu  4.1956724671613905\n",
      "350m 25s (- 233m 36s) (6 60%) 2.2484\n",
      "351m 12s (- 234m 8s) (6 60%) 2.2739\n",
      "352m 3s (- 234m 42s) (6 60%) 2.2856\n",
      "352m 51s (- 235m 14s) (6 60%) 2.2680\n",
      "353m 42s (- 235m 48s) (6 60%) 2.2914\n",
      "354m 29s (- 236m 19s) (6 60%) 2.2999\n",
      "355m 20s (- 236m 53s) (6 60%) 2.3082\n",
      "356m 8s (- 237m 25s) (6 60%) 2.2883\n",
      "356m 59s (- 237m 59s) (6 60%) 2.3033\n",
      "357m 46s (- 238m 31s) (6 60%) 2.3049\n",
      "Bleu  4.223862481817211\n",
      "359m 22s (- 239m 34s) (6 60%) 2.3316\n",
      "360m 10s (- 240m 6s) (6 60%) 2.3317\n",
      "361m 0s (- 240m 40s) (6 60%) 2.2915\n",
      "361m 48s (- 241m 12s) (6 60%) 2.3107\n",
      "362m 38s (- 241m 45s) (6 60%) 2.3094\n",
      "363m 26s (- 155m 45s) (7 70%) 2.0559\n",
      "364m 16s (- 156m 7s) (7 70%) 1.7093\n",
      "365m 4s (- 156m 27s) (7 70%) 1.6997\n",
      "365m 55s (- 156m 49s) (7 70%) 1.7167\n",
      "366m 43s (- 157m 9s) (7 70%) 1.7082\n",
      "Bleu  4.5122146766902755\n",
      "368m 19s (- 157m 51s) (7 70%) 1.7346\n",
      "369m 6s (- 158m 11s) (7 70%) 1.7331\n",
      "369m 57s (- 158m 33s) (7 70%) 1.7429\n",
      "370m 45s (- 158m 53s) (7 70%) 1.7625\n",
      "371m 36s (- 159m 15s) (7 70%) 1.7576\n",
      "372m 23s (- 159m 35s) (7 70%) 1.7906\n",
      "373m 14s (- 159m 57s) (7 70%) 1.7805\n",
      "374m 2s (- 160m 18s) (7 70%) 1.7888\n",
      "374m 53s (- 160m 39s) (7 70%) 1.7741\n",
      "375m 40s (- 161m 0s) (7 70%) 1.8334\n",
      "Bleu  4.0539958523014015\n",
      "377m 17s (- 161m 41s) (7 70%) 1.8173\n",
      "378m 5s (- 162m 2s) (7 70%) 1.8628\n",
      "378m 56s (- 162m 24s) (7 70%) 1.8500\n",
      "379m 43s (- 162m 44s) (7 70%) 1.8686\n",
      "380m 34s (- 163m 6s) (7 70%) 1.8733\n",
      "381m 22s (- 163m 26s) (7 70%) 1.8768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382m 13s (- 163m 48s) (7 70%) 1.8925\n",
      "383m 1s (- 164m 9s) (7 70%) 1.9146\n",
      "383m 52s (- 164m 30s) (7 70%) 1.9270\n",
      "384m 39s (- 164m 51s) (7 70%) 1.9222\n",
      "Bleu  4.057368929882965\n",
      "386m 17s (- 165m 33s) (7 70%) 1.9413\n",
      "387m 4s (- 165m 53s) (7 70%) 1.9022\n",
      "387m 55s (- 166m 15s) (7 70%) 1.9062\n",
      "388m 43s (- 166m 35s) (7 70%) 1.9294\n",
      "389m 33s (- 166m 57s) (7 70%) 1.9575\n",
      "390m 21s (- 167m 17s) (7 70%) 1.9740\n",
      "391m 12s (- 167m 39s) (7 70%) 1.9585\n",
      "392m 0s (- 168m 0s) (7 70%) 1.9850\n",
      "392m 51s (- 168m 21s) (7 70%) 2.0028\n",
      "393m 38s (- 168m 42s) (7 70%) 1.9875\n",
      "Bleu  4.067351666502684\n",
      "395m 15s (- 169m 23s) (7 70%) 1.9940\n",
      "396m 3s (- 169m 44s) (7 70%) 1.9789\n",
      "396m 54s (- 170m 6s) (7 70%) 1.9858\n",
      "397m 42s (- 170m 26s) (7 70%) 2.0059\n",
      "398m 33s (- 170m 48s) (7 70%) 1.9985\n",
      "399m 21s (- 171m 9s) (7 70%) 1.9922\n",
      "400m 12s (- 171m 30s) (7 70%) 2.0518\n",
      "400m 59s (- 171m 51s) (7 70%) 2.0298\n",
      "401m 50s (- 172m 13s) (7 70%) 2.0273\n",
      "402m 38s (- 172m 33s) (7 70%) 2.0305\n",
      "Bleu  4.419631319739919\n",
      "404m 14s (- 173m 14s) (7 70%) 2.0397\n",
      "405m 2s (- 173m 35s) (7 70%) 2.0690\n",
      "405m 53s (- 173m 57s) (7 70%) 2.0835\n",
      "406m 41s (- 174m 17s) (7 70%) 2.0810\n",
      "407m 32s (- 174m 39s) (7 70%) 2.0890\n",
      "408m 20s (- 175m 0s) (7 70%) 2.0814\n",
      "409m 11s (- 175m 21s) (7 70%) 2.0853\n",
      "409m 58s (- 175m 42s) (7 70%) 2.0713\n",
      "410m 49s (- 176m 4s) (7 70%) 2.1106\n",
      "411m 37s (- 176m 24s) (7 70%) 2.1338\n",
      "Bleu  4.047741718257053\n",
      "413m 13s (- 177m 5s) (7 70%) 2.1071\n",
      "414m 1s (- 177m 26s) (7 70%) 2.1051\n",
      "414m 52s (- 177m 48s) (7 70%) 2.1089\n",
      "415m 39s (- 178m 8s) (7 70%) 2.1437\n",
      "416m 31s (- 178m 30s) (7 70%) 2.1774\n",
      "417m 18s (- 178m 50s) (7 70%) 2.1579\n",
      "418m 9s (- 179m 12s) (7 70%) 2.1651\n",
      "418m 57s (- 179m 33s) (7 70%) 2.1457\n",
      "419m 47s (- 179m 54s) (7 70%) 2.1381\n",
      "420m 35s (- 180m 15s) (7 70%) 2.1327\n",
      "Bleu  4.487637701106289\n",
      "422m 11s (- 180m 56s) (7 70%) 2.1527\n",
      "422m 58s (- 181m 16s) (7 70%) 2.1719\n",
      "423m 49s (- 181m 38s) (7 70%) 2.1856\n",
      "424m 37s (- 106m 9s) (8 80%) 1.6953\n",
      "425m 28s (- 106m 22s) (8 80%) 1.5733\n",
      "426m 16s (- 106m 34s) (8 80%) 1.6075\n",
      "427m 7s (- 106m 46s) (8 80%) 1.5809\n",
      "427m 55s (- 106m 58s) (8 80%) 1.6128\n",
      "428m 46s (- 107m 11s) (8 80%) 1.6020\n",
      "429m 34s (- 107m 23s) (8 80%) 1.6315\n",
      "Bleu  4.0758893760087425\n",
      "431m 12s (- 107m 48s) (8 80%) 1.6229\n",
      "432m 0s (- 108m 0s) (8 80%) 1.6564\n",
      "432m 51s (- 108m 12s) (8 80%) 1.6257\n",
      "433m 39s (- 108m 24s) (8 80%) 1.6861\n",
      "434m 29s (- 108m 37s) (8 80%) 1.6792\n",
      "435m 17s (- 108m 49s) (8 80%) 1.6915\n",
      "436m 8s (- 109m 2s) (8 80%) 1.6912\n",
      "436m 56s (- 109m 14s) (8 80%) 1.6968\n",
      "437m 46s (- 109m 26s) (8 80%) 1.7099\n",
      "438m 34s (- 109m 38s) (8 80%) 1.7094\n",
      "Bleu  4.253906709112992\n",
      "440m 10s (- 110m 2s) (8 80%) 1.7049\n",
      "440m 58s (- 110m 14s) (8 80%) 1.7564\n",
      "441m 49s (- 110m 27s) (8 80%) 1.7778\n",
      "442m 37s (- 110m 39s) (8 80%) 1.7449\n",
      "443m 28s (- 110m 52s) (8 80%) 1.7736\n",
      "444m 16s (- 111m 4s) (8 80%) 1.7919\n",
      "445m 7s (- 111m 16s) (8 80%) 1.7748\n",
      "445m 54s (- 111m 28s) (8 80%) 1.7832\n",
      "446m 45s (- 111m 41s) (8 80%) 1.8087\n",
      "447m 33s (- 111m 53s) (8 80%) 1.7938\n",
      "Bleu  4.27614658533433\n",
      "449m 9s (- 112m 17s) (8 80%) 1.8389\n",
      "449m 57s (- 112m 29s) (8 80%) 1.8376\n",
      "450m 48s (- 112m 42s) (8 80%) 1.8163\n",
      "451m 36s (- 112m 54s) (8 80%) 1.8623\n",
      "452m 26s (- 113m 6s) (8 80%) 1.8579\n",
      "453m 14s (- 113m 18s) (8 80%) 1.8596\n",
      "454m 5s (- 113m 31s) (8 80%) 1.8687\n",
      "454m 53s (- 113m 43s) (8 80%) 1.8605\n",
      "455m 44s (- 113m 56s) (8 80%) 1.8915\n",
      "456m 31s (- 114m 7s) (8 80%) 1.8744\n",
      "Bleu  3.971956926728787\n",
      "458m 7s (- 114m 31s) (8 80%) 1.8826\n",
      "458m 55s (- 114m 43s) (8 80%) 1.8961\n",
      "459m 45s (- 114m 56s) (8 80%) 1.9138\n",
      "460m 33s (- 115m 8s) (8 80%) 1.9224\n",
      "461m 24s (- 115m 21s) (8 80%) 1.9241\n",
      "462m 11s (- 115m 32s) (8 80%) 1.9038\n",
      "463m 2s (- 115m 45s) (8 80%) 1.9468\n",
      "463m 49s (- 115m 57s) (8 80%) 1.9273\n",
      "464m 40s (- 116m 10s) (8 80%) 1.9307\n",
      "465m 28s (- 116m 22s) (8 80%) 1.9717\n",
      "Bleu  3.9641315687633027\n",
      "467m 2s (- 116m 45s) (8 80%) 1.9364\n",
      "467m 50s (- 116m 57s) (8 80%) 1.9708\n",
      "468m 40s (- 117m 10s) (8 80%) 1.9543\n",
      "469m 28s (- 117m 22s) (8 80%) 1.9544\n",
      "470m 19s (- 117m 34s) (8 80%) 1.9840\n",
      "471m 6s (- 117m 46s) (8 80%) 1.9425\n",
      "471m 57s (- 117m 59s) (8 80%) 1.9897\n",
      "472m 45s (- 118m 11s) (8 80%) 1.9832\n",
      "473m 36s (- 118m 24s) (8 80%) 1.9769\n",
      "474m 23s (- 118m 35s) (8 80%) 2.0149\n",
      "Bleu  3.5367150887912295\n",
      "476m 2s (- 119m 0s) (8 80%) 1.9933\n",
      "476m 50s (- 119m 12s) (8 80%) 2.0199\n",
      "477m 41s (- 119m 25s) (8 80%) 2.0081\n",
      "478m 29s (- 119m 37s) (8 80%) 2.0503\n",
      "479m 19s (- 119m 49s) (8 80%) 2.0496\n",
      "480m 7s (- 120m 1s) (8 80%) 2.0273\n",
      "480m 58s (- 120m 14s) (8 80%) 2.0204\n",
      "481m 45s (- 120m 26s) (8 80%) 2.0573\n",
      "482m 36s (- 120m 39s) (8 80%) 2.0394\n",
      "483m 24s (- 120m 51s) (8 80%) 2.0387\n",
      "Bleu  3.8582701709042255\n",
      "485m 0s (- 53m 53s) (9 90%) 1.9550\n",
      "485m 48s (- 53m 58s) (9 90%) 1.5172\n",
      "486m 39s (- 54m 4s) (9 90%) 1.4979\n",
      "487m 26s (- 54m 9s) (9 90%) 1.5119\n",
      "488m 17s (- 54m 15s) (9 90%) 1.5161\n",
      "489m 5s (- 54m 20s) (9 90%) 1.5245\n",
      "489m 55s (- 54m 26s) (9 90%) 1.5360\n",
      "490m 43s (- 54m 31s) (9 90%) 1.5295\n",
      "491m 33s (- 54m 37s) (9 90%) 1.5421\n",
      "492m 21s (- 54m 42s) (9 90%) 1.5788\n",
      "Bleu  4.022645293541227\n",
      "493m 58s (- 54m 53s) (9 90%) 1.6044\n",
      "494m 46s (- 54m 58s) (9 90%) 1.5887\n",
      "495m 37s (- 55m 4s) (9 90%) 1.6070\n",
      "496m 24s (- 55m 9s) (9 90%) 1.6279\n",
      "497m 15s (- 55m 15s) (9 90%) 1.6311\n",
      "498m 3s (- 55m 20s) (9 90%) 1.6576\n",
      "498m 54s (- 55m 26s) (9 90%) 1.6305\n",
      "499m 42s (- 55m 31s) (9 90%) 1.6267\n",
      "500m 32s (- 55m 36s) (9 90%) 1.6469\n",
      "501m 20s (- 55m 42s) (9 90%) 1.6884\n",
      "Bleu  3.8604083504373996\n",
      "502m 57s (- 55m 53s) (9 90%) 1.6822\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-73287c193cf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_losses = trainIters(train_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, n_iters=10, \n\u001b[1;32m      2\u001b[0m                          \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                           teacher_forcing_ratio=1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-ef04652cbf0e>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, encoder_optimizer, decoder_optimizer, n_iters, print_every, validate_every, plot_every, learning_rate, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                 \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             )\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ef04652cbf0e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inputs, input_lengths, targets, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length, teacher_forcing_ratio, clip)\u001b[0m\n\u001b[1;32m    555\u001b[0m     target_lengths)\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;31m# Clip gradient norms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/nlp/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/nlp/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_losses = trainIters(train_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, n_iters=10, \n",
    "                         print_every=50, plot_every=100, validate_every = 500, learning_rate=0.001, \n",
    "                                          teacher_forcing_ratio=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
