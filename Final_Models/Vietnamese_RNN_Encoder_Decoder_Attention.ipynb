{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU based encoder and Attention based decoder after Luong for Vietnamese-English translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load all the libraries\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import List\n",
    "from collections import Counter, namedtuple\n",
    "from itertools import zip_longest\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import functional\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import io\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "MAX_LENGTH = 30 #maximum sentence length\n",
    "\n",
    "MAX_VOCAB_SIZE = 50000 #maximum vocabulary size\n",
    "\n",
    "PAD_IDX = 0 \n",
    "SOS_IDX = 1\n",
    "EOS_IDX = 2\n",
    "UNK_IDX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check CUDA is available\n",
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Code references: https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb?fbclid=IwAR0LRHAIXhvRqewTXayFLEdr3Pw6temcC2d0SaNE6KZ_sXPyaCvvHC-tasQ\n",
    "\n",
    "\n",
    "# Remove punctuation\n",
    "def removePunctuation(s):\n",
    "\n",
    "    to_remove = ('&lt;', '&gt;', '&amp;', '&apos;', '&quot;')\n",
    "    table = str.maketrans(dict.fromkeys('.!?:,'))\n",
    "    s = s.translate(table)\n",
    "    for i in to_remove:\n",
    "        s=s.replace(i,'')   \n",
    "    s = s.strip()   \n",
    "    return s\n",
    "\n",
    "\n",
    "def tokenize_13a(line):\n",
    "    \"\"\"\n",
    "    Tokenizes an input line using a relatively minimal tokenization that is however equivalent to mteval-v13a, used by WMT.\n",
    "    :param line: a segment to tokenize\n",
    "    :return: the tokenized line\n",
    "    \"\"\"\n",
    "\n",
    "    norm = line\n",
    "\n",
    "    # language-independent part:\n",
    "    norm = norm.replace('<skipped>', '')\n",
    "    norm = norm.replace('-\\n', '')\n",
    "    norm = norm.replace('\\n', ' ')\n",
    "    norm = norm.replace('&quot;', '\"')\n",
    "    norm = norm.replace('&amp;', '&')\n",
    "    norm = norm.replace('&lt;', '<')\n",
    "    norm = norm.replace('&gt;', '>')\n",
    "\n",
    "    # language-dependent part (assuming Western languages):\n",
    "    norm = \" {} \".format(norm)\n",
    "    norm = re.sub(r'([\\{-\\~\\[-\\` -\\&\\(-\\+\\:-\\@\\/])', ' \\\\1 ', norm)\n",
    "    norm = re.sub(r'([^0-9])([\\.,])', '\\\\1 \\\\2 ', norm)  # tokenize period and comma unless preceded by a digit\n",
    "    norm = re.sub(r'([\\.,])([^0-9])', ' \\\\1 \\\\2', norm)  # tokenize period and comma unless followed by a digit\n",
    "    norm = re.sub(r'([0-9])(-)', '\\\\1 \\\\2 ', norm)  # tokenize dash when preceded by a digit\n",
    "    norm = re.sub(r'\\s+', ' ', norm)  # one space only between words\n",
    "    norm = re.sub(r'^\\s+', '', norm)  # no leading space\n",
    "    norm = re.sub(r'\\s+$', '', norm)  # no trailing space\n",
    "\n",
    "    return norm\n",
    "\n",
    "def corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n",
    "                 use_effective_order=False):\n",
    "    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
    "    :param sys_stream: The system stream (a sequence of segments)\n",
    "    :param ref_streams: A list of one or more reference streams (each a sequence of segments)\n",
    "    :param smooth: The smoothing method to use\n",
    "    :param smooth_floor: For 'floor' smoothing, the floor to use\n",
    "    :param force: Ignore data that looks already tokenized\n",
    "    :param lowercase: Lowercase the data\n",
    "    :param tokenize: The tokenizer to use\n",
    "    :return: a BLEU object containing everything you'd want\n",
    "    \"\"\"\n",
    "\n",
    "    # Add some robustness to the input arguments\n",
    "    if isinstance(sys_stream, str):\n",
    "        sys_stream = [sys_stream]\n",
    "    if isinstance(ref_streams, str):\n",
    "        ref_streams = [[ref_streams]]\n",
    "\n",
    "    sys_len = 0\n",
    "    ref_len = 0\n",
    "\n",
    "    correct = [0 for n in range(NGRAM_ORDER)]\n",
    "    total = [0 for n in range(NGRAM_ORDER)]\n",
    "    \n",
    "\n",
    "    # look for already-tokenized sentences\n",
    "    tokenized_count = 0\n",
    "\n",
    "    fhs = [sys_stream] + ref_streams\n",
    "    for lines in zip_longest(*fhs):\n",
    "        if None in lines:\n",
    "            raise EOFError(\"Source and reference streams have different lengths!\")\n",
    "\n",
    "        if lowercase:\n",
    "            lines = [x.lower() for x in lines]\n",
    "            \n",
    "        tokenize= 'tokenize_13a'    \n",
    "\n",
    "        if not (force or tokenize == 'none') and lines[0].rstrip().endswith(' .'):\n",
    "            tokenized_count += 1\n",
    "\n",
    "            if tokenized_count == 100:\n",
    "                logging.warning('That\\'s 100 lines that end in a tokenized period (\\'.\\')')\n",
    "                logging.warning('It looks like you forgot to detokenize your test data, which may hurt your score.')\n",
    "                logging.warning('If you insist your data is detokenized, or don\\'t care, you can suppress this message with \\'--force\\'.')\n",
    "\n",
    "        output, *refs = [tokenize_13a(x.rstrip()) for x in lines]\n",
    "        \n",
    "\n",
    "        ref_ngrams, closest_diff, closest_len = ref_stats(output, refs)\n",
    "        \n",
    "\n",
    "        sys_len += len(output.split())\n",
    "        ref_len += closest_len\n",
    "\n",
    "        sys_ngrams = extract_ngrams(output)\n",
    "        for ngram in sys_ngrams.keys():\n",
    "            n = len(ngram.split())\n",
    "            correct[n-1] += min(sys_ngrams[ngram], ref_ngrams.get(ngram, 0))\n",
    "            total[n-1] += sys_ngrams[ngram]\n",
    "            \n",
    "\n",
    "    return compute_bleu(correct, total, sys_len, ref_len, smooth, smooth_floor, use_effective_order)\n",
    "  \n",
    "  \n",
    "# n-gram order. Don't change this.\n",
    "NGRAM_ORDER = 4\n",
    "  \n",
    "def compute_bleu(correct: List[int], total: List[int], sys_len: int, ref_len: int, smooth = 'none', smooth_floor = 0.01,\n",
    "                 use_effective_order = False):\n",
    "    \"\"\"Computes BLEU score from its sufficient statistics. Adds smoothing.\n",
    "    :param correct: List of counts of correct ngrams, 1 <= n <= NGRAM_ORDER\n",
    "    :param total: List of counts of total ngrams, 1 <= n <= NGRAM_ORDER\n",
    "    :param sys_len: The cumulative system length\n",
    "    :param ref_len: The cumulative reference length\n",
    "    :param smooth: The smoothing method to use\n",
    "    :param smooth_floor: The smoothing value added, if smooth method 'floor' is used\n",
    "    :param use_effective_order: Use effective order.\n",
    "    :return: A BLEU object with the score (100-based) and other statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    precisions = [0 for x in range(NGRAM_ORDER)]\n",
    "\n",
    "    smooth_mteval = 1.\n",
    "    effective_order = NGRAM_ORDER\n",
    "    for n in range(NGRAM_ORDER):\n",
    "        if total[n] == 0:\n",
    "            break\n",
    "\n",
    "        if use_effective_order:\n",
    "            effective_order = n + 1\n",
    "\n",
    "        if correct[n] == 0:\n",
    "            if smooth == 'exp':\n",
    "                smooth_mteval *= 2\n",
    "                precisions[n] = 100. / (smooth_mteval * total[n])\n",
    "            elif smooth == 'floor':\n",
    "                precisions[n] = 100. * smooth_floor / total[n]\n",
    "        else:\n",
    "            precisions[n] = 100. * correct[n] / total[n]\n",
    "\n",
    "    # If the system guesses no i-grams, 1 <= i <= NGRAM_ORDER, the BLEU score is 0 (technically undefined).\n",
    "    # This is a problem for sentence-level BLEU or a corpus of short sentences, where systems will get no credit\n",
    "    # if sentence lengths fall under the NGRAM_ORDER threshold. This fix scales NGRAM_ORDER to the observed\n",
    "    # maximum order. It is only available through the API and off by default\n",
    "\n",
    "    brevity_penalty = 1.0\n",
    "    if sys_len < ref_len:\n",
    "        brevity_penalty = math.exp(1 - ref_len / sys_len) if sys_len > 0 else 0.0\n",
    "        \n",
    "\n",
    "    bleu = brevity_penalty * math.exp(sum(map(my_log, precisions[:effective_order])) / effective_order)\n",
    "\n",
    "    return bleu \n",
    "  \n",
    "\n",
    "def ref_stats(output, refs):\n",
    "    ngrams = Counter()\n",
    "    closest_diff = None\n",
    "    closest_len = None\n",
    "    for ref in refs:\n",
    "        tokens = ref.split()\n",
    "        reflen = len(tokens)\n",
    "        diff = abs(len(output.split()) - reflen)\n",
    "        if closest_diff is None or diff < closest_diff:\n",
    "            closest_diff = diff\n",
    "            closest_len = reflen\n",
    "        elif diff == closest_diff:\n",
    "            if reflen < closest_len:\n",
    "                closest_len = reflen\n",
    "\n",
    "        ngrams_ref = extract_ngrams(ref)\n",
    "        for ngram in ngrams_ref.keys():\n",
    "            ngrams[ngram] = max(ngrams[ngram], ngrams_ref[ngram])\n",
    "\n",
    "    return ngrams, closest_diff, closest_len\n",
    "  \n",
    "\n",
    "def extract_ngrams(line, min_order=1, max_order=NGRAM_ORDER) -> Counter:\n",
    "    \"\"\"Extracts all the ngrams (1 <= n <= NGRAM_ORDER) from a sequence of tokens.\n",
    "    :param line: a segment containing a sequence of words\n",
    "    :param max_order: collect n-grams from 1<=n<=max\n",
    "    :return: a dictionary containing ngrams and counts\n",
    "    \"\"\"\n",
    "\n",
    "    ngrams = Counter()\n",
    "    tokens = line.split()\n",
    "    for n in range(min_order, max_order + 1):\n",
    "        for i in range(0, len(tokens) - n + 1):\n",
    "            ngram = ' '.join(tokens[i: i + n])\n",
    "            ngrams[ngram] += 1\n",
    "\n",
    "    return ngrams  \n",
    "\n",
    "def my_log(num):\n",
    "    \"\"\"\n",
    "    Floors the log function\n",
    "    :param num: the number\n",
    "    :return: log(num) floored to a very low number\n",
    "    \"\"\"\n",
    "\n",
    "    if num == 0.0:\n",
    "        return -9999999999\n",
    "    return math.log(num)\n",
    "\n",
    "\n",
    "### CALCULATING LOSS FUNCTIONS ###\n",
    "\n",
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.range(0, max_len - 1).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def masked_cross_entropy(logits, target, length):\n",
    "    length = Variable(torch.LongTensor(length))\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1)).to(device)\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = functional.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1)).to(device)\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum().to(device)\n",
    "    return loss\n",
    "\n",
    "  \n",
    "### MODEL INPUTS PROCESSING ### \n",
    "    \n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 4  # Count SOS and EOS and Pad\n",
    "        self.all_words = []\n",
    "        \n",
    "    def build_vocab(self, embedding, max_vocab_size = 100000):\n",
    "        unique_words = list(embedding.keys())[0:max_vocab_size]\n",
    "\n",
    "        index2word =  unique_words #list of words available in embedding\n",
    "        index2word = ['<pad>', '<sos>', '<eos>','<unk>'] + index2word #add pad and unknown to the beginning\n",
    "\n",
    "        word2index = dict(zip(unique_words, range(4,4+len(unique_words)))) # dictionary of words and indices \n",
    "        word2index['<pad>'] = PAD_IDX  #add pad symbol to the dictionary\n",
    "        word2index['<unk>'] = UNK_IDX  #add unkown symbol to the dictionary\n",
    "        word2index['<eos>'] = EOS_IDX\n",
    "        word2index['<sos>'] = SOS_IDX\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.index2word = index2word\n",
    "        self.n_words = len(self.word2index)\n",
    "\n",
    "        return word2index, index2word \n",
    "    \n",
    "    \n",
    "### PREPROCESSING FUNCTIONS ###    \n",
    "            \n",
    "def remove_blanks(pair):\n",
    "    '''Remove empty lines'''\n",
    "    if len(pair[0]) == 0 or len(pair[1]) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def set_max_length(pair, max_length=MAX_LENGTH):\n",
    "    '''Remove pairs with empty inputs'''\n",
    "    if len(pair[0].split(' ')) > max_length or len(pair[1].split(' '))>max_length:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def readLangs(filename1, filename2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    with open(filename1, encoding='utf-8') as f:\n",
    "        lines1 = f.read().strip().split('\\n')\n",
    "        \n",
    "    with open(filename2, encoding='utf-8') as f:\n",
    "        lines2 = f.read().strip().split('\\n')   \n",
    "        \n",
    "    # Remove punctuation\n",
    "    lines1 = [removePunctuation(l) for l in lines1]\n",
    "    lines2 = [removePunctuation(l) for l in lines2]\n",
    "              \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse: #change from english->french to french->english for example\n",
    "        pairs =list(zip(lines2, lines1))\n",
    "        input_lang = Lang(filename2[-2:]) #take last two letters\n",
    "        output_lang = Lang(filename1[-2:])\n",
    "    else:\n",
    "        pairs =list(zip(lines1, lines2))\n",
    "        input_lang = Lang(filename1[-2:])\n",
    "        output_lang = Lang(filename2[-2:])\n",
    "            \n",
    "    pairs = list(filter(remove_blanks, pairs))  \n",
    "    pairs = list(filter(set_max_length, pairs))\n",
    "\n",
    "    return input_lang, output_lang, pairs \n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, embedding_in, embedding_out, num_sent=None, reverse=False):\n",
    "    \n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    pairs = pairs[:num_sent]\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "          \n",
    "    input_lang.build_vocab(embedding_in)\n",
    "    output_lang.build_vocab(embedding_out)\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "### PREPROCESS DATA FOR INPUT INTO LOADERS ### \n",
    "\n",
    "class VocabDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_tuple, word2id_lang1, word2id_lang2):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list1, self.data_list2 = zip(*data_tuple)\n",
    "        assert (len(self.data_list1) == len(self.data_list2))\n",
    "        self.word2id1 = word2id_lang1\n",
    "        self.word2id2 = word2id_lang2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list1)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        input_sentence = [self.word2id1[c] if c in self.word2id1.keys() \n",
    "                         else UNK_IDX for c in self.data_list1[key].split()][:MAX_LENGTH-1]\n",
    "        input_sentence.append(EOS_IDX)\n",
    "                                                                   \n",
    "        output_sentence = [self.word2id2[c] if c in self.word2id2.keys() \n",
    "                          else UNK_IDX for c in self.data_list2[key].split()][:MAX_LENGTH-1]\n",
    "        output_sentence.append(EOS_IDX)\n",
    "\n",
    "        return [input_sentence, output_sentence, len(input_sentence), len(output_sentence)]\n",
    "    \n",
    "\n",
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    length_list1 = []\n",
    "    length_list2 = []\n",
    "     \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        x1 = datum[0]\n",
    "        x2 = datum[1]\n",
    "        len1 = datum[2]\n",
    "        len2 = datum[3]\n",
    "        \n",
    "        length_list1.append(len1)\n",
    "        length_list2.append(len2)\n",
    "        #Pad first sentences\n",
    "        padded_vec1 = np.pad(np.array(x1),\n",
    "                                pad_width=((0,MAX_LENGTH-len1)),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list1.append(padded_vec1)\n",
    "        \n",
    "        #Pad second sentences\n",
    "        padded_vec2 = np.pad(np.array(x2),\n",
    "                        pad_width=((0,MAX_LENGTH-len2)),\n",
    "                        mode=\"constant\", constant_values=0)\n",
    "        data_list2.append(padded_vec2)\n",
    "        \n",
    "    data_list1 = np.array(data_list1)\n",
    "    data_list2 = np.array(data_list2)\n",
    "    length_list1 = np.array(length_list1)\n",
    "    lenth_list2 = np.array(length_list2)\n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list1)), \n",
    "            torch.from_numpy(np.array(data_list2)),\n",
    "            torch.LongTensor(length_list1), \n",
    "            torch.LongTensor(length_list2)]\n",
    "\n",
    "\n",
    "### MODELS ###\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, emb_weights, dropout=0):\n",
    "        '''Bidirectional RNN'''\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        weight_size = emb_weights.size()[1]\n",
    "        \n",
    "        # Embedding input: max_length x batch_size\n",
    "        # Embedding output: max_length x batch_size x hidden size\n",
    "        self.embedding = nn.Embedding(vocab_size, weight_size, padding_idx=0).from_pretrained(emb_weights, \n",
    "                                                                freeze=True).to(device) #vocab size x hidden size\n",
    "        \n",
    "        # Input: (max_length x batch_size x hidden_size)\n",
    "        # Output: hidden - 2 x batch_size x hidden_size\n",
    "        # Output: outputs max_length x batch_size x hidden_size*2\n",
    "        self.gru = nn.GRU(weight_size, hidden_size, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden\n",
    "    \n",
    "    \n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "     \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        scores = self.score(hidden, encoder_outputs).squeeze(2)\n",
    "        return F.softmax(scores).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "        # Calculate attention scores\n",
    "        self.batch_size = hidden.shape[1]\n",
    "        if self.method == 'dot':\n",
    "            score = torch.bmm(encoder_output.transpose(1,0), hidden.squeeze(0).unsqueeze(2)) \n",
    "            return score \n",
    "\n",
    "        elif self.method == 'general':\n",
    "            score = torch.bmm(encoder_output.transpose(1,0), self.attn(hidden.squeeze(0)).unsqueeze(2)) \n",
    "            return score\n",
    "\n",
    "\n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, weights_matrix, hidden_size, output_size, drop_out, n_layers=1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_out=drop_out\n",
    "        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n",
    "\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(self.num_embeddings,self.hidden_size)\n",
    "        self.embedding.from_pretrained(weights_matrix, freeze=True, sparse=False)\n",
    "        self.embedding_dropout = nn.Dropout(drop_out)\n",
    "      \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=drop_out)\n",
    "        \n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "\n",
    "        self.batch_size=input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq) # dim = Batch_Size x embedding_dim\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, self.batch_size, self.hidden_size)\n",
    "\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(hidden[0].view(1, self.batch_size, self.hidden_size), encoder_outputs)\n",
    "        \n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        return output, hidden, attn_weights  \n",
    "    \n",
    "    \n",
    "### TRAINING MODELS ###    \n",
    "         \n",
    "def train(inputs, input_lengths, targets, target_lengths, \n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH,\n",
    "         teacher_forcing_ratio=0.5, clip = 50):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 #\n",
    "    batch_size = inputs.size()[1]\n",
    "\n",
    "    max_targ_len = max_length\n",
    "\n",
    "    # Run sentences through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(inputs, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([SOS_IDX] * batch_size).to(device)\n",
    "    decoder_hidden = encoder_hidden[:1] # Use last (forward) hidden state from encoder\n",
    "    \n",
    "    #randomly use teacher forcing or not\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Run through decoder one time step at a time using TEACHER FORCING=1.0\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_targ_len, batch_size, output_lang.n_words)).to(device)\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_targ_len):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "            decoder_input = targets[t]\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_targ_len):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "\n",
    "    loss = masked_cross_entropy(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    targets.transpose(0, 1).contiguous(),\n",
    "    target_lengths)\n",
    "        \n",
    "    loss.backward()\n",
    "        \n",
    "    # Clip gradient norms to prevent gradient explosion\n",
    "    clip = clip\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    \n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def trainIters(loader, encoder, decoder, n_iters, print_every=1000, validate_every = 100,\n",
    "               plot_every=100, learning_rate=0.01,\n",
    "              teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    start = time.time()\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    plot_losses = []\n",
    "\n",
    "    counter = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while epoch < n_iters:\n",
    "        epoch += 1\n",
    "\n",
    "        # Get training data for this cycle\n",
    "        for i, (source, target, lengths1, lengths2) in enumerate(loader):\n",
    "\n",
    "            counter += 1 #counter for printing purposes\n",
    "\n",
    "            # Run the train function\n",
    "            loss = train(\n",
    "                source.long().transpose(0,1).to(device), lengths1, target.long().transpose(0,1).to(device), lengths2,\n",
    "                encoder, decoder,\n",
    "                encoder_optimizer, decoder_optimizer, criterion, teacher_forcing_ratio=teacher_forcing_ratio\n",
    "            )\n",
    "\n",
    "            # Keep track of loss\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if counter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_iters), epoch, \n",
    "                                                       epoch / n_iters * 100, print_loss_avg)\n",
    "                \n",
    "                print(print_summary)\n",
    "\n",
    "            if counter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "                # save in case of crash\n",
    "                torch.save(encoder.state_dict(), en_loc  + '/' +'encoder_att_leu_un1.pt')\n",
    "                torch.save(decoder.state_dict(), en_loc  + '/' +'decoder_att_leu_un1.pt')\n",
    "                torch.save(encoder_optimizer.state_dict(), en_loc + '/' + 'encoder_opt_att.pt')\n",
    "                torch.save(decoder_optimizer.state_dict(), en_loc + '/' + 'decoder_opt_att.pt')\n",
    "                \n",
    "            if counter % validate_every == 0:\n",
    "                bleu = validate(encoder, decoder, val_loader)\n",
    "                print('Bleu ', bleu)\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses\n",
    "\n",
    "\n",
    "### EVALUATE RESULTS ###\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, input_lengths, translated, search='greedy', max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Function that evaluate translation.\n",
    "    \"\"\"    \n",
    "    # process input sentence\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence.transpose(0,1)\n",
    "        input_length = sentence.size()[0]\n",
    "        \n",
    "        # encode the source lanugage\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor, input_lengths, None)\n",
    "\n",
    "        decoder_input = torch.tensor([SOS_IDX], device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden[:1] # Use last (forward) hidden state from encoder \n",
    "        # output of this function\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n",
    "            decoder_output, decoder_hidden, decoder_att = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output)\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1) \n",
    "\n",
    "            if topi.item() == EOS_IDX:\n",
    "                #decoded_words.append('<EOS>')\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                if topi.item() not in [SOS_IDX, EOS_IDX, UNK_IDX, PAD_IDX]:\n",
    "                    decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            \n",
    "            decoder_input = topi[0].detach()\n",
    "        \n",
    "        translation = []\n",
    "        for i in translated: #expected translation\n",
    "            if i.item() not in [SOS_IDX, EOS_IDX, UNK_IDX, PAD_IDX]:\n",
    "                translation.append(output_lang.index2word[i.item()])\n",
    "\n",
    "        return decoded_words, translation\n",
    "    \n",
    "    \n",
    "def evaluate_batch(loader, encoder, decoder):\n",
    "    \n",
    "    decoded_sentences = []\n",
    "    actual_sentences = []\n",
    "    \n",
    "    for i, (source, target, lengths1, lengths2) in enumerate(loader):\n",
    "        #iterate over batch\n",
    "        \n",
    "        for n in range(len(source)):\n",
    "            decoded, actual = evaluate(encoder, decoder, source[n].unsqueeze(0).to(device), lengths1[n], target[n])\n",
    "            decoded_sentences.append(decoded)\n",
    "            actual_sentences.append(actual)\n",
    "            \n",
    "    return decoded_sentences, actual_sentences\n",
    "\n",
    "\n",
    "def evaluate_bleu(translation_list, reference_list):\n",
    "     \n",
    "    translations = [' '.join(v) for v in translation_list]\n",
    "    references = [' '.join(v) for v in reference_list]\n",
    "    \n",
    "    return corpus_bleu(translations, [references])\n",
    "\n",
    "\n",
    "def validate(encoder, decoder, val_loader):\n",
    "    decoded_sentences, actual_sentences = evaluate_batch(val_loader, encoder, decoder)\n",
    "    bleu = evaluate_bleu(decoded_sentences, actual_sentences)\n",
    "    \n",
    "    return bleu\n",
    "\n",
    "\n",
    "#Plot results\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))    \n",
    "\n",
    "\n",
    "### LOADING AND PROCESSING PRETRAINED EMBEDDINGS ###\n",
    "\n",
    "def embed_to_tensor(embeddings):\n",
    "    y=np.array([np.array(list(xi)) for xi in embeddings.values()])\n",
    "    padding = np.zeros((1, y.shape[1]))\n",
    "    unknown = np.random.rand(1, y.shape[1]) # to account for Padding and Unknown\n",
    "    sos = np.random.rand(1, y.shape[1])\n",
    "    eos = np.random.rand(1, y.shape[1])\n",
    "    full_size = np.concatenate([padding, sos, eos, unknown, y], axis=0)\n",
    "    emb_weights = torch.from_numpy(full_size)\n",
    "    \n",
    "    return emb_weights   \n",
    "\n",
    "\n",
    "def load_embedding(fname, max_count=None):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    counter=0\n",
    "    for line in fin:\n",
    "        counter+=1\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "        if counter==max_count:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of files\n",
    "en_loc = 'iwslt-vi-en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### VIETNAMESE\n",
    "#Read in pretrained embedding vectors - subset for now\n",
    "embeddings_map_vi = load_embedding(en_loc + '/cc.vi.300.vec', max_count=50000)\n",
    "\n",
    "#Convert embedding values to lists\n",
    "embeddings_vi = {}\n",
    "\n",
    "for key, value in embeddings_map_vi.items():\n",
    "    embeddings_vi[key] = list(value)\n",
    "    \n",
    "### ENGLISH    \n",
    "#Read in pretrained embedding vectors - subset for now\n",
    "embeddings_map_en = load_embedding(en_loc + '/wiki-news-300d-1M.vec', max_count=50000)\n",
    "\n",
    "#Convert embedding values to lists\n",
    "embeddings_en = {}\n",
    "\n",
    "for key, value in embeddings_map_en.items():\n",
    "    embeddings_en[key] = list(value)\n",
    "    \n",
    "embed_vi_tensor = embed_to_tensor(embeddings_vi).float()\n",
    "embed_en_tensor = embed_to_tensor(embeddings_en).float()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and process train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 108159 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 50004\n",
      "en 50004\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(en_loc+'/train.tok.vi', en_loc+'/train.tok.en', \n",
    "                                             embedding_in = embeddings_vi,\n",
    "                                             embedding_out = embeddings_en, num_sent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 995 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 50004\n",
      "en 50004\n"
     ]
    }
   ],
   "source": [
    "input_lang_v, output_lang_v, pairs_v = prepareData(en_loc+'/dev.tok.vi', en_loc+'/dev.tok.en', \n",
    "                                                   embedding_in = embeddings_vi,\n",
    "                                                   embedding_out = embeddings_en,\n",
    "                                                   num_sent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chính vì lượng khí thải rất lớn  nó có ý_nghĩa quan_trọng với hệ_thống khí_quyển',\n",
       "  'And because it s so much stuff  it s really important for the atmospheric system'),\n",
       " ('Chính vì nó có ý_nghĩa quan_trọng với hệ_thống khí_quyển  giá nào chúng_tôi cũng theo_đuổi nghiên_cứu này đến_cùng',\n",
       "  'Because it s important to the atmospheric system  we go to all lengths to study this thing'),\n",
       " ('Chúng_tôi cho nó nổ và xem_xét từng mảnh nhỏ',\n",
       "  'We blow it up and look at the pieces')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check inputs\n",
    "pairs[15:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size=500\n",
    "\n",
    "encoder = EncoderRNN(hidden_size = hidden_size, vocab_size = input_lang.n_words,\n",
    "                    emb_weights = embed_vi_tensor).to(device)\n",
    "decoder = LuongAttnDecoderRNN(attn_model = 'general', hidden_size = hidden_size, output_size = output_lang.n_words,\n",
    "                    weights_matrix = embed_en_tensor, drop_out=0).to(device)\n",
    "\n",
    "#encoder.load_state_dict(torch.load(en_loc + '/encoder_att_leu_un.pt'))\n",
    "#decoder.load_state_dict(torch.load(en_loc + '/decoder_att_leu_un.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "\n",
    "train_dataset = VocabDataset(pairs, input_lang.word2index, output_lang.word2index)\n",
    "# 1 batch input dimension: num_sentences x max sentence length\n",
    "# 1 batch: source_sentences, target_sentences, source_lengths, target_lengths\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = VocabDataset(pairs_v, input_lang.word2index, output_lang.word2index)\n",
    "# 1 batch input dimension: num_sentences x max sentence length\n",
    "# 1 batch: source_sentences, target_sentences, source_lengths, target_lengths\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:477: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 36s (- 5m 25s) (1 10%) 5.5887\n",
      "1m 12s (- 10m 50s) (1 10%) 5.5009\n",
      "1m 51s (- 16m 46s) (1 10%) 5.3608\n",
      "2m 27s (- 22m 10s) (1 10%) 5.3511\n",
      "3m 7s (- 28m 11s) (1 10%) 5.3499\n",
      "3m 43s (- 33m 35s) (1 10%) 5.2789\n",
      "4m 23s (- 39m 29s) (1 10%) 5.2472\n",
      "4m 59s (- 44m 53s) (1 10%) 5.2722\n",
      "5m 39s (- 50m 51s) (1 10%) 5.2574\n",
      "6m 15s (- 56m 15s) (1 10%) 5.1580\n",
      "Bleu  0.8649508933189214\n",
      "7m 33s (- 68m 0s) (1 10%) 5.0586\n",
      "8m 9s (- 73m 25s) (1 10%) 5.1489\n",
      "8m 49s (- 79m 24s) (1 10%) 5.1019\n",
      "9m 25s (- 84m 47s) (1 10%) 5.0612\n",
      "10m 4s (- 90m 41s) (1 10%) 5.0076\n",
      "10m 40s (- 96m 4s) (1 10%) 5.0071\n",
      "11m 19s (- 101m 55s) (1 10%) 5.0098\n",
      "11m 55s (- 107m 18s) (1 10%) 4.9624\n",
      "12m 34s (- 113m 11s) (1 10%) 4.9407\n",
      "13m 9s (- 118m 28s) (1 10%) 4.8922\n",
      "Bleu  1.7644043097182078\n",
      "14m 24s (- 129m 39s) (1 10%) 4.8812\n",
      "14m 59s (- 134m 59s) (1 10%) 4.8935\n",
      "15m 39s (- 140m 55s) (1 10%) 4.8251\n",
      "16m 15s (- 146m 17s) (1 10%) 4.8944\n",
      "16m 53s (- 152m 2s) (1 10%) 4.8152\n",
      "17m 28s (- 157m 19s) (1 10%) 4.8361\n",
      "18m 7s (- 163m 4s) (1 10%) 4.7839\n",
      "18m 42s (- 168m 20s) (1 10%) 4.7305\n",
      "19m 22s (- 174m 22s) (1 10%) 4.8002\n",
      "19m 58s (- 179m 48s) (1 10%) 4.7106\n",
      "Bleu  1.9875119062818905\n",
      "21m 14s (- 191m 11s) (1 10%) 4.7363\n",
      "21m 50s (- 196m 32s) (1 10%) 4.7057\n",
      "22m 29s (- 202m 22s) (1 10%) 4.6837\n",
      "23m 4s (- 207m 44s) (1 10%) 4.7080\n",
      "23m 43s (- 213m 28s) (1 10%) 4.6521\n",
      "24m 18s (- 218m 50s) (1 10%) 4.7066\n",
      "24m 58s (- 224m 48s) (1 10%) 4.6878\n",
      "25m 34s (- 230m 10s) (1 10%) 4.6572\n",
      "26m 13s (- 236m 1s) (1 10%) 4.6493\n",
      "26m 49s (- 241m 23s) (1 10%) 4.6228\n",
      "Bleu  2.689927921384208\n",
      "28m 5s (- 252m 45s) (1 10%) 4.6115\n",
      "28m 40s (- 258m 7s) (1 10%) 4.5897\n",
      "29m 18s (- 263m 50s) (1 10%) 4.6212\n",
      "29m 54s (- 269m 11s) (1 10%) 4.5808\n",
      "46m 18s (- 416m 46s) (1 10%) 4.5985\n",
      "46m 53s (- 422m 3s) (1 10%) 4.5150\n",
      "47m 31s (- 427m 41s) (1 10%) 4.5163\n",
      "48m 6s (- 432m 59s) (1 10%) 4.5441\n",
      "48m 44s (- 438m 37s) (1 10%) 4.5329\n",
      "49m 19s (- 443m 54s) (1 10%) 4.5584\n",
      "Bleu  2.768679490339095\n",
      "50m 34s (- 455m 7s) (1 10%) 4.4786\n",
      "51m 8s (- 460m 20s) (1 10%) 4.4619\n",
      "51m 45s (- 465m 50s) (1 10%) 4.4676\n",
      "52m 20s (- 471m 2s) (1 10%) 4.4487\n",
      "52m 59s (- 476m 51s) (1 10%) 4.4630\n",
      "53m 35s (- 482m 23s) (1 10%) 4.4204\n",
      "54m 14s (- 488m 9s) (1 10%) 4.4561\n",
      "54m 50s (- 493m 35s) (1 10%) 4.4523\n",
      "55m 28s (- 499m 19s) (1 10%) 4.3998\n",
      "56m 4s (- 504m 43s) (1 10%) 4.4270\n",
      "Bleu  3.1928406405059273\n",
      "57m 19s (- 515m 52s) (1 10%) 4.4468\n",
      "57m 55s (- 521m 18s) (1 10%) 4.4293\n",
      "58m 33s (- 527m 0s) (1 10%) 4.4259\n",
      "59m 9s (- 532m 25s) (1 10%) 4.3938\n",
      "59m 47s (- 538m 10s) (1 10%) 4.3611\n",
      "60m 23s (- 543m 31s) (1 10%) 4.3824\n",
      "61m 1s (- 549m 16s) (1 10%) 4.3567\n",
      "61m 37s (- 246m 31s) (2 20%) 4.1926\n",
      "62m 16s (- 249m 4s) (2 20%) 4.0057\n",
      "62m 51s (- 251m 26s) (2 20%) 3.9153\n",
      "Bleu  3.5592130894022036\n",
      "64m 6s (- 256m 26s) (2 20%) 3.9951\n",
      "64m 41s (- 258m 46s) (2 20%) 3.9826\n",
      "65m 19s (- 261m 16s) (2 20%) 3.9623\n",
      "65m 53s (- 263m 35s) (2 20%) 3.9923\n",
      "66m 30s (- 266m 3s) (2 20%) 4.0209\n",
      "67m 5s (- 268m 22s) (2 20%) 3.9824\n",
      "67m 42s (- 270m 50s) (2 20%) 3.9597\n",
      "68m 17s (- 273m 9s) (2 20%) 4.0369\n",
      "68m 54s (- 275m 37s) (2 20%) 3.9718\n",
      "69m 29s (- 277m 56s) (2 20%) 3.9645\n",
      "Bleu  3.670894029472684\n",
      "70m 43s (- 282m 53s) (2 20%) 4.0275\n",
      "71m 18s (- 285m 12s) (2 20%) 3.9876\n",
      "71m 54s (- 287m 39s) (2 20%) 3.9744\n",
      "72m 29s (- 289m 59s) (2 20%) 4.0141\n",
      "73m 6s (- 292m 26s) (2 20%) 3.9593\n",
      "73m 41s (- 294m 46s) (2 20%) 4.0054\n",
      "74m 18s (- 297m 13s) (2 20%) 3.9736\n",
      "74m 53s (- 299m 33s) (2 20%) 3.9634\n",
      "75m 30s (- 302m 0s) (2 20%) 3.9695\n",
      "76m 5s (- 304m 20s) (2 20%) 4.0056\n",
      "Bleu  4.1809338199281605\n",
      "77m 19s (- 309m 19s) (2 20%) 3.9893\n",
      "77m 54s (- 311m 39s) (2 20%) 3.9516\n",
      "78m 31s (- 314m 6s) (2 20%) 3.9964\n",
      "79m 6s (- 316m 25s) (2 20%) 3.9679\n",
      "79m 43s (- 318m 53s) (2 20%) 3.9780\n",
      "80m 18s (- 321m 12s) (2 20%) 3.9908\n",
      "80m 55s (- 323m 41s) (2 20%) 3.9543\n",
      "81m 30s (- 326m 0s) (2 20%) 3.9518\n",
      "82m 6s (- 328m 27s) (2 20%) 3.9695\n",
      "82m 41s (- 330m 46s) (2 20%) 3.9688\n",
      "Bleu  4.550718946764954\n",
      "83m 54s (- 335m 36s) (2 20%) 3.9679\n",
      "84m 28s (- 337m 55s) (2 20%) 3.9516\n",
      "85m 5s (- 340m 23s) (2 20%) 3.9742\n",
      "85m 40s (- 342m 43s) (2 20%) 3.9447\n",
      "86m 18s (- 345m 14s) (2 20%) 3.9614\n",
      "86m 54s (- 347m 38s) (2 20%) 3.9552\n",
      "87m 32s (- 350m 11s) (2 20%) 3.9567\n",
      "88m 8s (- 352m 34s) (2 20%) 3.9626\n",
      "88m 46s (- 355m 6s) (2 20%) 3.9517\n",
      "89m 22s (- 357m 29s) (2 20%) 3.9876\n",
      "Bleu  4.197009028526684\n",
      "90m 39s (- 362m 38s) (2 20%) 3.9924\n",
      "91m 15s (- 365m 1s) (2 20%) 3.9887\n",
      "91m 53s (- 367m 34s) (2 20%) 3.8802\n",
      "92m 29s (- 369m 58s) (2 20%) 3.9238\n",
      "94m 58s (- 379m 52s) (2 20%) 3.9481\n",
      "95m 36s (- 382m 25s) (2 20%) 3.9320\n",
      "96m 12s (- 384m 50s) (2 20%) 3.9734\n",
      "Bleu  4.591453746412477\n",
      "97m 29s (- 389m 59s) (2 20%) 3.9907\n",
      "98m 6s (- 392m 24s) (2 20%) 3.9060\n",
      "98m 44s (- 394m 58s) (2 20%) 3.9127\n",
      "99m 20s (- 397m 22s) (2 20%) 3.9446\n",
      "99m 58s (- 399m 55s) (2 20%) 3.9334\n",
      "100m 35s (- 402m 20s) (2 20%) 3.9148\n",
      "101m 13s (- 404m 52s) (2 20%) 3.9001\n",
      "101m 49s (- 407m 16s) (2 20%) 3.9437\n",
      "102m 27s (- 409m 51s) (2 20%) 3.9583\n",
      "103m 3s (- 412m 14s) (2 20%) 3.9271\n",
      "Bleu  4.57771059166098\n",
      "104m 24s (- 417m 36s) (2 20%) 3.9438\n",
      "105m 0s (- 420m 0s) (2 20%) 3.9316\n",
      "105m 38s (- 422m 32s) (2 20%) 3.9012\n",
      "106m 14s (- 424m 57s) (2 20%) 3.9570\n",
      "106m 53s (- 427m 33s) (2 20%) 3.9544\n",
      "107m 29s (- 250m 49s) (3 30%) 3.4982\n",
      "108m 7s (- 252m 18s) (3 30%) 3.4006\n",
      "108m 43s (- 253m 42s) (3 30%) 3.4121\n",
      "109m 21s (- 255m 11s) (3 30%) 3.4693\n",
      "109m 57s (- 256m 34s) (3 30%) 3.4699\n",
      "Bleu  5.275096190479686\n",
      "111m 13s (- 259m 30s) (3 30%) 3.4388\n",
      "111m 49s (- 260m 54s) (3 30%) 3.4488\n",
      "112m 27s (- 262m 24s) (3 30%) 3.4832\n",
      "113m 3s (- 263m 48s) (3 30%) 3.4664\n",
      "113m 42s (- 265m 19s) (3 30%) 3.4968\n",
      "114m 18s (- 266m 43s) (3 30%) 3.4950\n",
      "114m 57s (- 268m 15s) (3 30%) 3.5075\n",
      "115m 34s (- 269m 39s) (3 30%) 3.4951\n",
      "116m 12s (- 271m 8s) (3 30%) 3.4924\n",
      "116m 48s (- 272m 33s) (3 30%) 3.4899\n",
      "Bleu  5.572056010995372\n",
      "118m 4s (- 275m 29s) (3 30%) 3.5012\n",
      "118m 40s (- 276m 54s) (3 30%) 3.5514\n",
      "119m 19s (- 278m 24s) (3 30%) 3.4894\n",
      "119m 55s (- 279m 49s) (3 30%) 3.5253\n",
      "120m 34s (- 281m 19s) (3 30%) 3.5183\n",
      "121m 10s (- 282m 44s) (3 30%) 3.5708\n",
      "121m 49s (- 284m 14s) (3 30%) 3.5580\n",
      "122m 25s (- 285m 38s) (3 30%) 3.5340\n",
      "123m 3s (- 287m 8s) (3 30%) 3.5706\n",
      "123m 39s (- 288m 32s) (3 30%) 3.5491\n",
      "Bleu  5.040525190321631\n",
      "124m 56s (- 291m 32s) (3 30%) 3.5556\n",
      "125m 32s (- 292m 56s) (3 30%) 3.5619\n",
      "126m 11s (- 294m 27s) (3 30%) 3.5928\n",
      "126m 48s (- 295m 52s) (3 30%) 3.5320\n",
      "127m 26s (- 297m 22s) (3 30%) 3.5574\n",
      "128m 3s (- 298m 47s) (3 30%) 3.5987\n",
      "128m 42s (- 300m 18s) (3 30%) 3.5684\n",
      "129m 18s (- 301m 43s) (3 30%) 3.5806\n",
      "129m 57s (- 303m 13s) (3 30%) 3.5307\n",
      "130m 32s (- 304m 36s) (3 30%) 3.5747\n",
      "Bleu  5.361507863408648\n",
      "131m 50s (- 307m 37s) (3 30%) 3.5161\n",
      "132m 26s (- 309m 1s) (3 30%) 3.5799\n",
      "133m 4s (- 310m 30s) (3 30%) 3.5651\n",
      "133m 40s (- 311m 53s) (3 30%) 3.5958\n",
      "134m 17s (- 313m 21s) (3 30%) 3.6334\n",
      "134m 52s (- 314m 43s) (3 30%) 3.6104\n",
      "135m 29s (- 316m 9s) (3 30%) 3.6091\n",
      "136m 4s (- 317m 30s) (3 30%) 3.6382\n",
      "136m 43s (- 319m 0s) (3 30%) 3.6397\n",
      "137m 19s (- 320m 25s) (3 30%) 3.6115\n",
      "Bleu  5.201790411557659\n",
      "138m 35s (- 323m 22s) (3 30%) 3.6413\n",
      "139m 11s (- 324m 46s) (3 30%) 3.5767\n",
      "139m 50s (- 326m 17s) (3 30%) 3.6079\n",
      "140m 26s (- 327m 41s) (3 30%) 3.5768\n",
      "141m 4s (- 329m 11s) (3 30%) 3.6182\n",
      "141m 41s (- 330m 35s) (3 30%) 3.6230\n",
      "142m 19s (- 332m 5s) (3 30%) 3.6016\n",
      "142m 55s (- 333m 30s) (3 30%) 3.5915\n",
      "143m 34s (- 335m 0s) (3 30%) 3.6391\n",
      "144m 10s (- 336m 24s) (3 30%) 3.6273\n",
      "Bleu  5.860002346682743\n",
      "145m 24s (- 339m 17s) (3 30%) 3.6190\n",
      "145m 59s (- 340m 39s) (3 30%) 3.6028\n",
      "146m 38s (- 342m 10s) (3 30%) 3.6201\n",
      "147m 14s (- 343m 33s) (3 30%) 3.6322\n",
      "147m 52s (- 345m 3s) (3 30%) 3.6653\n",
      "148m 28s (- 346m 25s) (3 30%) 3.6153\n",
      "149m 5s (- 347m 53s) (3 30%) 3.6198\n",
      "149m 41s (- 349m 15s) (3 30%) 3.6239\n",
      "150m 18s (- 350m 42s) (3 30%) 3.6414\n",
      "150m 53s (- 352m 5s) (3 30%) 3.6030\n",
      "Bleu  5.6335164658107075\n",
      "152m 8s (- 355m 0s) (3 30%) 3.6465\n",
      "152m 43s (- 356m 22s) (3 30%) 3.6139\n",
      "153m 21s (- 230m 2s) (4 40%) 3.5168\n",
      "153m 57s (- 230m 55s) (4 40%) 3.0515\n",
      "154m 34s (- 231m 51s) (4 40%) 3.0684\n",
      "155m 9s (- 232m 44s) (4 40%) 3.0918\n",
      "155m 47s (- 233m 41s) (4 40%) 3.1124\n",
      "156m 22s (- 234m 34s) (4 40%) 3.1193\n",
      "157m 0s (- 235m 30s) (4 40%) 3.1287\n",
      "157m 35s (- 236m 22s) (4 40%) 3.1184\n",
      "Bleu  5.693094612584492\n",
      "158m 49s (- 238m 14s) (4 40%) 3.1800\n",
      "159m 24s (- 239m 6s) (4 40%) 3.1419\n",
      "160m 1s (- 240m 2s) (4 40%) 3.1417\n",
      "160m 36s (- 240m 55s) (4 40%) 3.1490\n",
      "161m 14s (- 241m 51s) (4 40%) 3.1863\n",
      "161m 49s (- 242m 44s) (4 40%) 3.2172\n",
      "162m 27s (- 243m 41s) (4 40%) 3.1479\n",
      "163m 2s (- 244m 33s) (4 40%) 3.1573\n",
      "163m 40s (- 245m 31s) (4 40%) 3.2357\n",
      "164m 16s (- 246m 24s) (4 40%) 3.2173\n",
      "Bleu  5.7207362281431084\n",
      "165m 28s (- 248m 13s) (4 40%) 3.2669\n",
      "166m 3s (- 249m 5s) (4 40%) 3.2103\n",
      "166m 41s (- 250m 1s) (4 40%) 3.2289\n",
      "167m 16s (- 250m 54s) (4 40%) 3.2923\n",
      "167m 54s (- 251m 51s) (4 40%) 3.2229\n",
      "168m 29s (- 252m 44s) (4 40%) 3.2400\n",
      "169m 7s (- 253m 40s) (4 40%) 3.2443\n",
      "169m 42s (- 254m 33s) (4 40%) 3.2593\n",
      "170m 19s (- 255m 29s) (4 40%) 3.2569\n",
      "170m 54s (- 256m 22s) (4 40%) 3.2560\n",
      "Bleu  5.960733528848735\n",
      "172m 10s (- 258m 16s) (4 40%) 3.2899\n",
      "172m 46s (- 259m 9s) (4 40%) 3.2563\n",
      "173m 23s (- 260m 5s) (4 40%) 3.2774\n",
      "173m 59s (- 260m 58s) (4 40%) 3.2775\n",
      "174m 36s (- 261m 54s) (4 40%) 3.3062\n",
      "175m 11s (- 262m 47s) (4 40%) 3.2445\n",
      "175m 49s (- 263m 43s) (4 40%) 3.2749\n",
      "176m 24s (- 264m 36s) (4 40%) 3.3075\n",
      "177m 1s (- 265m 32s) (4 40%) 3.3547\n",
      "177m 36s (- 266m 25s) (4 40%) 3.3371\n",
      "Bleu  5.920116963036049\n",
      "178m 49s (- 268m 13s) (4 40%) 3.3252\n",
      "179m 24s (- 269m 6s) (4 40%) 3.3320\n",
      "180m 1s (- 270m 2s) (4 40%) 3.3227\n",
      "180m 36s (- 270m 55s) (4 40%) 3.3715\n",
      "181m 14s (- 271m 51s) (4 40%) 3.3559\n",
      "181m 49s (- 272m 44s) (4 40%) 3.2986\n",
      "182m 26s (- 273m 40s) (4 40%) 3.3495\n",
      "183m 2s (- 274m 33s) (4 40%) 3.3434\n",
      "183m 39s (- 275m 29s) (4 40%) 3.3393\n",
      "184m 14s (- 276m 22s) (4 40%) 3.3549\n",
      "Bleu  5.741535052970848\n",
      "185m 27s (- 278m 10s) (4 40%) 3.3759\n",
      "186m 2s (- 279m 3s) (4 40%) 3.3722\n",
      "186m 40s (- 280m 0s) (4 40%) 3.3680\n",
      "187m 15s (- 280m 53s) (4 40%) 3.3305\n",
      "187m 53s (- 281m 49s) (4 40%) 3.3180\n",
      "188m 28s (- 282m 42s) (4 40%) 3.3651\n",
      "189m 5s (- 283m 38s) (4 40%) 3.3500\n",
      "189m 40s (- 284m 31s) (4 40%) 3.3623\n",
      "190m 19s (- 285m 28s) (4 40%) 3.3985\n",
      "190m 54s (- 286m 21s) (4 40%) 3.3859\n",
      "Bleu  5.790969518955885\n",
      "192m 8s (- 288m 13s) (4 40%) 3.3633\n",
      "192m 43s (- 289m 5s) (4 40%) 3.3536\n",
      "193m 21s (- 290m 2s) (4 40%) 3.3765\n",
      "193m 56s (- 290m 55s) (4 40%) 3.3780\n",
      "194m 34s (- 291m 51s) (4 40%) 3.3996\n",
      "195m 9s (- 292m 44s) (4 40%) 3.3979\n",
      "195m 46s (- 293m 40s) (4 40%) 3.4014\n",
      "196m 22s (- 294m 33s) (4 40%) 3.3666\n",
      "196m 59s (- 295m 29s) (4 40%) 3.4316\n",
      "197m 35s (- 296m 22s) (4 40%) 3.4237\n",
      "Bleu  6.253102902231361\n",
      "198m 49s (- 198m 49s) (5 50%) 3.0470\n",
      "199m 25s (- 199m 25s) (5 50%) 2.8710\n",
      "200m 2s (- 200m 2s) (5 50%) 2.8837\n",
      "200m 38s (- 200m 38s) (5 50%) 2.8362\n",
      "201m 16s (- 201m 16s) (5 50%) 2.8889\n",
      "201m 51s (- 201m 51s) (5 50%) 2.8956\n",
      "202m 29s (- 202m 29s) (5 50%) 2.9421\n",
      "203m 4s (- 203m 4s) (5 50%) 2.9072\n",
      "203m 43s (- 203m 43s) (5 50%) 2.9008\n",
      "204m 19s (- 204m 19s) (5 50%) 2.8731\n",
      "Bleu  5.956459650556662\n",
      "205m 34s (- 205m 34s) (5 50%) 2.9613\n",
      "206m 10s (- 206m 10s) (5 50%) 2.9269\n",
      "206m 48s (- 206m 48s) (5 50%) 2.9784\n",
      "207m 23s (- 207m 23s) (5 50%) 2.9429\n",
      "208m 1s (- 208m 1s) (5 50%) 2.9461\n",
      "208m 37s (- 208m 37s) (5 50%) 2.9809\n",
      "209m 15s (- 209m 15s) (5 50%) 3.0127\n",
      "209m 50s (- 209m 50s) (5 50%) 3.0076\n",
      "210m 27s (- 210m 27s) (5 50%) 3.0099\n",
      "211m 3s (- 211m 3s) (5 50%) 3.0096\n",
      "Bleu  5.9771563500127405\n",
      "212m 18s (- 212m 18s) (5 50%) 2.9911\n",
      "212m 54s (- 212m 54s) (5 50%) 3.0642\n",
      "213m 31s (- 213m 31s) (5 50%) 3.0480\n",
      "214m 6s (- 214m 6s) (5 50%) 3.0458\n",
      "214m 44s (- 214m 44s) (5 50%) 3.0692\n",
      "215m 19s (- 215m 19s) (5 50%) 3.0522\n",
      "215m 56s (- 215m 56s) (5 50%) 3.0463\n",
      "216m 32s (- 216m 32s) (5 50%) 3.0513\n",
      "217m 13s (- 217m 13s) (5 50%) 3.0586\n",
      "217m 48s (- 217m 48s) (5 50%) 3.0753\n",
      "Bleu  6.47955420900946\n",
      "219m 3s (- 219m 3s) (5 50%) 3.0689\n",
      "219m 38s (- 219m 38s) (5 50%) 3.1229\n",
      "220m 16s (- 220m 16s) (5 50%) 3.0838\n",
      "220m 52s (- 220m 52s) (5 50%) 3.1038\n",
      "221m 30s (- 221m 30s) (5 50%) 3.1249\n",
      "222m 5s (- 222m 5s) (5 50%) 3.1190\n",
      "222m 43s (- 222m 43s) (5 50%) 3.1564\n",
      "223m 18s (- 223m 18s) (5 50%) 3.1306\n",
      "223m 56s (- 223m 56s) (5 50%) 3.1425\n",
      "224m 31s (- 224m 31s) (5 50%) 3.1302\n",
      "Bleu  5.609665726407691\n",
      "225m 46s (- 225m 46s) (5 50%) 3.1113\n",
      "226m 21s (- 226m 21s) (5 50%) 3.1514\n",
      "226m 59s (- 226m 59s) (5 50%) 3.1321\n",
      "227m 34s (- 227m 34s) (5 50%) 3.1121\n",
      "228m 12s (- 228m 12s) (5 50%) 3.1377\n",
      "228m 47s (- 228m 47s) (5 50%) 3.1566\n",
      "229m 25s (- 229m 25s) (5 50%) 3.1463\n",
      "230m 1s (- 230m 1s) (5 50%) 3.1807\n",
      "230m 38s (- 230m 38s) (5 50%) 3.1662\n",
      "231m 14s (- 231m 14s) (5 50%) 3.1507\n",
      "Bleu  6.417981249288512\n",
      "232m 29s (- 232m 29s) (5 50%) 3.1341\n",
      "233m 4s (- 233m 4s) (5 50%) 3.1462\n",
      "233m 42s (- 233m 42s) (5 50%) 3.1697\n",
      "234m 17s (- 234m 17s) (5 50%) 3.1547\n",
      "234m 55s (- 234m 55s) (5 50%) 3.2146\n",
      "235m 30s (- 235m 30s) (5 50%) 3.2003\n",
      "236m 8s (- 236m 8s) (5 50%) 3.1900\n",
      "236m 44s (- 236m 44s) (5 50%) 3.2240\n",
      "237m 21s (- 237m 21s) (5 50%) 3.1893\n",
      "237m 57s (- 237m 57s) (5 50%) 3.2117\n",
      "Bleu  5.936643487313048\n",
      "239m 13s (- 239m 13s) (5 50%) 3.2017\n",
      "239m 49s (- 239m 49s) (5 50%) 3.1908\n",
      "240m 26s (- 240m 26s) (5 50%) 3.1959\n",
      "241m 2s (- 241m 2s) (5 50%) 3.2059\n",
      "241m 40s (- 241m 40s) (5 50%) 3.2242\n",
      "242m 16s (- 242m 16s) (5 50%) 3.2119\n",
      "242m 54s (- 242m 54s) (5 50%) 3.1944\n",
      "243m 29s (- 243m 29s) (5 50%) 3.2323\n",
      "244m 8s (- 162m 45s) (6 60%) 2.6994\n",
      "244m 43s (- 163m 9s) (6 60%) 2.7067\n",
      "Bleu  6.425958587506046\n",
      "245m 58s (- 163m 58s) (6 60%) 2.6857\n",
      "246m 33s (- 164m 22s) (6 60%) 2.6822\n",
      "247m 11s (- 164m 47s) (6 60%) 2.7142\n",
      "247m 46s (- 165m 11s) (6 60%) 2.7306\n",
      "248m 24s (- 165m 36s) (6 60%) 2.7605\n",
      "248m 59s (- 165m 59s) (6 60%) 2.7858\n",
      "249m 38s (- 166m 25s) (6 60%) 2.7719\n",
      "250m 13s (- 166m 49s) (6 60%) 2.7595\n",
      "250m 51s (- 167m 14s) (6 60%) 2.7742\n",
      "251m 27s (- 167m 38s) (6 60%) 2.7859\n",
      "Bleu  6.087710167052482\n",
      "252m 42s (- 168m 28s) (6 60%) 2.8125\n",
      "253m 18s (- 168m 52s) (6 60%) 2.8349\n",
      "253m 55s (- 169m 17s) (6 60%) 2.8555\n",
      "254m 31s (- 169m 40s) (6 60%) 2.8288\n",
      "255m 8s (- 170m 5s) (6 60%) 2.8410\n",
      "255m 43s (- 170m 29s) (6 60%) 2.8832\n",
      "256m 21s (- 170m 54s) (6 60%) 2.8649\n",
      "256m 57s (- 171m 18s) (6 60%) 2.8785\n",
      "257m 34s (- 171m 43s) (6 60%) 2.8361\n",
      "258m 10s (- 172m 6s) (6 60%) 2.9108\n",
      "Bleu  6.561604397872349\n",
      "259m 23s (- 172m 55s) (6 60%) 2.8545\n",
      "259m 59s (- 173m 19s) (6 60%) 2.8629\n",
      "260m 36s (- 173m 44s) (6 60%) 2.8869\n",
      "261m 11s (- 174m 7s) (6 60%) 2.8878\n",
      "261m 49s (- 174m 32s) (6 60%) 2.9247\n",
      "262m 24s (- 174m 56s) (6 60%) 2.8996\n",
      "263m 2s (- 175m 21s) (6 60%) 2.9396\n",
      "263m 37s (- 175m 44s) (6 60%) 2.9226\n",
      "264m 15s (- 176m 10s) (6 60%) 2.9190\n",
      "264m 50s (- 176m 33s) (6 60%) 2.9597\n",
      "Bleu  6.407864772921735\n",
      "266m 2s (- 177m 21s) (6 60%) 2.9816\n",
      "266m 38s (- 177m 45s) (6 60%) 2.9293\n",
      "267m 16s (- 178m 11s) (6 60%) 2.9582\n",
      "267m 52s (- 178m 35s) (6 60%) 2.9434\n",
      "268m 31s (- 179m 0s) (6 60%) 2.9883\n",
      "269m 7s (- 179m 24s) (6 60%) 2.9867\n",
      "269m 45s (- 179m 50s) (6 60%) 3.0047\n",
      "270m 20s (- 180m 13s) (6 60%) 2.9701\n",
      "270m 58s (- 180m 39s) (6 60%) 2.9918\n",
      "271m 34s (- 181m 3s) (6 60%) 3.0049\n",
      "Bleu  6.293486038652367\n",
      "272m 47s (- 181m 51s) (6 60%) 2.9827\n",
      "273m 23s (- 182m 15s) (6 60%) 2.9884\n",
      "274m 0s (- 182m 40s) (6 60%) 3.0039\n",
      "274m 35s (- 183m 3s) (6 60%) 2.9882\n",
      "275m 12s (- 183m 28s) (6 60%) 3.0642\n",
      "275m 48s (- 183m 52s) (6 60%) 2.9757\n",
      "276m 27s (- 184m 18s) (6 60%) 3.0079\n",
      "277m 3s (- 184m 42s) (6 60%) 3.0322\n",
      "277m 42s (- 185m 8s) (6 60%) 2.9955\n",
      "278m 18s (- 185m 32s) (6 60%) 3.0356\n",
      "Bleu  6.476591203223172\n",
      "279m 33s (- 186m 22s) (6 60%) 3.0156\n",
      "280m 9s (- 186m 46s) (6 60%) 3.0408\n",
      "280m 47s (- 187m 11s) (6 60%) 3.0275\n",
      "281m 22s (- 187m 35s) (6 60%) 3.0531\n",
      "282m 0s (- 188m 0s) (6 60%) 3.0618\n",
      "282m 36s (- 188m 24s) (6 60%) 3.0535\n",
      "283m 14s (- 188m 49s) (6 60%) 3.0815\n",
      "283m 50s (- 189m 13s) (6 60%) 3.0647\n",
      "284m 28s (- 189m 39s) (6 60%) 3.0215\n",
      "285m 4s (- 190m 2s) (6 60%) 3.0614\n",
      "Bleu  6.374171993850828\n",
      "286m 18s (- 190m 52s) (6 60%) 3.0241\n",
      "286m 53s (- 191m 15s) (6 60%) 3.0774\n",
      "287m 31s (- 191m 41s) (6 60%) 3.0916\n",
      "288m 7s (- 192m 4s) (6 60%) 3.0982\n",
      "288m 44s (- 192m 29s) (6 60%) 3.1029\n",
      "289m 20s (- 124m 0s) (7 70%) 2.8622\n",
      "289m 58s (- 124m 16s) (7 70%) 2.6123\n",
      "290m 33s (- 124m 31s) (7 70%) 2.5865\n",
      "291m 10s (- 124m 47s) (7 70%) 2.5730\n",
      "291m 46s (- 125m 2s) (7 70%) 2.5913\n",
      "Bleu  6.185066831561227\n",
      "293m 0s (- 125m 34s) (7 70%) 2.6132\n",
      "293m 36s (- 125m 49s) (7 70%) 2.6262\n",
      "294m 13s (- 126m 5s) (7 70%) 2.6027\n",
      "294m 48s (- 126m 20s) (7 70%) 2.6458\n",
      "295m 25s (- 126m 36s) (7 70%) 2.6344\n",
      "296m 0s (- 126m 51s) (7 70%) 2.6758\n",
      "296m 38s (- 127m 7s) (7 70%) 2.6625\n",
      "297m 13s (- 127m 23s) (7 70%) 2.6803\n",
      "297m 51s (- 127m 39s) (7 70%) 2.6779\n",
      "298m 26s (- 127m 54s) (7 70%) 2.6987\n",
      "Bleu  5.934117487145399\n",
      "299m 40s (- 128m 25s) (7 70%) 2.7152\n",
      "300m 15s (- 128m 40s) (7 70%) 2.7004\n",
      "300m 52s (- 128m 56s) (7 70%) 2.6996\n",
      "301m 28s (- 129m 12s) (7 70%) 2.7415\n",
      "302m 5s (- 129m 28s) (7 70%) 2.7258\n",
      "302m 41s (- 129m 43s) (7 70%) 2.7264\n",
      "303m 18s (- 129m 59s) (7 70%) 2.7637\n",
      "303m 53s (- 130m 14s) (7 70%) 2.7401\n",
      "304m 31s (- 130m 30s) (7 70%) 2.7552\n",
      "305m 6s (- 130m 45s) (7 70%) 2.7697\n",
      "Bleu  6.463043784277398\n",
      "306m 20s (- 131m 17s) (7 70%) 2.7605\n",
      "306m 55s (- 131m 32s) (7 70%) 2.7760\n",
      "307m 32s (- 131m 48s) (7 70%) 2.8197\n",
      "308m 7s (- 132m 3s) (7 70%) 2.8293\n",
      "308m 44s (- 132m 19s) (7 70%) 2.8217\n",
      "309m 19s (- 132m 34s) (7 70%) 2.7901\n",
      "309m 57s (- 132m 50s) (7 70%) 2.7725\n",
      "310m 32s (- 133m 5s) (7 70%) 2.8278\n",
      "311m 9s (- 133m 21s) (7 70%) 2.8422\n",
      "311m 44s (- 133m 36s) (7 70%) 2.8527\n",
      "Bleu  6.2395026505679105\n",
      "312m 58s (- 134m 7s) (7 70%) 2.8696\n",
      "313m 33s (- 134m 22s) (7 70%) 2.8488\n",
      "314m 10s (- 134m 38s) (7 70%) 2.8674\n",
      "314m 46s (- 134m 54s) (7 70%) 2.8767\n",
      "315m 23s (- 135m 10s) (7 70%) 2.8684\n",
      "315m 58s (- 135m 25s) (7 70%) 2.8742\n",
      "316m 36s (- 135m 41s) (7 70%) 2.8889\n",
      "317m 11s (- 135m 56s) (7 70%) 2.8483\n",
      "317m 48s (- 136m 12s) (7 70%) 2.8882\n",
      "318m 24s (- 136m 27s) (7 70%) 2.9156\n",
      "Bleu  6.320266097975114\n",
      "319m 37s (- 136m 59s) (7 70%) 2.9115\n",
      "320m 12s (- 137m 14s) (7 70%) 2.8531\n",
      "320m 50s (- 137m 30s) (7 70%) 2.9579\n",
      "321m 25s (- 137m 45s) (7 70%) 2.9217\n",
      "322m 3s (- 138m 1s) (7 70%) 2.8902\n",
      "322m 38s (- 138m 16s) (7 70%) 2.9365\n",
      "323m 15s (- 138m 32s) (7 70%) 2.9469\n",
      "323m 50s (- 138m 47s) (7 70%) 2.9054\n",
      "324m 28s (- 139m 3s) (7 70%) 2.9277\n",
      "325m 3s (- 139m 18s) (7 70%) 2.9155\n",
      "Bleu  6.998735078756999\n",
      "326m 16s (- 139m 49s) (7 70%) 2.9563\n",
      "326m 51s (- 140m 5s) (7 70%) 2.9201\n",
      "327m 29s (- 140m 21s) (7 70%) 2.9527\n",
      "328m 4s (- 140m 36s) (7 70%) 2.9723\n",
      "328m 41s (- 140m 52s) (7 70%) 2.9622\n",
      "329m 16s (- 141m 7s) (7 70%) 2.9263\n",
      "329m 54s (- 141m 23s) (7 70%) 2.8959\n",
      "330m 29s (- 141m 38s) (7 70%) 2.8799\n",
      "331m 7s (- 141m 54s) (7 70%) 2.9761\n",
      "331m 42s (- 142m 9s) (7 70%) 2.9834\n",
      "Bleu  6.517738006487763\n",
      "332m 57s (- 142m 41s) (7 70%) 3.0170\n",
      "333m 32s (- 142m 56s) (7 70%) 2.9790\n",
      "334m 10s (- 143m 12s) (7 70%) 2.9458\n",
      "334m 45s (- 83m 41s) (8 80%) 2.5494\n",
      "335m 22s (- 83m 50s) (8 80%) 2.4737\n",
      "335m 57s (- 83m 59s) (8 80%) 2.5089\n",
      "336m 35s (- 84m 8s) (8 80%) 2.4735\n",
      "337m 10s (- 84m 17s) (8 80%) 2.5126\n",
      "337m 48s (- 84m 27s) (8 80%) 2.5294\n",
      "338m 23s (- 84m 35s) (8 80%) 2.5460\n",
      "Bleu  6.351511975160736\n",
      "339m 38s (- 84m 54s) (8 80%) 2.5499\n",
      "340m 14s (- 85m 3s) (8 80%) 2.5276\n",
      "340m 52s (- 85m 13s) (8 80%) 2.6302\n",
      "341m 27s (- 85m 21s) (8 80%) 2.5847\n",
      "342m 5s (- 85m 31s) (8 80%) 2.6012\n",
      "342m 40s (- 85m 40s) (8 80%) 2.6005\n",
      "343m 18s (- 85m 49s) (8 80%) 2.5903\n",
      "343m 53s (- 85m 58s) (8 80%) 2.6438\n",
      "344m 31s (- 86m 7s) (8 80%) 2.5930\n",
      "345m 6s (- 86m 16s) (8 80%) 2.6353\n",
      "Bleu  6.499778716522543\n",
      "346m 20s (- 86m 35s) (8 80%) 2.6290\n",
      "346m 55s (- 86m 43s) (8 80%) 2.6115\n",
      "347m 33s (- 86m 53s) (8 80%) 2.6180\n",
      "348m 8s (- 87m 2s) (8 80%) 2.6385\n",
      "348m 48s (- 87m 12s) (8 80%) 2.6604\n",
      "349m 23s (- 87m 20s) (8 80%) 2.6440\n",
      "350m 1s (- 87m 30s) (8 80%) 2.6720\n",
      "350m 36s (- 87m 39s) (8 80%) 2.6764\n",
      "351m 14s (- 87m 48s) (8 80%) 2.7069\n",
      "351m 50s (- 87m 57s) (8 80%) 2.6768\n",
      "Bleu  6.260883510600305\n",
      "353m 5s (- 88m 16s) (8 80%) 2.6528\n",
      "353m 40s (- 88m 25s) (8 80%) 2.6884\n",
      "354m 18s (- 88m 34s) (8 80%) 2.7053\n",
      "354m 53s (- 88m 43s) (8 80%) 2.6883\n",
      "355m 31s (- 88m 52s) (8 80%) 2.7858\n",
      "356m 6s (- 89m 1s) (8 80%) 2.7272\n",
      "356m 44s (- 89m 11s) (8 80%) 2.7219\n",
      "357m 19s (- 89m 19s) (8 80%) 2.7690\n",
      "357m 57s (- 89m 29s) (8 80%) 2.7800\n",
      "358m 32s (- 89m 38s) (8 80%) 2.7457\n",
      "Bleu  6.845126225693957\n",
      "359m 46s (- 89m 56s) (8 80%) 2.7745\n",
      "360m 22s (- 90m 5s) (8 80%) 2.8078\n",
      "361m 0s (- 90m 15s) (8 80%) 2.7766\n",
      "361m 35s (- 90m 23s) (8 80%) 2.7567\n",
      "362m 13s (- 90m 33s) (8 80%) 2.8155\n",
      "362m 48s (- 90m 42s) (8 80%) 2.7896\n",
      "363m 25s (- 90m 51s) (8 80%) 2.7935\n",
      "364m 1s (- 91m 0s) (8 80%) 2.8098\n",
      "364m 39s (- 91m 9s) (8 80%) 2.8158\n",
      "365m 14s (- 91m 18s) (8 80%) 2.8201\n",
      "Bleu  6.398102699252079\n",
      "366m 28s (- 91m 37s) (8 80%) 2.7960\n",
      "367m 3s (- 91m 45s) (8 80%) 2.8247\n",
      "367m 42s (- 91m 55s) (8 80%) 2.8304\n",
      "368m 17s (- 92m 4s) (8 80%) 2.8224\n",
      "368m 55s (- 92m 13s) (8 80%) 2.8293\n",
      "369m 30s (- 92m 22s) (8 80%) 2.8279\n",
      "370m 8s (- 92m 32s) (8 80%) 2.8448\n",
      "370m 44s (- 92m 41s) (8 80%) 2.8487\n",
      "371m 22s (- 92m 50s) (8 80%) 2.8582\n",
      "371m 57s (- 92m 59s) (8 80%) 2.8667\n",
      "Bleu  6.443391824736274\n",
      "373m 12s (- 93m 18s) (8 80%) 2.8358\n",
      "373m 47s (- 93m 26s) (8 80%) 2.8364\n",
      "374m 25s (- 93m 36s) (8 80%) 2.8505\n",
      "375m 1s (- 93m 45s) (8 80%) 2.8662\n",
      "375m 38s (- 93m 54s) (8 80%) 2.9222\n",
      "376m 14s (- 94m 3s) (8 80%) 2.8822\n",
      "376m 52s (- 94m 13s) (8 80%) 2.8834\n",
      "377m 27s (- 94m 21s) (8 80%) 2.8832\n",
      "378m 5s (- 94m 31s) (8 80%) 2.8917\n",
      "378m 40s (- 94m 40s) (8 80%) 2.9008\n",
      "Bleu  6.989315022096038\n",
      "379m 54s (- 42m 12s) (9 90%) 2.8150\n",
      "380m 30s (- 42m 16s) (9 90%) 2.4294\n",
      "381m 8s (- 42m 20s) (9 90%) 2.4245\n",
      "381m 43s (- 42m 24s) (9 90%) 2.4519\n",
      "382m 21s (- 42m 29s) (9 90%) 2.4035\n",
      "382m 56s (- 42m 32s) (9 90%) 2.4405\n",
      "383m 34s (- 42m 37s) (9 90%) 2.4572\n",
      "384m 9s (- 42m 41s) (9 90%) 2.4460\n",
      "384m 47s (- 42m 45s) (9 90%) 2.4635\n",
      "385m 23s (- 42m 49s) (9 90%) 2.4780\n",
      "Bleu  6.146395976393944\n",
      "386m 36s (- 42m 57s) (9 90%) 2.4706\n",
      "387m 11s (- 43m 1s) (9 90%) 2.5194\n",
      "387m 49s (- 43m 5s) (9 90%) 2.5358\n",
      "388m 25s (- 43m 9s) (9 90%) 2.5149\n",
      "389m 3s (- 43m 13s) (9 90%) 2.5530\n",
      "389m 38s (- 43m 17s) (9 90%) 2.5122\n",
      "390m 16s (- 43m 21s) (9 90%) 2.5343\n",
      "390m 51s (- 43m 25s) (9 90%) 2.5544\n",
      "391m 29s (- 43m 29s) (9 90%) 2.5561\n",
      "392m 4s (- 43m 33s) (9 90%) 2.5871\n",
      "Bleu  6.340574226350288\n",
      "393m 17s (- 43m 41s) (9 90%) 2.5787\n",
      "393m 52s (- 43m 45s) (9 90%) 2.6022\n",
      "394m 30s (- 43m 50s) (9 90%) 2.5944\n",
      "395m 5s (- 43m 53s) (9 90%) 2.5808\n",
      "395m 43s (- 43m 58s) (9 90%) 2.6052\n",
      "396m 18s (- 44m 2s) (9 90%) 2.6651\n",
      "396m 56s (- 44m 6s) (9 90%) 2.6637\n",
      "397m 31s (- 44m 10s) (9 90%) 2.6425\n",
      "398m 9s (- 44m 14s) (9 90%) 2.6086\n",
      "398m 44s (- 44m 18s) (9 90%) 2.6678\n",
      "Bleu  6.487593629444101\n",
      "399m 58s (- 44m 26s) (9 90%) 2.6837\n",
      "400m 33s (- 44m 30s) (9 90%) 2.6496\n",
      "401m 11s (- 44m 34s) (9 90%) 2.6864\n",
      "401m 46s (- 44m 38s) (9 90%) 2.7195\n",
      "402m 24s (- 44m 42s) (9 90%) 2.6647\n",
      "402m 59s (- 44m 46s) (9 90%) 2.7100\n",
      "403m 37s (- 44m 50s) (9 90%) 2.6779\n",
      "404m 12s (- 44m 54s) (9 90%) 2.6861\n",
      "404m 49s (- 44m 58s) (9 90%) 2.6908\n",
      "405m 24s (- 45m 2s) (9 90%) 2.7062\n",
      "Bleu  6.309194698376794\n",
      "406m 39s (- 45m 11s) (9 90%) 2.6740\n",
      "407m 16s (- 45m 15s) (9 90%) 2.7641\n",
      "407m 54s (- 45m 19s) (9 90%) 2.7095\n",
      "408m 30s (- 45m 23s) (9 90%) 2.7201\n",
      "409m 9s (- 45m 27s) (9 90%) 2.7517\n",
      "409m 45s (- 45m 31s) (9 90%) 2.7069\n",
      "410m 22s (- 45m 35s) (9 90%) 2.7128\n",
      "410m 58s (- 45m 39s) (9 90%) 2.7448\n",
      "411m 36s (- 45m 44s) (9 90%) 2.7302\n",
      "412m 11s (- 45m 47s) (9 90%) 2.7598\n",
      "Bleu  6.355759310302617\n",
      "413m 24s (- 45m 56s) (9 90%) 2.7736\n",
      "413m 59s (- 45m 59s) (9 90%) 2.7338\n",
      "414m 37s (- 46m 4s) (9 90%) 2.7279\n",
      "415m 13s (- 46m 8s) (9 90%) 2.7708\n",
      "415m 51s (- 46m 12s) (9 90%) 2.7666\n",
      "416m 26s (- 46m 16s) (9 90%) 2.7591\n",
      "417m 4s (- 46m 20s) (9 90%) 2.7887\n",
      "417m 39s (- 46m 24s) (9 90%) 2.8031\n",
      "418m 17s (- 46m 28s) (9 90%) 2.7876\n",
      "418m 53s (- 46m 32s) (9 90%) 2.7697\n",
      "Bleu  6.61907008747392\n",
      "420m 6s (- 46m 40s) (9 90%) 2.7929\n",
      "420m 42s (- 46m 44s) (9 90%) 2.7931\n",
      "421m 19s (- 46m 48s) (9 90%) 2.7982\n",
      "421m 55s (- 46m 52s) (9 90%) 2.8161\n",
      "422m 32s (- 46m 56s) (9 90%) 2.8357\n",
      "423m 8s (- 47m 0s) (9 90%) 2.8105\n",
      "423m 46s (- 47m 5s) (9 90%) 2.7823\n",
      "424m 21s (- 47m 9s) (9 90%) 2.7966\n",
      "424m 59s (- 0m 0s) (10 100%) 2.5366\n",
      "425m 34s (- 0m 0s) (10 100%) 2.3530\n",
      "Bleu  6.706314882731272\n",
      "426m 48s (- 0m 0s) (10 100%) 2.3692\n",
      "427m 23s (- 0m 0s) (10 100%) 2.3685\n",
      "428m 1s (- 0m 0s) (10 100%) 2.3830\n",
      "428m 37s (- 0m 0s) (10 100%) 2.3645\n",
      "429m 14s (- 0m 0s) (10 100%) 2.4046\n",
      "429m 50s (- 0m 0s) (10 100%) 2.3848\n",
      "430m 28s (- 0m 0s) (10 100%) 2.4440\n",
      "431m 3s (- 0m 0s) (10 100%) 2.4343\n",
      "431m 41s (- 0m 0s) (10 100%) 2.4365\n",
      "432m 16s (- 0m 0s) (10 100%) 2.4329\n",
      "Bleu  6.291850187533066\n",
      "433m 30s (- 0m 0s) (10 100%) 2.4775\n",
      "434m 6s (- 0m 0s) (10 100%) 2.5014\n",
      "434m 44s (- 0m 0s) (10 100%) 2.4495\n",
      "435m 19s (- 0m 0s) (10 100%) 2.4555\n",
      "435m 56s (- 0m 0s) (10 100%) 2.4906\n",
      "436m 31s (- 0m 0s) (10 100%) 2.4683\n",
      "437m 9s (- 0m 0s) (10 100%) 2.4682\n",
      "437m 45s (- 0m 0s) (10 100%) 2.5120\n",
      "438m 23s (- 0m 0s) (10 100%) 2.5233\n",
      "438m 58s (- 0m 0s) (10 100%) 2.5603\n",
      "Bleu  6.479289889295155\n",
      "440m 12s (- 0m 0s) (10 100%) 2.5486\n",
      "440m 48s (- 0m 0s) (10 100%) 2.5562\n",
      "441m 25s (- 0m 0s) (10 100%) 2.5713\n",
      "442m 1s (- 0m 0s) (10 100%) 2.5750\n",
      "442m 39s (- 0m 0s) (10 100%) 2.5481\n",
      "443m 14s (- 0m 0s) (10 100%) 2.5793\n",
      "443m 52s (- 0m 0s) (10 100%) 2.5942\n",
      "444m 27s (- 0m 0s) (10 100%) 2.5902\n",
      "445m 5s (- 0m 0s) (10 100%) 2.5441\n",
      "445m 41s (- 0m 0s) (10 100%) 2.5666\n",
      "Bleu  5.96410849700562\n",
      "446m 55s (- 0m 0s) (10 100%) 2.6057\n",
      "447m 31s (- 0m 0s) (10 100%) 2.6543\n",
      "448m 9s (- 0m 0s) (10 100%) 2.6025\n",
      "448m 44s (- 0m 0s) (10 100%) 2.5761\n",
      "449m 22s (- 0m 0s) (10 100%) 2.6046\n",
      "449m 58s (- 0m 0s) (10 100%) 2.6417\n",
      "450m 37s (- 0m 0s) (10 100%) 2.6663\n",
      "451m 12s (- 0m 0s) (10 100%) 2.6426\n",
      "451m 50s (- 0m 0s) (10 100%) 2.6932\n",
      "452m 25s (- 0m 0s) (10 100%) 2.6330\n",
      "Bleu  6.299649252910662\n",
      "453m 40s (- 0m 0s) (10 100%) 2.6625\n",
      "454m 16s (- 0m 0s) (10 100%) 2.6873\n",
      "454m 54s (- 0m 0s) (10 100%) 2.6513\n",
      "455m 29s (- 0m 0s) (10 100%) 2.6928\n",
      "456m 7s (- 0m 0s) (10 100%) 2.6838\n",
      "456m 43s (- 0m 0s) (10 100%) 2.6687\n",
      "457m 21s (- 0m 0s) (10 100%) 2.7136\n",
      "457m 56s (- 0m 0s) (10 100%) 2.6899\n",
      "458m 34s (- 0m 0s) (10 100%) 2.6701\n",
      "459m 9s (- 0m 0s) (10 100%) 2.7068\n",
      "Bleu  6.364539061485933\n",
      "460m 23s (- 0m 0s) (10 100%) 2.7149\n",
      "460m 58s (- 0m 0s) (10 100%) 2.6717\n",
      "461m 36s (- 0m 0s) (10 100%) 2.6853\n",
      "462m 11s (- 0m 0s) (10 100%) 2.7120\n",
      "462m 49s (- 0m 0s) (10 100%) 2.6990\n",
      "463m 25s (- 0m 0s) (10 100%) 2.7536\n",
      "464m 3s (- 0m 0s) (10 100%) 2.6972\n",
      "464m 38s (- 0m 0s) (10 100%) 2.7888\n",
      "465m 16s (- 0m 0s) (10 100%) 2.7468\n",
      "465m 52s (- 0m 0s) (10 100%) 2.7593\n",
      "Bleu  6.620014725614682\n",
      "467m 5s (- 0m 0s) (10 100%) 2.7555\n",
      "467m 40s (- 0m 0s) (10 100%) 2.7343\n",
      "468m 18s (- 0m 0s) (10 100%) 2.7407\n",
      "468m 54s (- 0m 0s) (10 100%) 2.7585\n",
      "469m 32s (- 0m 0s) (10 100%) 2.7669\n",
      "470m 7s (- 0m 0s) (10 100%) 2.7713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b53979f0b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b53979895c0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses = trainIters(train_loader, encoder, decoder, n_iters=10, \n",
    "                         print_every=50, plot_every=100, validate_every = 500, learning_rate=0.001, \n",
    "                                          teacher_forcing_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:477: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 35s (- 5m 20s) (1 10%) 2.3107\n",
      "1m 11s (- 10m 39s) (1 10%) 2.3422\n",
      "1m 48s (- 16m 19s) (1 10%) 2.3571\n",
      "2m 24s (- 21m 38s) (1 10%) 2.3960\n",
      "3m 2s (- 27m 21s) (1 10%) 2.4258\n",
      "3m 37s (- 32m 40s) (1 10%) 2.4065\n",
      "4m 15s (- 38m 21s) (1 10%) 2.4188\n",
      "4m 51s (- 43m 40s) (1 10%) 2.4107\n",
      "5m 29s (- 49m 21s) (1 10%) 2.4443\n",
      "6m 4s (- 54m 40s) (1 10%) 2.4579\n",
      "Bleu  6.865203369094646\n",
      "7m 19s (- 65m 53s) (1 10%) 2.4767\n",
      "7m 54s (- 71m 12s) (1 10%) 2.4549\n",
      "8m 32s (- 76m 56s) (1 10%) 2.4800\n",
      "9m 8s (- 82m 15s) (1 10%) 2.5201\n",
      "9m 46s (- 87m 58s) (1 10%) 2.5292\n",
      "10m 21s (- 93m 17s) (1 10%) 2.5378\n",
      "10m 59s (- 98m 55s) (1 10%) 2.5319\n",
      "11m 34s (- 104m 14s) (1 10%) 2.5387\n",
      "12m 12s (- 109m 55s) (1 10%) 2.5666\n",
      "12m 48s (- 115m 14s) (1 10%) 2.5464\n",
      "Bleu  6.956523700603462\n",
      "14m 2s (- 126m 25s) (1 10%) 2.5484\n",
      "14m 38s (- 131m 44s) (1 10%) 2.5543\n",
      "15m 16s (- 137m 27s) (1 10%) 2.5883\n",
      "15m 51s (- 142m 46s) (1 10%) 2.5577\n",
      "16m 29s (- 148m 27s) (1 10%) 2.5939\n",
      "17m 5s (- 153m 47s) (1 10%) 2.6072\n",
      "17m 43s (- 159m 28s) (1 10%) 2.6405\n",
      "18m 18s (- 164m 47s) (1 10%) 2.6648\n",
      "18m 56s (- 170m 28s) (1 10%) 2.6122\n",
      "19m 31s (- 175m 47s) (1 10%) 2.6545\n",
      "Bleu  6.551351854980631\n",
      "20m 46s (- 186m 56s) (1 10%) 2.6597\n",
      "21m 21s (- 192m 15s) (1 10%) 2.6648\n",
      "21m 59s (- 197m 56s) (1 10%) 2.6195\n",
      "22m 34s (- 203m 14s) (1 10%) 2.6345\n",
      "23m 12s (- 208m 51s) (1 10%) 2.6959\n",
      "23m 47s (- 214m 9s) (1 10%) 2.6319\n",
      "24m 25s (- 219m 49s) (1 10%) 2.6489\n",
      "25m 0s (- 225m 6s) (1 10%) 2.6875\n",
      "25m 38s (- 230m 49s) (1 10%) 2.6706\n",
      "26m 14s (- 236m 7s) (1 10%) 2.6809\n",
      "Bleu  6.854458832891184\n",
      "27m 28s (- 247m 12s) (1 10%) 2.6936\n",
      "28m 3s (- 252m 30s) (1 10%) 2.6904\n",
      "28m 41s (- 258m 11s) (1 10%) 2.6799\n",
      "29m 16s (- 263m 30s) (1 10%) 2.6936\n",
      "29m 54s (- 269m 10s) (1 10%) 2.7014\n",
      "30m 29s (- 274m 28s) (1 10%) 2.7107\n",
      "31m 7s (- 280m 7s) (1 10%) 2.7110\n",
      "31m 42s (- 285m 24s) (1 10%) 2.6951\n",
      "32m 20s (- 291m 5s) (1 10%) 2.7361\n",
      "32m 55s (- 296m 23s) (1 10%) 2.7342\n",
      "Bleu  6.782485543953762\n",
      "34m 8s (- 307m 19s) (1 10%) 2.7092\n",
      "34m 44s (- 312m 37s) (1 10%) 2.7138\n",
      "35m 22s (- 318m 18s) (1 10%) 2.7089\n",
      "35m 57s (- 323m 35s) (1 10%) 2.7654\n",
      "36m 35s (- 329m 16s) (1 10%) 2.7036\n",
      "37m 10s (- 334m 34s) (1 10%) 2.7348\n",
      "37m 48s (- 340m 12s) (1 10%) 2.7454\n",
      "38m 23s (- 345m 30s) (1 10%) 2.7754\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2e3ef1276292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_losses = trainIters(train_loader, encoder, decoder, n_iters=10, \n\u001b[1;32m      2\u001b[0m                          \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                           teacher_forcing_ratio=1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-e8cf60dc2110>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_iters, print_every, validate_every, plot_every, learning_rate, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                 \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             )\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e8cf60dc2110>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inputs, input_lengths, targets, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length, teacher_forcing_ratio, clip)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;31m# Run through decoder one time step at a time using TEACHER FORCING=1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m     \u001b[0mall_decoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_targ_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_losses = trainIters(train_loader, encoder, decoder, n_iters=10, \n",
    "                         print_every=50, plot_every=100, validate_every = 500, learning_rate=0.001, \n",
    "                                          teacher_forcing_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:477: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ks4841/pytorch-gpu/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 35s (- 5m 19s) (1 10%) 2.2659\n",
      "1m 10s (- 10m 37s) (1 10%) 2.2432\n",
      "1m 48s (- 16m 13s) (1 10%) 2.2702\n",
      "2m 23s (- 21m 30s) (1 10%) 2.2299\n",
      "3m 1s (- 27m 10s) (1 10%) 2.1893\n",
      "3m 36s (- 32m 27s) (1 10%) 2.2344\n",
      "4m 14s (- 38m 6s) (1 10%) 2.2315\n",
      "4m 49s (- 43m 24s) (1 10%) 2.2097\n",
      "5m 27s (- 49m 3s) (1 10%) 2.1909\n",
      "6m 2s (- 54m 20s) (1 10%) 2.1975\n",
      "Bleu  6.960126626842421\n",
      "7m 16s (- 65m 29s) (1 10%) 2.1914\n",
      "7m 51s (- 70m 46s) (1 10%) 2.2174\n",
      "8m 29s (- 76m 27s) (1 10%) 2.1851\n",
      "9m 5s (- 81m 46s) (1 10%) 2.2174\n",
      "9m 42s (- 87m 26s) (1 10%) 2.2180\n",
      "10m 18s (- 92m 45s) (1 10%) 2.2205\n",
      "10m 56s (- 98m 28s) (1 10%) 2.1849\n",
      "11m 31s (- 103m 46s) (1 10%) 2.2021\n",
      "12m 9s (- 109m 25s) (1 10%) 2.1927\n",
      "12m 44s (- 114m 42s) (1 10%) 2.2078\n",
      "Bleu  7.116369505133828\n",
      "13m 59s (- 125m 53s) (1 10%) 2.1861\n",
      "14m 34s (- 131m 10s) (1 10%) 2.1669\n",
      "15m 12s (- 136m 53s) (1 10%) 2.1796\n",
      "15m 47s (- 142m 11s) (1 10%) 2.2050\n",
      "16m 25s (- 147m 50s) (1 10%) 2.1495\n",
      "17m 0s (- 153m 7s) (1 10%) 2.1621\n",
      "17m 38s (- 158m 48s) (1 10%) 2.1933\n",
      "18m 14s (- 164m 6s) (1 10%) 2.1879\n",
      "18m 51s (- 169m 47s) (1 10%) 2.1594\n",
      "19m 27s (- 175m 4s) (1 10%) 2.1989\n",
      "Bleu  7.093602968394659\n",
      "20m 41s (- 186m 14s) (1 10%) 2.1932\n",
      "21m 16s (- 191m 32s) (1 10%) 2.1670\n",
      "21m 54s (- 197m 11s) (1 10%) 2.1608\n",
      "22m 30s (- 202m 30s) (1 10%) 2.1417\n",
      "23m 8s (- 208m 12s) (1 10%) 2.1982\n",
      "23m 43s (- 213m 30s) (1 10%) 2.1745\n",
      "24m 21s (- 219m 9s) (1 10%) 2.2002\n",
      "24m 56s (- 224m 26s) (1 10%) 2.1463\n",
      "25m 34s (- 230m 6s) (1 10%) 2.1836\n",
      "26m 9s (- 235m 24s) (1 10%) 2.1423\n",
      "Bleu  7.573264834005014\n",
      "27m 23s (- 246m 34s) (1 10%) 2.1971\n",
      "27m 58s (- 251m 49s) (1 10%) 2.1830\n",
      "28m 36s (- 257m 25s) (1 10%) 2.1787\n",
      "29m 11s (- 262m 44s) (1 10%) 2.1721\n",
      "29m 50s (- 268m 36s) (1 10%) 2.1550\n",
      "30m 27s (- 274m 4s) (1 10%) 2.1508\n",
      "31m 5s (- 279m 49s) (1 10%) 2.1429\n",
      "31m 41s (- 285m 15s) (1 10%) 2.1425\n",
      "32m 19s (- 290m 59s) (1 10%) 2.1393\n",
      "32m 55s (- 296m 18s) (1 10%) 2.1883\n",
      "Bleu  7.517244954569493\n",
      "34m 9s (- 307m 28s) (1 10%) 2.1476\n",
      "34m 45s (- 312m 45s) (1 10%) 2.1551\n",
      "35m 22s (- 318m 22s) (1 10%) 2.1551\n",
      "35m 58s (- 323m 42s) (1 10%) 2.1925\n",
      "36m 35s (- 329m 22s) (1 10%) 2.1784\n",
      "37m 11s (- 334m 41s) (1 10%) 2.1810\n",
      "37m 49s (- 340m 21s) (1 10%) 2.1542\n",
      "38m 24s (- 345m 40s) (1 10%) 2.1391\n",
      "39m 2s (- 351m 20s) (1 10%) 2.1630\n",
      "39m 37s (- 356m 39s) (1 10%) 2.1703\n",
      "Bleu  7.535697513961816\n",
      "40m 52s (- 367m 55s) (1 10%) 2.1773\n",
      "41m 28s (- 373m 15s) (1 10%) 2.1598\n",
      "42m 6s (- 378m 57s) (1 10%) 2.1264\n",
      "42m 41s (- 384m 16s) (1 10%) 2.1359\n",
      "43m 19s (- 389m 57s) (1 10%) 2.1678\n",
      "43m 55s (- 395m 15s) (1 10%) 2.1404\n",
      "44m 32s (- 400m 56s) (1 10%) 2.1442\n",
      "45m 8s (- 180m 33s) (2 20%) 2.0956\n",
      "45m 46s (- 183m 5s) (2 20%) 2.0336\n",
      "46m 21s (- 185m 27s) (2 20%) 2.0128\n",
      "Bleu  7.403246325079366\n",
      "47m 36s (- 190m 26s) (2 20%) 2.0103\n",
      "48m 12s (- 192m 48s) (2 20%) 2.0178\n",
      "48m 50s (- 195m 20s) (2 20%) 2.0286\n",
      "49m 25s (- 197m 42s) (2 20%) 2.0167\n",
      "50m 3s (- 200m 14s) (2 20%) 2.0237\n",
      "50m 39s (- 202m 36s) (2 20%) 2.0395\n",
      "51m 17s (- 205m 9s) (2 20%) 2.0165\n",
      "51m 52s (- 207m 31s) (2 20%) 2.0360\n",
      "52m 30s (- 210m 2s) (2 20%) 2.0186\n",
      "53m 6s (- 212m 24s) (2 20%) 2.0161\n",
      "Bleu  7.613772305151324\n",
      "54m 21s (- 217m 24s) (2 20%) 1.9875\n",
      "54m 56s (- 219m 46s) (2 20%) 2.0474\n",
      "55m 34s (- 222m 18s) (2 20%) 2.0346\n",
      "56m 10s (- 224m 41s) (2 20%) 2.0298\n",
      "56m 48s (- 227m 12s) (2 20%) 2.0101\n",
      "57m 23s (- 229m 34s) (2 20%) 2.0456\n",
      "58m 1s (- 232m 6s) (2 20%) 2.0114\n",
      "58m 37s (- 234m 28s) (2 20%) 2.0614\n",
      "59m 15s (- 237m 0s) (2 20%) 2.0520\n",
      "59m 50s (- 239m 22s) (2 20%) 2.0343\n",
      "Bleu  7.779114092758543\n",
      "61m 5s (- 244m 20s) (2 20%) 2.0061\n",
      "61m 40s (- 246m 42s) (2 20%) 2.0390\n",
      "62m 18s (- 249m 15s) (2 20%) 2.0288\n",
      "62m 54s (- 251m 37s) (2 20%) 2.0115\n",
      "63m 32s (- 254m 9s) (2 20%) 2.0236\n",
      "64m 7s (- 256m 31s) (2 20%) 2.0302\n",
      "64m 45s (- 259m 3s) (2 20%) 2.0127\n",
      "65m 21s (- 261m 25s) (2 20%) 2.0671\n",
      "65m 59s (- 263m 57s) (2 20%) 2.0308\n",
      "66m 34s (- 266m 19s) (2 20%) 2.0217\n",
      "Bleu  7.460207588579085\n",
      "67m 49s (- 271m 18s) (2 20%) 2.0132\n",
      "68m 25s (- 273m 40s) (2 20%) 2.0467\n",
      "69m 3s (- 276m 12s) (2 20%) 2.0256\n",
      "69m 38s (- 278m 34s) (2 20%) 2.0480\n",
      "70m 16s (- 281m 7s) (2 20%) 2.0423\n",
      "70m 52s (- 283m 29s) (2 20%) 2.0361\n",
      "71m 30s (- 286m 2s) (2 20%) 2.0288\n",
      "72m 6s (- 288m 24s) (2 20%) 2.0259\n",
      "72m 43s (- 290m 55s) (2 20%) 2.0069\n",
      "73m 19s (- 293m 17s) (2 20%) 2.0632\n",
      "Bleu  7.540248198532134\n",
      "74m 34s (- 298m 17s) (2 20%) 2.0543\n",
      "75m 9s (- 300m 39s) (2 20%) 2.0262\n",
      "75m 47s (- 303m 8s) (2 20%) 2.0337\n",
      "76m 22s (- 305m 30s) (2 20%) 2.0656\n",
      "77m 0s (- 308m 2s) (2 20%) 2.0513\n",
      "77m 35s (- 310m 23s) (2 20%) 2.0217\n",
      "78m 13s (- 312m 55s) (2 20%) 2.0916\n",
      "78m 49s (- 315m 17s) (2 20%) 2.0428\n",
      "79m 27s (- 317m 48s) (2 20%) 2.0333\n",
      "80m 2s (- 320m 10s) (2 20%) 2.0389\n",
      "Bleu  7.523661796041862\n",
      "81m 16s (- 325m 7s) (2 20%) 2.0730\n",
      "81m 52s (- 327m 29s) (2 20%) 2.0557\n",
      "82m 30s (- 330m 0s) (2 20%) 2.0747\n",
      "83m 5s (- 332m 22s) (2 20%) 2.0436\n",
      "83m 43s (- 334m 54s) (2 20%) 2.0353\n",
      "84m 19s (- 337m 16s) (2 20%) 2.0786\n",
      "84m 56s (- 339m 47s) (2 20%) 2.0725\n",
      "85m 32s (- 342m 9s) (2 20%) 2.0433\n",
      "86m 10s (- 344m 41s) (2 20%) 2.0520\n",
      "86m 45s (- 347m 3s) (2 20%) 2.0609\n",
      "Bleu  7.866213253990843\n",
      "88m 0s (- 352m 1s) (2 20%) 2.0650\n",
      "88m 35s (- 354m 23s) (2 20%) 2.0742\n",
      "89m 13s (- 356m 54s) (2 20%) 2.0519\n",
      "89m 49s (- 359m 16s) (2 20%) 2.0510\n",
      "90m 27s (- 361m 48s) (2 20%) 2.0583\n",
      "91m 2s (- 212m 25s) (3 30%) 1.9755\n",
      "91m 40s (- 213m 54s) (3 30%) 1.9289\n",
      "92m 15s (- 215m 17s) (3 30%) 1.9513\n",
      "92m 53s (- 216m 45s) (3 30%) 1.9089\n",
      "93m 29s (- 218m 8s) (3 30%) 1.9044\n",
      "Bleu  7.57433372671091\n",
      "94m 43s (- 221m 2s) (3 30%) 1.9473\n",
      "95m 19s (- 222m 24s) (3 30%) 1.9431\n",
      "95m 57s (- 223m 53s) (3 30%) 1.9165\n",
      "96m 32s (- 225m 15s) (3 30%) 1.9683\n",
      "97m 10s (- 226m 43s) (3 30%) 1.9240\n",
      "97m 45s (- 228m 6s) (3 30%) 1.9377\n",
      "98m 23s (- 229m 34s) (3 30%) 1.9044\n",
      "98m 58s (- 230m 57s) (3 30%) 1.9431\n",
      "99m 36s (- 232m 25s) (3 30%) 1.9452\n",
      "100m 12s (- 233m 48s) (3 30%) 1.9425\n",
      "Bleu  7.602258495325931\n",
      "101m 27s (- 236m 43s) (3 30%) 1.9216\n",
      "102m 2s (- 238m 5s) (3 30%) 1.9735\n",
      "102m 39s (- 239m 33s) (3 30%) 1.9151\n",
      "103m 15s (- 240m 55s) (3 30%) 1.9289\n",
      "103m 53s (- 242m 23s) (3 30%) 1.9574\n",
      "104m 28s (- 243m 46s) (3 30%) 1.9733\n",
      "105m 6s (- 245m 14s) (3 30%) 1.9195\n",
      "105m 41s (- 246m 36s) (3 30%) 1.9409\n",
      "106m 19s (- 248m 5s) (3 30%) 1.9245\n",
      "106m 54s (- 249m 27s) (3 30%) 1.9591\n",
      "Bleu  7.484351673255104\n",
      "108m 9s (- 252m 21s) (3 30%) 1.9334\n",
      "108m 44s (- 253m 43s) (3 30%) 1.9779\n",
      "109m 22s (- 255m 11s) (3 30%) 1.9497\n",
      "109m 57s (- 256m 33s) (3 30%) 1.9598\n",
      "110m 35s (- 258m 2s) (3 30%) 1.9864\n",
      "111m 10s (- 259m 24s) (3 30%) 1.9225\n",
      "111m 48s (- 260m 52s) (3 30%) 1.9550\n",
      "112m 23s (- 262m 15s) (3 30%) 1.9476\n",
      "113m 1s (- 263m 43s) (3 30%) 1.9617\n",
      "113m 36s (- 265m 5s) (3 30%) 1.9700\n",
      "Bleu  7.831290124629442\n",
      "114m 50s (- 267m 58s) (3 30%) 1.9599\n",
      "115m 26s (- 269m 21s) (3 30%) 1.9620\n",
      "116m 4s (- 270m 49s) (3 30%) 1.9586\n",
      "116m 39s (- 272m 11s) (3 30%) 1.9665\n",
      "117m 17s (- 273m 40s) (3 30%) 1.9654\n",
      "117m 52s (- 275m 2s) (3 30%) 1.9570\n",
      "118m 29s (- 276m 29s) (3 30%) 1.9424\n",
      "119m 4s (- 277m 51s) (3 30%) 1.9643\n",
      "119m 42s (- 279m 19s) (3 30%) 1.9575\n",
      "120m 17s (- 280m 41s) (3 30%) 1.9488\n",
      "Bleu  7.936370448203016\n",
      "121m 32s (- 283m 35s) (3 30%) 1.9470\n",
      "122m 7s (- 284m 57s) (3 30%) 1.9531\n",
      "122m 45s (- 286m 25s) (3 30%) 1.9997\n",
      "123m 20s (- 287m 47s) (3 30%) 1.9381\n",
      "123m 58s (- 289m 15s) (3 30%) 1.9400\n",
      "124m 33s (- 290m 38s) (3 30%) 1.9833\n",
      "125m 11s (- 292m 5s) (3 30%) 1.9801\n",
      "125m 46s (- 293m 27s) (3 30%) 1.9723\n",
      "126m 23s (- 294m 55s) (3 30%) 1.9817\n",
      "126m 58s (- 296m 17s) (3 30%) 1.9504\n",
      "Bleu  7.773838474702041\n",
      "128m 12s (- 299m 9s) (3 30%) 2.0018\n",
      "128m 47s (- 300m 31s) (3 30%) 1.9891\n",
      "129m 25s (- 301m 59s) (3 30%) 1.9651\n",
      "130m 0s (- 303m 21s) (3 30%) 1.9670\n",
      "130m 38s (- 304m 49s) (3 30%) 1.9809\n",
      "131m 13s (- 306m 11s) (3 30%) 1.9722\n",
      "131m 51s (- 307m 39s) (3 30%) 1.9494\n",
      "132m 26s (- 309m 1s) (3 30%) 1.9811\n",
      "133m 3s (- 310m 29s) (3 30%) 1.9348\n",
      "133m 39s (- 311m 51s) (3 30%) 1.9734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ceadc9b5403f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_losses = trainIters(train_loader, encoder, decoder, n_iters=10, \n\u001b[1;32m      2\u001b[0m                          \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                           teacher_forcing_ratio=1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-e8cf60dc2110>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_iters, print_every, validate_every, plot_every, learning_rate, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalidate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bleu '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e8cf60dc2110>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(encoder, decoder, val_loader)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mdecoded_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e8cf60dc2110>\u001b[0m in \u001b[0;36mevaluate_batch\u001b[0;34m(loader, encoder, decoder)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0;31m# Go sentence by sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m             \u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m             \u001b[0mdecoded_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0mactual_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e8cf60dc2110>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, input_lengths, translated, search, max_length)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             decoder_output, decoder_hidden, decoder_att = decoder(\n\u001b[0;32m--> 780\u001b[0;31m                 decoder_input, decoder_hidden, encoder_output)\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;31m# hint: print out decoder_output and decoder_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3d263c674a5a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mconcat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;31m#print (\"concat_input\", concat_input.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mconcat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0;31m#print (\"concat_output\", concat_output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/nlp/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-gpu/nlp/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_losses = trainIters(train_loader, encoder, decoder, n_iters=10, \n",
    "                         print_every=50, plot_every=100, validate_every = 500, learning_rate=0.0001, \n",
    "                                          teacher_forcing_ratio=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the final version on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang_t, output_lang_t, pairs_t = prepareData(en_loc+'/test.tok.vi', en_loc+'/test.tok.en', \n",
    "                                                   embedding_in = embeddings_vi,\n",
    "                                                   embedding_out = embeddings_en,\n",
    "                                                   num_sent=None)\n",
    "\n",
    "test_dataset = VocabDataset(pairs_t, input_lang.word2index, output_lang.word2index)\n",
    "# 1 batch input dimension: num_sentences x max sentence length\n",
    "# 1 batch: source_sentences, target_sentences, source_lengths, target_lengths\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "validate(encoder, decoder, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
