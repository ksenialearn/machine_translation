{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stella_Sun.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "cK0Z6BEm4Ygp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "GFHdAEFQtTRG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install torch"
      ]
    },
    {
      "metadata": {
        "id": "YJl1CJvlt5gG",
        "colab_type": "code",
        "outputId": "4aea8846-d60e-4d23-d8ca-d3d8a900077a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x59368000 @  0x7ff2844d22a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xAQHOkBolXXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Pacgages"
      ]
    },
    {
      "metadata": {
        "id": "gOAe8qRguGdA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import pickle as pkl\n",
        "import random\n",
        "import pdb\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import unicodedata\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "#specify SOS() and EOS(end of sentence)\n",
        "#specify maximum vocabulary size = 50000\n",
        "PAD_IDX = 2\n",
        "UNK_IDX = 3\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_VOCAB_SIZE = 800000\n",
        "MAX_LENGTH = 50\n",
        "\n",
        "train_en = 'data/train.tok.en'\n",
        "train_zh = 'data/train.tok.zh'\n",
        "val_en = 'data/dev.tok.en'\n",
        "val_zh = 'data/dev.tok.zh'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PsEuCzYYuMoR",
        "colab_type": "code",
        "outputId": "5b343322-3295-4ae4-c826-5370ce9a2f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#user GPU if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "  print(\"Currently using GPU\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently using GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0FntyL6ovSDY",
        "colab_type": "code",
        "outputId": "61e43e56-c690-4685-aa31-301214b97b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5vc0D8zWxu_p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Embedding"
      ]
    },
    {
      "metadata": {
        "id": "6FZwLxswviX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "folder_path = os.getcwd() + '/gdrive/My Drive/NLP_Project/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JrucOX2bsLUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"<SOS>\":0, \"<EOS>\":1, \"<PAD>\":2, \"<UNK>\":3}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\", 3:\"<UNK>\"}\n",
        "        self.n_words = 4  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines_lang1 = open(folder_path+'data/train.tok.{}'.format(lang1), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    lines_lang2 = open(folder_path+'data/train.tok.{}'.format(lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    \n",
        "    assert (len(lines_lang1)==len(lines_lang2))\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[lines_lang1[i], normalizeString(lines_lang2[i])] for i in range (len(lines_lang1))]\n",
        "    #print (pairs[-1])\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGFkxsahuPPT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_emb_matrix(language):\n",
        "    #load fasttext word vectors\n",
        "    words_to_load = MAX_VOCAB_SIZE\n",
        "    if language == 'english':\n",
        "      file = 'wiki-news-300d-1M-subword.vec'\n",
        "    if language == 'chinese':\n",
        "      file = 'cc.zh.300.vec'\n",
        "    \n",
        "\n",
        "    with open(folder_path + 'data/' + file) as f:\n",
        "        #remove the first line\n",
        "        firstLine = f.readline()\n",
        "        loaded_embeddings = np.zeros((words_to_load + 4, 300))\n",
        "        words2id = {}\n",
        "        idx2words = {}\n",
        "        #ordered_words = []\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= words_to_load: \n",
        "                break\n",
        "            s = line.split()\n",
        "            loaded_embeddings[i + 4 , :] = np.asarray(s[1:])\n",
        "            words2id['<SOS>'] = SOS_token\n",
        "            words2id['<EOS>'] = EOS_token\n",
        "            words2id['<pad>'] = PAD_IDX\n",
        "            words2id['<unk>'] = UNK_IDX\n",
        "            words2id[s[0]] = i + 4\n",
        "            \n",
        "            idx2words[0] = '<SOS>'\n",
        "            idx2words[1] = '<EOD>'\n",
        "            idx2words[2] = '<pad>'\n",
        "            idx2words[3] = '<unk>'\n",
        "            \n",
        "            idx2words[i + 4] = s[0]\n",
        "   \n",
        "\n",
        "    return words2id,idx2words,loaded_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxBmZe6Yucnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_weights_matrix(index2word_lang, word2index_lang, index2word_embed, word2index_embed, loaded_embeddings):\n",
        "    emb_dim=300\n",
        "    missing_count=0\n",
        "    matrix_len = len(index2word_lang)\n",
        "    weights_matrix = np.zeros((matrix_len, 300))\n",
        "    \n",
        "    for key in index2word_lang.keys():\n",
        "        word=index2word_lang[key]\n",
        "        if (word in word2index_embed.keys()):\n",
        "          weights_matrix[key] = loaded_embeddings[word2index_embed[word]]\n",
        "        else:\n",
        "          missing_count=missing_count+1\n",
        "          weights_matrix[key] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
        "    print (missing_count)\n",
        "    return weights_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBRaSTyItmS5",
        "colab_type": "code",
        "outputId": "477a066a-260a-4764-8d60-db8188724261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "train_input_lang, train_output_lang, train_pairs = prepareData(\"zh\", \"en\", reverse=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 213376 sentence pairs\n",
            "Trimmed to 193446 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "zh 79368\n",
            "en 45471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FdZ2rxHMueaH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# words2id_eng,idx2words_eng,loaded_embeddings_eng = load_emb_matrix('english')\n",
        "# words2id_zh,idx2words_zh,loaded_embeddings_zh = load_emb_matrix('chinese')\n",
        "\n",
        "# pkl.dump(words2id_eng, open(folder_path + 'data/words2id_eng_1M.pkl', 'wb'))\n",
        "# pkl.dump(idx2words_eng, open(folder_path +'data/idx2words_eng_1M.pkl', 'wb'))\n",
        "# pkl.dump(loaded_embeddings_eng, open(folder_path +'data/embedding_matrix_eng_1M.pkl', 'wb'))\n",
        "\n",
        "# pkl.dump(words2id_zh, open(folder_path + 'data/words2id_zh_1M.pkl', 'wb'))\n",
        "# pkl.dump(idx2words_zh, open(folder_path + 'data/idx2words_zh_1M.pkl', 'wb'))\n",
        "# pkl.dump(loaded_embeddings_zh, open(folder_path +'data/embedding_matrix_zh_1M.pkl', 'wb'))\n",
        "\n",
        "words2id_eng=pkl.load(open(folder_path + 'data/words2id_eng_1M.pkl', 'rb'))\n",
        "idx2words_eng=pkl.load(open(folder_path +'data/idx2words_eng_1M.pkl', 'rb'))\n",
        "loaded_embeddings_eng=pkl.load(open(folder_path +'data/embedding_matrix_eng_1M.pkl', 'rb'))\n",
        "\n",
        "words2id_zh=pkl.load(open(folder_path + 'data/words2id_zh_1M.pkl', 'rb'))\n",
        "idx2words_zh=pkl.load(open(folder_path + 'data/idx2words_zh_1M.pkl', 'rb'))\n",
        "loaded_embeddings_zh=pkl.load(open(folder_path +'data/embedding_matrix_zh_1M.pkl', 'rb'))\n",
        "\n",
        "# #load embeding matrix\n",
        "# words2id_eng = pkl.load(open(folder_path + 'data/words2id_eng.pkl', 'rb'))\n",
        "# idx2words_eng = pkl.load(open(folder_path +'data/idx2words_eng.pkl', 'rb'))\n",
        "# loaded_embeddings_eng= pkl.load(open(folder_path +'data/embedding_matrix_eng.pkl', 'rb'))\n",
        "\n",
        "\n",
        "# words2id_zh = pkl.load(open(folder_path + 'data/words2id_zh.pkl', 'rb'))\n",
        "# idx2words_zh = pkl.load(open(folder_path +'data/idx2words_zh.pkl', 'rb'))\n",
        "# loaded_embeddings_zh= pkl.load(open(folder_path +'data/embedding_matrix_zh.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFouTPE8xLzg",
        "colab_type": "code",
        "outputId": "07a34011-766e-4ef3-9197-4d1e19b2cbd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "weights_matrix_eng=generate_weights_matrix(train_output_lang.index2word, train_output_lang.word2index, idx2words_eng, words2id_eng, loaded_embeddings_eng)\n",
        "weights_matrix_eng = torch.from_numpy(weights_matrix_eng).to(device)\n",
        "\n",
        "\n",
        "weights_matrix_zh=generate_weights_matrix(train_input_lang.index2word, train_input_lang.word2index, idx2words_zh, words2id_zh, loaded_embeddings_zh) \n",
        "weights_matrix_zh = torch.from_numpy(weights_matrix_zh).to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6387\n",
            "19084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2UL5zzkP307M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pkl.dump(weights_matrix_eng, open(folder_path +'data/weights_matrix_eng_1M.pkl', 'wb'))\n",
        "# pkl.dump(weights_matrix_zh, open(folder_path +'data/weights_matrix_zh_1M.pkl', 'wb'))\n",
        "\n",
        "weights_matrix_eng=pkl.load(open(folder_path +'data/weights_matrix_eng_1M.pkl', 'rb'))\n",
        "weights_matrix_zh=pkl.load(open(folder_path +'data/weights_matrix_zh_1M.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjOzDI9w4B5f",
        "colab_type": "code",
        "outputId": "cd66040c-ab4b-4509-e2c0-d1cda6b0f9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "words2id_eng[\"they\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "EtQLeRS54pQo",
        "colab_type": "code",
        "outputId": "beb99cdf-b23f-4518-b948-b914033dad46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "weights_matrix_eng[177]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0096,  0.0142, -0.0165, -0.0160,  0.0348, -0.0028, -0.0091, -0.0407,\n",
              "         0.0240,  0.0095, -0.0168, -0.0538, -0.0003, -0.0560,  0.0284,  0.0146,\n",
              "         0.0532,  0.0161,  0.0490, -0.0022, -0.0056, -0.0035,  0.0023,  0.0190,\n",
              "        -0.0233, -0.0374,  0.0185, -0.0271,  0.0885, -0.0025, -0.0349, -0.0071,\n",
              "        -0.0144,  0.0123, -0.0258, -0.0204, -0.0158, -0.0176, -0.0319, -0.0306,\n",
              "        -0.0172, -0.0500, -0.0072,  0.0092,  0.0276, -0.0190,  0.0216, -0.0176,\n",
              "        -0.0389, -0.0024,  0.0283, -0.0001, -0.0173, -0.0021, -0.0721,  0.0124,\n",
              "        -0.0067, -0.0123, -0.0375, -0.0157,  0.0125, -0.0097,  0.0590, -0.0182,\n",
              "         0.0177, -0.0003, -0.0033, -0.0108, -0.0134,  0.0026,  0.0035,  0.0074,\n",
              "         0.0413,  0.0033,  0.0232,  0.0017,  0.0468, -0.0035, -0.0158, -0.0082,\n",
              "        -0.0057,  0.0004,  0.0038,  0.0365, -0.0175, -0.0076,  0.0123, -0.0137,\n",
              "        -0.0067, -0.0055, -0.0076,  0.0203, -0.0616, -0.0454,  0.0277, -0.0569,\n",
              "         0.0300,  0.0189,  0.0033, -0.0035,  0.0426, -0.0114,  0.0228,  0.0061,\n",
              "        -0.0112, -0.0350,  0.0064, -0.0143,  0.0370,  0.0113,  0.0117,  0.0494,\n",
              "         0.0474, -0.0216, -0.0018,  0.0151, -0.0205, -0.0041, -0.0168, -0.0107,\n",
              "         0.0035,  0.0103,  0.0050,  0.0036, -0.0004, -0.0087, -0.0222, -0.0003,\n",
              "         0.0024,  0.0407, -0.0029,  0.0028,  0.0134,  0.0132,  0.0039,  0.0099,\n",
              "        -0.0140,  0.0113, -0.0184,  0.0274, -0.0018, -0.0189, -0.0178, -0.0092,\n",
              "         0.0135,  0.0179,  0.0208,  0.0189, -0.0382, -0.0089,  0.0493,  0.1304,\n",
              "        -0.0295, -0.0144,  0.0133, -0.0104,  0.0103, -0.0243, -0.0138, -0.0149,\n",
              "         0.0025,  0.0099, -0.0204, -0.0067,  0.0278, -0.0017,  0.0169, -0.0022,\n",
              "         0.0199, -0.0137,  0.0302, -0.0263,  0.0032, -0.0141, -0.0275,  0.0244,\n",
              "        -0.0119,  0.0173,  0.0092, -0.0130,  0.0302, -0.0017, -0.0119,  0.0042,\n",
              "        -0.0097, -0.0487, -0.0053,  0.1185,  0.0027,  0.0042, -0.0217,  0.0891,\n",
              "        -0.1056,  0.0014,  0.0080,  0.0138,  0.0283, -0.0121,  0.0151, -0.0076,\n",
              "        -0.0931,  0.0415, -0.0057,  0.0033,  0.0249, -0.0187,  0.0033, -0.0031,\n",
              "        -0.0012, -0.1359, -0.0273, -0.0069,  0.0598,  0.0071,  0.0136, -0.0147,\n",
              "        -0.0193,  0.0040, -0.0480, -0.0233,  0.0047, -0.0128, -0.0007,  0.0818,\n",
              "         0.0108, -0.0086,  0.0245,  0.0148, -0.0147,  0.0368,  0.0009, -0.0577,\n",
              "        -0.0909, -0.0243, -0.0009,  0.0005,  0.0209, -0.0088, -0.0045, -0.0087,\n",
              "         0.0918,  0.0132, -0.0066,  0.0166,  0.0292, -0.0156, -0.0161, -0.0643,\n",
              "         0.0041, -0.0422,  0.0009,  0.0299,  0.0224,  0.0062, -0.0650,  0.0235,\n",
              "        -0.0223, -0.0007, -0.0214, -0.0243, -0.0228,  0.0367,  0.0174, -0.0236,\n",
              "         0.0206,  0.0070,  0.0061, -0.0086, -0.0250,  0.0379, -0.0045,  0.0716,\n",
              "        -0.0705, -0.0277, -0.0035, -0.0107, -0.0051,  0.0112,  0.0155, -0.0260,\n",
              "        -0.0648,  0.0269,  0.0055,  0.0013, -0.0040,  0.0028,  0.0082, -0.0175,\n",
              "        -0.0084,  0.0217, -0.0041,  0.0129, -0.0140,  0.0289,  0.0235, -0.0296,\n",
              "         0.0298,  0.0087, -0.0267,  0.0207],\n",
              "       device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "8cyLitkK4mic",
        "colab_type": "code",
        "outputId": "ebc5443f-ed00-4182-ce6a-25ea2d2528e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "cell_type": "code",
      "source": [
        "loaded_embeddings_eng[74]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.600e-03,  1.420e-02, -1.650e-02, -1.600e-02,  3.480e-02,\n",
              "       -2.800e-03, -9.100e-03, -4.070e-02,  2.400e-02,  9.500e-03,\n",
              "       -1.680e-02, -5.380e-02, -3.000e-04, -5.600e-02,  2.840e-02,\n",
              "        1.460e-02,  5.320e-02,  1.610e-02,  4.900e-02, -2.200e-03,\n",
              "       -5.600e-03, -3.500e-03,  2.300e-03,  1.900e-02, -2.330e-02,\n",
              "       -3.740e-02,  1.850e-02, -2.710e-02,  8.850e-02, -2.500e-03,\n",
              "       -3.490e-02, -7.100e-03, -1.440e-02,  1.230e-02, -2.580e-02,\n",
              "       -2.040e-02, -1.580e-02, -1.760e-02, -3.190e-02, -3.060e-02,\n",
              "       -1.720e-02, -5.000e-02, -7.200e-03,  9.200e-03,  2.760e-02,\n",
              "       -1.900e-02,  2.160e-02, -1.760e-02, -3.890e-02, -2.400e-03,\n",
              "        2.830e-02, -1.000e-04, -1.730e-02, -2.100e-03, -7.210e-02,\n",
              "        1.240e-02, -6.700e-03, -1.230e-02, -3.750e-02, -1.570e-02,\n",
              "        1.250e-02, -9.700e-03,  5.900e-02, -1.820e-02,  1.770e-02,\n",
              "       -3.000e-04, -3.300e-03, -1.080e-02, -1.340e-02,  2.600e-03,\n",
              "        3.500e-03,  7.400e-03,  4.130e-02,  3.300e-03,  2.320e-02,\n",
              "        1.700e-03,  4.680e-02, -3.500e-03, -1.580e-02, -8.200e-03,\n",
              "       -5.700e-03,  4.000e-04,  3.800e-03,  3.650e-02, -1.750e-02,\n",
              "       -7.600e-03,  1.230e-02, -1.370e-02, -6.700e-03, -5.500e-03,\n",
              "       -7.600e-03,  2.030e-02, -6.160e-02, -4.540e-02,  2.770e-02,\n",
              "       -5.690e-02,  3.000e-02,  1.890e-02,  3.300e-03, -3.500e-03,\n",
              "        4.260e-02, -1.140e-02,  2.280e-02,  6.100e-03, -1.120e-02,\n",
              "       -3.500e-02,  6.400e-03, -1.430e-02,  3.700e-02,  1.130e-02,\n",
              "        1.170e-02,  4.940e-02,  4.740e-02, -2.160e-02, -1.800e-03,\n",
              "        1.510e-02, -2.050e-02, -4.100e-03, -1.680e-02, -1.070e-02,\n",
              "        3.500e-03,  1.030e-02,  5.000e-03,  3.600e-03, -4.000e-04,\n",
              "       -8.700e-03, -2.220e-02, -3.000e-04,  2.400e-03,  4.070e-02,\n",
              "       -2.900e-03,  2.800e-03,  1.340e-02,  1.320e-02,  3.900e-03,\n",
              "        9.900e-03, -1.400e-02,  1.130e-02, -1.840e-02,  2.740e-02,\n",
              "       -1.800e-03, -1.890e-02, -1.780e-02, -9.200e-03,  1.350e-02,\n",
              "        1.790e-02,  2.080e-02,  1.890e-02, -3.820e-02, -8.900e-03,\n",
              "        4.930e-02,  1.304e-01, -2.950e-02, -1.440e-02,  1.330e-02,\n",
              "       -1.040e-02,  1.030e-02, -2.430e-02, -1.380e-02, -1.490e-02,\n",
              "        2.500e-03,  9.900e-03, -2.040e-02, -6.700e-03,  2.780e-02,\n",
              "       -1.700e-03,  1.690e-02, -2.200e-03,  1.990e-02, -1.370e-02,\n",
              "        3.020e-02, -2.630e-02,  3.200e-03, -1.410e-02, -2.750e-02,\n",
              "        2.440e-02, -1.190e-02,  1.730e-02,  9.200e-03, -1.300e-02,\n",
              "        3.020e-02, -1.700e-03, -1.190e-02,  4.200e-03, -9.700e-03,\n",
              "       -4.870e-02, -5.300e-03,  1.185e-01,  2.700e-03,  4.200e-03,\n",
              "       -2.170e-02,  8.910e-02, -1.056e-01,  1.400e-03,  8.000e-03,\n",
              "        1.380e-02,  2.830e-02, -1.210e-02,  1.510e-02, -7.600e-03,\n",
              "       -9.310e-02,  4.150e-02, -5.700e-03,  3.300e-03,  2.490e-02,\n",
              "       -1.870e-02,  3.300e-03, -3.100e-03, -1.200e-03, -1.359e-01,\n",
              "       -2.730e-02, -6.900e-03,  5.980e-02,  7.100e-03,  1.360e-02,\n",
              "       -1.470e-02, -1.930e-02,  4.000e-03, -4.800e-02, -2.330e-02,\n",
              "        4.700e-03, -1.280e-02, -7.000e-04,  8.180e-02,  1.080e-02,\n",
              "       -8.600e-03,  2.450e-02,  1.480e-02, -1.470e-02,  3.680e-02,\n",
              "        9.000e-04, -5.770e-02, -9.090e-02, -2.430e-02, -9.000e-04,\n",
              "        5.000e-04,  2.090e-02, -8.800e-03, -4.500e-03, -8.700e-03,\n",
              "        9.180e-02,  1.320e-02, -6.600e-03,  1.660e-02,  2.920e-02,\n",
              "       -1.560e-02, -1.610e-02, -6.430e-02,  4.100e-03, -4.220e-02,\n",
              "        9.000e-04,  2.990e-02,  2.240e-02,  6.200e-03, -6.500e-02,\n",
              "        2.350e-02, -2.230e-02, -7.000e-04, -2.140e-02, -2.430e-02,\n",
              "       -2.280e-02,  3.670e-02,  1.740e-02, -2.360e-02,  2.060e-02,\n",
              "        7.000e-03,  6.100e-03, -8.600e-03, -2.500e-02,  3.790e-02,\n",
              "       -4.500e-03,  7.160e-02, -7.050e-02, -2.770e-02, -3.500e-03,\n",
              "       -1.070e-02, -5.100e-03,  1.120e-02,  1.550e-02, -2.600e-02,\n",
              "       -6.480e-02,  2.690e-02,  5.500e-03,  1.300e-03, -4.000e-03,\n",
              "        2.800e-03,  8.200e-03, -1.750e-02, -8.400e-03,  2.170e-02,\n",
              "       -4.100e-03,  1.290e-02, -1.400e-02,  2.890e-02,  2.350e-02,\n",
              "       -2.960e-02,  2.980e-02,  8.700e-03, -2.670e-02,  2.070e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "eVIfRDKA0Z2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def generate_weights_matrix(idx2words,loaded_embeddings):\n",
        "   \n",
        "#     matrix_len = len(idx2words)\n",
        "#     weights_matrix = np.zeros((matrix_len, 300))\n",
        "    \n",
        "#     for key in idx2words.keys():\n",
        "        \n",
        "#         try: \n",
        "#             weights_matrix[key]\n",
        "#             loaded_embeddings[key]\n",
        "#             weights_matrix[key] = loaded_embeddings[key]\n",
        "#         except KeyError:\n",
        "#             weights_matrix[key] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
        "#     return weights_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZkL7tHO1Gk5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# words2id_eng,idx2words_eng,loaded_embeddings_eng = load_emb_matrix('english')\n",
        "# words2id_zh,idx2words_zh,loaded_embeddings_zh = load_emb_matrix('chinese')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ku5T3oez1RPH",
        "colab_type": "code",
        "outputId": "1851ecb6-30ea-4ef1-ad3d-3d7c449fa6d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# weights_matrix_eng=generate_weights_matrix(idx2words,loaded_embeddings_eng)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tsDhDz0Jo57e",
        "colab_type": "code",
        "outputId": "1f95321c-c53f-4776-8309-4c3c312013b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# weights_matrix_eng.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([79366, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "htO3kD7foNsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# words2id_eng = output_lang.word2index\n",
        "# idx2words_eng= output_lang.index2word\n",
        "# loaded_embeddings_eng= pkl.load(open(folder_path +'data/embedding_matrix_eng.pkl', 'rb'))\n",
        "# words2id_zh = input_lang.word2index\n",
        "# idx2words_zh= input_lang.index2word\n",
        "# loaded_embeddings_zh= pkl.load(open(folder_path +'data/embedding_matrix_zh.pkl', 'rb'))\n",
        "# weights_matrix_eng = generate_weights_matrix(idx2words_eng,loaded_embeddings_eng)\n",
        "# weights_matrix_zh = generate_weights_matrix(idx2words_zh,loaded_embeddings_zh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNs5BYqvuiIq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #weights_matrix_eng = generate_weights_matrix(idx2words_eng,loaded_embeddings_eng)\n",
        "# #pkl.dump(weights_matrix_eng, open(folder_path + 'data/weights_matrix_eng.pkl', 'wb'))\n",
        "\n",
        "# weights_matrix_eng=pkl.load(open(folder_path + 'data/weights_matrix_eng.pkl', 'rb'))\n",
        "# weights_matrix_eng = torch.from_numpy(weights_matrix_eng).to(device)\n",
        "\n",
        "# #weights_matrix_zh = generate_weights_matrix(idx2words_zh,loaded_embeddings_zh)\n",
        "# #pkl.dump(weights_matrix_zh, open(folder_path + 'data/weights_matrix_zh.pkl', 'wb'))\n",
        "\n",
        "# weights_matrix_zh=pkl.load(open(folder_path + 'data/weights_matrix_zh.pkl', 'rb'))\n",
        "# weights_matrix_zh = torch.from_numpy(weights_matrix_zh).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yt7SPyNP-afV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# #define a class of language\n",
        "# class Language:\n",
        "#     def __init__(self, name,word2index,index2word):\n",
        "#         self.name = name\n",
        "#         self.word2index = word2index\n",
        "#         #self.word2count = {}\n",
        "#         self.index2word = index2word\n",
        "#         self.n_words = len(word2index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1jRnrrZg-d1B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Turn a Unicode string to plain ASCII, thanks to\n",
        "# # http://stackoverflow.com/a/518232/2809427\n",
        "# def unicodeToAscii(s):\n",
        "#     return ''.join(\n",
        "#         c for c in unicodedata.normalize('NFD', s)\n",
        "#         if unicodedata.category(c) != 'Mn'\n",
        "#     )\n",
        "\n",
        "# # Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "# def normalizeString(s):\n",
        "#     s = s.replace(r\"&quot;\",\"\")\n",
        "#     s = s.replace(r\"&apos;\",\"'\")\n",
        "#     s = unicodeToAscii(s.strip())\n",
        "#     s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "#     return s\n",
        "  \n",
        "  \n",
        "# def filterPair(p):\n",
        "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "#         len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "\n",
        "# def filterPairs(pairs):\n",
        "#     return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzerrpTv-zkX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #To read the data file we will split the file into lines, and then split lines into pairs. \n",
        "\n",
        "# def readLanguages_sample(input_lang,target_lang):\n",
        "#     print(\"\\nReading lines...\")\n",
        "\n",
        "#     # Read the file and split into lines\n",
        "#     input_lines = open(folder_path + input_lang, encoding='utf-8').\\\n",
        "#         read().strip().split('\\n')\n",
        "#     target_lines = open(folder_path + target_lang, encoding='utf-8').\\\n",
        "#         read().strip().split('\\n')\n",
        "\n",
        "#     # Split every line and normalize\n",
        "#     #for chinese input, strip the space at the begining and end of the sentence\n",
        "#     #for english output, use normalizeString function\n",
        "#     sample_input = input_lines[:10000]\n",
        "#     sample_target = target_lines[:10000]\n",
        "    \n",
        "#     input_lines_norm = [l.strip() for l in sample_input]\n",
        "#     target_lines_norm = [normalizeString(l) for l in sample_target]\n",
        "    \n",
        "#     #build pairs\n",
        "#     #drop pair if both zh and en are empty strings\n",
        "#     pairs = [[item[0],item[1]] for item in zip(input_lines_norm,target_lines_norm) if len(item[0])+len(item[1]) != 0]\n",
        "    \n",
        "#     input_lines = Language(\"zh\")\n",
        "#     target_lines = Language(\"en\")\n",
        "\n",
        "#     return input_lines, target_lines, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRwKm-ji-fQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #To read the data file we will split the file into lines, and then split lines into pairs. \n",
        "\n",
        "# def readLanguages(input_lang,target_lang):\n",
        "#     print(\"\\nReading lines...\")\n",
        "\n",
        "#     # Read the file and split into lines\n",
        "#     input_lines = open(folder_path + input_lang, encoding='utf-8').\\\n",
        "#         read().strip().split('\\n')\n",
        "#     target_lines = open(folder_path + target_lang, encoding='utf-8').\\\n",
        "#         read().strip().split('\\n')\n",
        "\n",
        "#     # Split every line and normalize\n",
        "#     #for chinese input, strip the space at the begining and end of the sentence\n",
        "#     #for english output, use normalizeString function\n",
        "#     input_lines_norm = [l.strip() for l in input_lines]\n",
        "#     target_lines_norm = [normalizeString(l) for l in target_lines]\n",
        "    \n",
        "#     #build pairs\n",
        "#     #drop pair if both zh and en are empty strings\n",
        "#     pairs = [[item[0],item[1]] for item in zip(input_lines_norm,target_lines_norm) if len(item[0])+len(item[1]) != 0]\n",
        "    \n",
        "#     input_lines = Language(\"zh\",words2id_zh,idx2words_zh)\n",
        "#     target_lines = Language(\"en\",words2id_eng,idx2words_eng)\n",
        "\n",
        "#     return input_lines, target_lines, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FX6hvr77-pUq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def prepareData(input_lang, target_lang):\n",
        "#     input_lang, output_lang, pairs = readLanguages(input_lang, target_lang)\n",
        "#     print(\"Read %s sentence pairs\" % len(pairs))\n",
        "#     pairs = filterPairs(pairs)\n",
        "#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "#     print(\"Counting words...\")\n",
        "# #     for pair in pairs:\n",
        "# #         input_lang.addSentence(pair[0])\n",
        "# #         output_lang.addSentence(pair[1])\n",
        "#     print(\"Counted words:\")\n",
        "#     print(input_lang.name, input_lang.n_words)\n",
        "#     print(output_lang.name, output_lang.n_words)\n",
        "    \n",
        "#     return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsOpgjHA-hMn",
        "colab_type": "code",
        "outputId": "05389e93-5a5c-4aff-df18-f2b46c353dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# train_input_lang, train_output_lang, train_pairs = prepareData(train_zh, train_en)\n",
        "# print(\"print a random pair of training pairs:\")\n",
        "# print(random.choice(train_pairs))\n",
        "\n",
        "\n",
        "\n",
        "# # val_input_lang, val_output_lang, val_pairs = prepareData(val_zh, val_en)\n",
        "# # print(\"print a random pair of validation pairs:\")\n",
        "# # print(random.choice(val_pairs))\n",
        "\n",
        "\n",
        "# # pkl.dump(train_input, open(folder_path +'data/train_input.pkl', 'wb'))\n",
        "# # pkl.dump(train_output, open(folder_path +'data/train_output.pkl', 'wb'))\n",
        "# # pkl.dump(train_pairs, open(folder_path +'data/train_pairs.pkl', 'wb'))\n",
        "# # pkl.dump(val_input, open(folder_path +'data/val_input.pkl', 'wb'))\n",
        "# # pkl.dump(val_output, open(folder_path +'data/val_output.pkl', 'wb'))\n",
        "# # pkl.dump(val_pairs, open(folder_path +'data/val_pairs.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Reading lines...\n",
            "Read 213237 sentence pairs\n",
            "Trimmed to 195215 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "zh 100004\n",
            "en 100004\n",
            "print a random pair of training pairs:\n",
            "['科技 让 巨大 的 创造 创造力 释放 释放出 释放出来 放出 出来', 'And this has unleashed tremendous energy .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ozVXC-QyNPR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "O_batbZJ-jUl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence.split(' ')] + [EOS_token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLz7Ne86_Op7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "class VocabDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Note that this class inherits torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pairs,input_language, output_language):\n",
        "        \"\"\"\n",
        "        @param pairs: pairs of input and target sentences(raw text sentences)\n",
        "        @param input_language: Class Lang of input languages (zh in this case)\n",
        "        @param output_language: Class Lang of output languages (en in this case)\n",
        "\n",
        "        \"\"\"\n",
        "        self.pairs = pairs\n",
        "        self.inputs = [pair[0] for pair in pairs]\n",
        "        self.input_lang = input_language\n",
        "        self.output_lang = output_language\n",
        "        self.outputs = [pair[1] for pair in pairs]\n",
        "        \n",
        "        \n",
        "        #assert self.input_lang == self.target_lang\n",
        "       \n",
        "    def __len__(self):\n",
        "         return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"\n",
        "        Triggered when you call dataset[i]\n",
        "        \"\"\"\n",
        "        \n",
        "        #turn raw text sentecens into indices\n",
        "        input_ = indexesFromSentence(self.input_lang, self.inputs[key])\n",
        "        output = indexesFromSentence(self.output_lang, self.outputs[key])\n",
        "        #print (output)\n",
        "        #print both the length of the source sequence and the target sequence\n",
        "        return [input_,len(input_),output,len(output)]\n",
        "    \n",
        "    \n",
        "    def __gettext__(self,key):\n",
        "      return [self.inputs[key],self.outputs[key]]\n",
        "\n",
        "def vocab_collate_func(batch):\n",
        "    \"\"\"\n",
        "    Customized function for DataLoader that dynamically pads the batch so that all\n",
        "    data have the same length\n",
        "    \"\"\"\n",
        "    input_data_list = []\n",
        "    output_data_list = []\n",
        "   \n",
        "    \n",
        "    for datum in batch:\n",
        "      input_data_list.append(datum[0])\n",
        "      output_data_list.append(datum[2])\n",
        "      \n",
        "      \n",
        "    # Zip into pairs, sort by length (descending), unzip\n",
        "    seq_pairs = sorted(zip(input_data_list, output_data_list), key=lambda p: len(p[0]), reverse=True)\n",
        "    input_seqs, output_seqs = zip(*seq_pairs)\n",
        "    \n",
        "    #store the length of the sequences \n",
        "    input_data_len = [len(p) for p in input_seqs]\n",
        "    output_data_len = [len(p) for p in output_seqs]\n",
        "    \n",
        "    #padding\n",
        "    padded_vec_input = [np.pad(np.array(p),\n",
        "                                 pad_width=((0,MAX_LENGTH-len(p))),\n",
        "                                 mode=\"constant\", constant_values=PAD_IDX) for p in input_seqs]\n",
        "        \n",
        "    padded_vec_output = [np.pad(np.array(p),\n",
        "                                 pad_width=((0,MAX_LENGTH-len(p))),\n",
        "                                 mode=\"constant\", constant_values=PAD_IDX) for p in output_seqs]      \n",
        "    \n",
        "    \n",
        "    input_var = Variable(torch.LongTensor(padded_vec_input))\n",
        "    output_var = Variable(torch.LongTensor(padded_vec_output))\n",
        "    input_data_len = Variable(torch.LongTensor(input_data_len))\n",
        "    output_data_len = Variable(torch.LongTensor(output_data_len))\n",
        "    \n",
        "    \n",
        "    return [input_var,input_data_len,output_var,output_data_len]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRbCrU0z_v2o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build train and valid dataloaders\n",
        "\n",
        "train_dataset = VocabDataset(train_pairs,train_input_lang, train_output_lang)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           collate_fn=vocab_collate_func,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last = True)\n",
        "\n",
        "\n",
        "# val_dataset = VocabDataset(val_pairs,val_input_lang,val_output_lang)\n",
        "# val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "#                                            batch_size=BATCH_SIZE,\n",
        "#                                            collate_fn=vocab_collate_func,\n",
        "#                                            shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NFX3YvX-yz2B",
        "colab_type": "code",
        "outputId": "28e614d0-3775-4cbf-cddd-6111b5df0344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "EOS_token"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "KjCdG1QI_xNu",
        "colab_type": "code",
        "outputId": "7cf77a33-97f6-4f5c-e70f-0aa238df2e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 5, 6, 7, 8, 8, 9, 8, 8, 10, 8, 1], 12, [4, 5, 6, 7, 8, 1], 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "aM4ltrQY3Trg",
        "colab_type": "code",
        "outputId": "94b6f542-a737-4f78-91e7-a61c20b46521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_pairs[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['深海 海中 的 生命   大卫   盖罗 ', 'life in the deep oceans']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "kCANjXu91Nyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in train_loader:\n",
        "  [input_var,input_data_len,output_var,output_data_len]=i\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGNnOUkZ1uWk",
        "colab_type": "code",
        "outputId": "dcea07dd-fc70-4ed1-fd9b-10a8805aa1c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "input_var[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1300,     6,    12,     8,     8, 17908,    58,  1228,   251,  1252,\n",
              "          351,    15,   241,     6,  1104,    74,  1927,   344,  4744,     8,\n",
              "            8,   117,     8,     8,    15,    85,   828, 36616,   946, 23088,\n",
              "        16654,     8,     8,  3180, 10683,    15,   355,   773,   659,   260,\n",
              "          326,     8,     1,     2,     2,     2,     2,     2,     2,     2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "XpDtRegB11cL",
        "colab_type": "code",
        "outputId": "5b74d996-4220-402c-8f48-c6eb5a60b68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_input_lang.index2word[960]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'玩耍'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "-8dk3XNi6ycF",
        "colab_type": "code",
        "outputId": "01a63bbd-45fa-400f-c059-9951c46da146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "for x in input_var[0]:\n",
        "  print (train_input_lang.index2word[x.data.tolist()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "但是\n",
            "与此\n",
            "与此同时\n",
            "同时\n",
            "可能\n",
            "有\n",
            "\n",
            "\n",
            "你\n",
            "不能\n",
            "预测\n",
            "的\n",
            "变化\n",
            "\n",
            "\n",
            "比如\n",
            "\n",
            "\n",
            "\n",
            "飞机\n",
            "需要\n",
            "更多\n",
            "的\n",
            "跑道\n",
            "去\n",
            "起飞\n",
            "\n",
            "\n",
            "\n",
            "因为\n",
            "高温\n",
            "\n",
            "\n",
            "不\n",
            "稠密\n",
            "的\n",
            "空气\n",
            "\n",
            "\n",
            "不能\n",
            "提供\n",
            "足够\n",
            "的\n",
            "升力\n",
            "\n",
            "\n",
            "<EOS>\n",
            "<PAD>\n",
            "<PAD>\n",
            "<PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GbqLi-5P5Ek6",
        "colab_type": "code",
        "outputId": "d13920c4-c3a9-454a-e4e4-2662a961e5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "output_var[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18940,   959,   148,   388,   108, 17072,   959,   220,    15,   221,\n",
              "          166,    19,   148,    14,    60,    96, 18930,  1139,    38,    52,\n",
              "            6,   111,   388,   108,  3753,   133,  8401,  1854, 18959,  9982,\n",
              "          121,    46,  2396,    96,    75,    15,    39,   231, 15262,     5,\n",
              "            6,   347,    13,     1,     2,     2,     2,     2,     2,     2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "RHKS4rPD5IhB",
        "colab_type": "code",
        "outputId": "7670da80-cd92-47a7-893f-89e74a166ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "for x in output_var[0]:\n",
        "  print (train_output_lang.index2word[x.data.tolist()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ao\n",
            "who\n",
            "also\n",
            "was\n",
            "a\n",
            "pianist\n",
            "who\n",
            "couldn\n",
            "apos\n",
            "t\n",
            "see\n",
            "and\n",
            "also\n",
            "i\n",
            "think\n",
            "like\n",
            "derek\n",
            "thought\n",
            "that\n",
            "all\n",
            "the\n",
            "world\n",
            "was\n",
            "a\n",
            "piano\n",
            "so\n",
            "whenever\n",
            "art\n",
            "tatum\n",
            "plays\n",
            "something\n",
            "it\n",
            "sounds\n",
            "like\n",
            "there\n",
            "apos\n",
            "s\n",
            "three\n",
            "pianos\n",
            "in\n",
            "the\n",
            "room\n",
            ".\n",
            "<EOS>\n",
            "<PAD>\n",
            "<PAD>\n",
            "<PAD>\n",
            "<PAD>\n",
            "<PAD>\n",
            "<PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jDJsqrFayR4m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ]
    },
    {
      "metadata": {
        "id": "Ac8yy73v_QiC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, weights_matrix, input_size, hidden_size,n_layers=1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "     \n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.n_layers = n_layers\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
        "        self.embedding.from_pretrained(weights_matrix, freeze=False, sparse=False)\n",
        "        #self.embedding.weight.requires_grad = True\n",
        "\n",
        "        \n",
        "        self.gru = nn.GRU(self.embedding_dim, hidden_size, n_layers, bidirectional=True)\n",
        "        \n",
        "\n",
        "    def forward(self, input_seqs, input_len, hidden=None):\n",
        "\n",
        "       \n",
        "        embedded = self.embedding(input_seqs)\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_len)\n",
        "        output, hidden = self.gru(packed, hidden)\n",
        "\n",
        "        output, output_len = torch.nn.utils.rnn.pad_packed_sequence(output)\n",
        "        output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:]\n",
        "        \n",
        "        return output,hidden\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JXSMSJUHyVMm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ]
    },
    {
      "metadata": {
        "id": "NN6-E9GQ_SYx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, weights_matrix, hidden_size, output_size,n_layers=1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n",
        "        \n",
        "        #self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
        "#         self.embedding.weight.data.copy_(weights_matrix)\n",
        "#         self.embedding.weight.requires_grad = True\n",
        "        #self.embedding.from_pretrained(weights_matrix, freeze=True, sparse=False)\n",
        "        \n",
        "        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        \n",
        "        embedded = self.embedding(input_seq) # dim = Batch_Size x embedding_dim\n",
        "        embedded = embedded.view(1, self.batch_size, self.embedding_dim) # S=1 x Batch_Size x embedding_dim\n",
        "        \n",
        "        rnn_output, hidden = self.gru1(embedded, hidden)\n",
        "        output = F.relu(rnn_output)\n",
        "        \n",
        "        output, hidden = self.gru2(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        \n",
        "        return output,hidden\n",
        "\n",
        "\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "veJMFCR__UzN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, weights_matrix, hidden_size, output_size, n_layers=1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n",
        "\n",
        "        #self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
        "#         self.embedding.weight.data.copy_(weights_matrix)\n",
        "#         self.embedding.weight.requires_grad = True\n",
        "        #self.embedding.from_pretrained(weights_matrix, freeze=True, sparse=False)\n",
        "  \n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "       \n",
        "        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n",
        "        \n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input_seq).view(1, 1, -1)\n",
        " \n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxYk3UJQ_W8z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        \n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
        "     \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        max_len = encoder_outputs.size(0)\n",
        "        this_batch_size = encoder_outputs.size(1)\n",
        "\n",
        "        # Create variable to store attention energies\n",
        "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)).to(device) # Batch_Size x Seq_Length\n",
        "\n",
        "        \n",
        "#         # For each batch of encoder outputs\n",
        "        for b in range(this_batch_size):\n",
        "            # Calculate energy for each encoder output\n",
        "            for i in range(max_len):\n",
        "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
        "\n",
        "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
        "        return F.softmax(attn_energies,dim=1).unsqueeze(1)\n",
        "      \n",
        "    def score(self, hidden, encoder_output):\n",
        "        \n",
        "        if self.method == 'dot':\n",
        "#             print (hidden.shape)\n",
        "#             print (encoder_output.shape)\n",
        "            energy = hidden[0].dot(encoder_output[0])\n",
        "            return energy\n",
        "        \n",
        "        elif self.method == 'general':\n",
        "            energy = self.attn(encoder_output)\n",
        "            energy = torch.mm(hidden[0], energy.transpose(0,1))\n",
        "            return energy\n",
        "        \n",
        "        elif self.method == 'concat':\n",
        "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
        "            energy = self.v.dot(energy)\n",
        "            return energy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nik892T7_YoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, weights_matrix, hidden_size, output_size, n_layers=1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n",
        "\n",
        "\n",
        "        # Define layers\n",
        "        #self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
        "#         self.embedding.weight.data.copy_(weights_matrix)\n",
        "#         self.embedding.weight.requires_grad = True\n",
        "        self.embedding.from_pretrained(weights_matrix, freeze=False, sparse=False)\n",
        "        \n",
        "        \n",
        "        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n",
        "        \n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "        # Choose attention model\n",
        "        if attn_model != 'none':\n",
        "            self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step at a time\n",
        "\n",
        "        # Get the embedding of the current input word (last output word)\n",
        "\n",
        "        embedded = self.embedding(input_seq) # dim = Batch_Size x embedding_dim\n",
        "        embedded = embedded.view(1, self.batch_size, self.embedding_dim) # S=1 x Batch_Size x embedding_dim\n",
        "\n",
        "        # Get current hidden state from input word and last hidden state\n",
        "        # rnn_output : [1 x batch_size x hidden_size]\n",
        "        # hidden: [layer x batch_size x hidden_size]\n",
        "        rnn_output, hidden = self.gru1(embedded, last_hidden)\n",
        "        \n",
        "        # Calculate attention from current RNN state and all encoder outputs;\n",
        "        # apply to encoder outputs to get weighted average\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
        "\n",
        "        # Attentional vector using the RNN hidden state and context vector\n",
        "        # concatenated together (Luong eq. 5)\n",
        "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
        "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "\n",
        "        # Finally predict next token (Luong eq. 6, without softmax)\n",
        "        output = self.out(concat_output)\n",
        "\n",
        "        #Return final output, hidden state, and attention weights (for visualization)\n",
        "        return output, hidden, attn_weights\n",
        "        #return attn_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8N3Gbi_t_aJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BahdanauAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, weights_matrix, hidden_size, output_size, n_layers=1):\n",
        "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
        "        \n",
        "        # Define parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n",
        "        \n",
        "        \n",
        "        # Define layers\n",
        "        #self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
        "#         self.embedding.weight.data.copy_(weights_matrix)\n",
        "#         self.embedding.weight.requires_grad = True\n",
        "        \n",
        "        self.attn = Attn('concat', hidden_size)\n",
        "        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n",
        "        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step at a time\n",
        "        # TODO: FIX BATCHING\n",
        "        \n",
        "        # Get the embedding of the current input word (last output word)\n",
        "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
        "        \n",
        "        # Calculate attention weights and apply to encoder outputs\n",
        "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
        "        context = context.transpose(0, 1) # 1 x B x N\n",
        "        \n",
        "        # Combine embedded input word and attended context, run through RNN\n",
        "        rnn_input = torch.cat((word_embedded, context), 2)\n",
        "        output, hidden = self.gru(rnn_input, last_hidden)\n",
        "        \n",
        "        # Final output layer\n",
        "        output = output.squeeze(0) # B x N\n",
        "        output = F.log_softmax(self.out(torch.cat((output, context), 1)),dim=1)\n",
        "        \n",
        "        # Return final output, hidden state, and attention weights (for visualization)\n",
        "        return output, hidden, attn_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bct0uwzoybjL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Function"
      ]
    },
    {
      "metadata": {
        "id": "fR4JgAnI_by8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#record the run time\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wkWNQq3E_dGY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82n4HDUwygzV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss function"
      ]
    },
    {
      "metadata": {
        "id": "Atk9GiIo_hkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sequence_mask(sequence_length, max_len=None):\n",
        "    if max_len is None:\n",
        "        max_len = sequence_length.data.max()\n",
        "    batch_size = BATCH_SIZE\n",
        "    seq_range = torch.arange(0, max_len).long()\n",
        "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
        "    seq_range_expand = Variable(seq_range_expand)\n",
        "    \n",
        "    seq_range_expand = seq_range_expand.to(device)\n",
        "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
        "                         .expand_as(seq_range_expand))\n",
        "    return seq_range_expand < seq_length_expand\n",
        "\n",
        "\n",
        "def masked_cross_entropy(logits, target, length):\n",
        "    length = Variable(torch.LongTensor(length)).to(device)\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        logits: A Variable containing a FloatTensor of size\n",
        "            (batch, max_len, num_classes) which contains the\n",
        "            unnormalized probability for each class.\n",
        "        target: A Variable containing a LongTensor of size\n",
        "            (batch, max_len) which contains the index of the true\n",
        "            class for each corresponding step.\n",
        "        length: A Variable containing a LongTensor of size (batch,)\n",
        "            which contains the length of each data in a batch.\n",
        "    Returns:\n",
        "        loss: An average loss value masked by the length.\n",
        "    \"\"\"\n",
        "    \n",
        "    # logits_flat: (batch * max_len, num_classes)\n",
        "    logits_flat = logits.view(-1, logits.size(-1))\n",
        "    # log_probs_flat: (batch * max_len, num_classes)\n",
        "    log_probs_flat = F.log_softmax(logits_flat,dim=1)\n",
        "    \n",
        "    # target_flat: (batch * max_len, 1)\n",
        "    target_flat = target.view(-1, 1)\n",
        "    \n",
        "    # losses_flat: (batch * max_len, 1)\n",
        "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
        "    # losses: (batch, max_len)\n",
        "    losses = losses_flat.view(*target.size())\n",
        "    # mask: (batch, max_len)\n",
        "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
        "    losses = losses * mask.float()\n",
        "    loss = losses.sum() / length.float().sum()\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzgAAl74_ko5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#the train function is now taking a batch at a time\n",
        "def train(input_batch, input_lengths, output_batch, output_lengths, encoder, decoder, encoder_optimizer, \n",
        "          decoder_optimizer, criterion, max_length=MAX_LENGTH, if_attention = True):\n",
        "    \n",
        "    encoder_outputs, encoder_hidden = encoder(input_batch, input_lengths, None)\n",
        "  \n",
        "\n",
        "    # Prepare decoder input and outputs\n",
        "    decoder_input = Variable(torch.LongTensor([SOS_token] * BATCH_SIZE)).to(device)\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
        "    all_decoder_outputs = Variable(torch.zeros(max_length, BATCH_SIZE, decoder.output_size)).to(device)\n",
        "    \n",
        "    # Run through decoder one time step at a time\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    \n",
        "    # Teacher forcing: Feed the target as the next input\n",
        "    if use_teacher_forcing:\n",
        "        # Run through decoder one time step at a time\n",
        "        for di in range(max_length):\n",
        "            if if_attention == True:\n",
        "                decoder_output, decoder_hidden, decoder_attn = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "            else:\n",
        "\n",
        "                decoder_output, decoder_hidden = decoder(\n",
        "                    decoder_input, decoder_hidden)\n",
        "                \n",
        "            all_decoder_outputs[di] = decoder_output # Store this step's outputs\n",
        "            decoder_input = output_batch[di] # Next input is current target\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(max_length):\n",
        "            if if_attention == True:\n",
        "                decoder_output, decoder_hidden, decoder_attn = decoder(\n",
        "                  decoder_input, decoder_hidden, encoder_outputs)\n",
        "            else:\n",
        "\n",
        "                decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "                \n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "            all_decoder_outputs[di] = decoder_output\n",
        "\n",
        "    \n",
        "    # Loss calculation and backpropagation\n",
        "    loss = masked_cross_entropy(\n",
        "            all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
        "            output_batch.transpose(0, 1).contiguous(), # -> batch x seq\n",
        "            output_lengths)    \n",
        "\n",
        "    loss.backward()\n",
        "    ec = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    dc = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "    \n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "#     ec=0\n",
        "#     dc=0\n",
        "\n",
        "\n",
        "    return loss.item(), ec, dc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ViJaygPT_mY6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainIters(iters, criterion,  encoder, decoder, encoder_optimizer, decoder_optimizer, n_iters, loss_list, print_every=1000, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "    loss_list=[]\n",
        "    loss_avg=[]\n",
        "#     encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "#     decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "    #iters = 0\n",
        "  \n",
        "    while iters <= n_iters:\n",
        "      \n",
        "      \n",
        "      \n",
        "      for i, (input_var,input_data_len,output_var,output_data_len) in enumerate(train_loader):\n",
        "        print(\"Iteration:\", iters)\n",
        "        iters += 1\n",
        "        input_batch = input_var.transpose(0,1).to(device)\n",
        "        output_batch = output_var.transpose(0,1).to(device)\n",
        "        \n",
        "        loss, _, _ = train(input_batch,input_data_len,output_batch,output_data_len, encoder,\n",
        "                       decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        \n",
        "        \n",
        "        # Keep track of loss\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "        \n",
        "          \n",
        "        print('Loss: %s (%d %d%%) %.4f' % (timeSince(start, iters / n_iters),\n",
        "                                           iters, iters / n_iters * 100, loss))\n",
        "        loss_list.append(loss)\n",
        "        \n",
        "        if iters % print_every == 0:\n",
        "          \n",
        "          \n",
        "          \n",
        "          print_loss_avg = print_loss_total/print_every\n",
        "          print_loss_total = 0\n",
        "          loss_avg.append(print_loss_avg)\n",
        "          ##Learning Rate Decay\n",
        "          if (len(loss_avg)!=1):\n",
        "            loss_change  = loss_avg[-2]-loss_avg[-1]\n",
        "            print (\"loss_change: \", loss_change)\n",
        "            if (loss_change < 0.05):\n",
        "              \n",
        "              print(\"Learning Rate Decays:\")\n",
        "              for param_group in encoder_optimizer.param_groups:\n",
        "                \n",
        "                param_group['lr'] = param_group['lr']*0.5\n",
        "                print (\"Current Encoder Learning Rate: {}\". format (param_group['lr']))\n",
        "              for param_group in decoder_optimizer.param_groups:\n",
        "                \n",
        "                param_group['lr'] = param_group['lr']*0.5\n",
        "                print (\"Current Decoder Learning Rate: {}\". format (param_group['lr']))\n",
        "                \n",
        "              \n",
        "          print('Average Loss: %s (%d %d%%) %.4f' % (timeSince(start, iters / n_iters),\n",
        "                                           iters, iters / n_iters * 100, print_loss_avg))\n",
        "        \n",
        "          state = {'epoch': iters + 1, 'encoder_state_dict': encoder.state_dict(), 'decoder_state_dict': decoder.state_dict(),\n",
        "             'encoder_optimizer': encoder_optimizer.state_dict(), 'decoder_optimizer': decoder_optimizer.state_dict(), \"loss_list\": loss_list, \"loss_avg\": loss_avg}\n",
        "          \n",
        "          torch.save(state, folder_path+\"model_saved/Dec_3_state_{}.pt\".format(iters))\n",
        "        if iters % plot_every == 0:\n",
        "         \n",
        "          plot_loss_avg = plot_loss_total / plot_every\n",
        "          plot_losses.append(plot_loss_avg)\n",
        "          plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_TjxDZP6ASEH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Configure models\n",
        "attn_model = 'dot'\n",
        "hidden_size = 300\n",
        "layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "start_epoch=0\n",
        "teacher_forcing_ratio = 0.8\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iters = 100000\n",
        "#def __init__(self, attn_model, weights_matrix, hidden_size, output_size, n_layers=1):\n",
        "# def __init__(self, weights_matrix, input_size, hidden_size,n_layers=1):\n",
        "# Initialize models\n",
        "encoder = EncoderRNN(weights_matrix_zh, train_input_lang.n_words, hidden_size, n_layers = layers).to(device)\n",
        "#decoder = DecoderRNN(weights_matrix_eng, hidden_size, train_output_lang.n_words, n_layers = layers).to(device)\n",
        "decoder= LuongAttnDecoderRNN(attn_model, weights_matrix_eng, hidden_size, train_output_lang.n_words,n_layers = layers).to(device)\n",
        "# Initialize optimizers and criterion\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cK0Z6BEm4Ygp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load pretrained model"
      ]
    },
    {
      "metadata": {
        "id": "GYjTFdB8ui9i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_checkpoint(encoder, decoder, encoder_optimizer, decoder_optimizer, iteration_num):\n",
        "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
        "    folder_path = os.getcwd() + '/gdrive/My Drive/NLP_Project/'\n",
        "    start_epoch = 0\n",
        "    filename=folder_path+\"model_saved/Dec_3_state_{}.pt\".format(iteration_num)\n",
        "    loss_list=[]\n",
        "    if os.path.isfile(filename):\n",
        "        print(\"=> loading checkpoint '{}'\".format(iteration_num))\n",
        "        checkpoint = torch.load(filename, map_location=device)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        #model.load_state_dict(checkpoint['state_dict'])\n",
        "        encoder.load_state_dict(checkpoint[\"encoder_state_dict\"])\n",
        "        decoder.load_state_dict(checkpoint[\"decoder_state_dict\"])\n",
        "        encoder_optimizer.load_state_dict(checkpoint[\"encoder_optimizer\"])\n",
        "        decoder_optimizer.load_state_dict(checkpoint[\"decoder_optimizer\"])\n",
        "        loss_list=checkpoint[\"loss_list\"]\n",
        "        #optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        #losslogger = checkpoint['losslogger']\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(filename, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
        "\n",
        "    return start_epoch, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-bf8HU0ukUr",
        "colab_type": "code",
        "outputId": "2dec1463-94df-45ef-fa4f-ecf777d9d43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "start_epoch, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_list=\\\n",
        "load_checkpoint(encoder, decoder, encoder_optimizer, decoder_optimizer, 30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint '30'\n",
            "=> loaded checkpoint '/content/gdrive/My Drive/NLP_Project/model_saved/Dec_3_state_30.pt' (epoch 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rdjz6yeSh0vH",
        "colab_type": "code",
        "outputId": "03447177-8dae-437d-a025-7f7870e76ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "loss_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10.577936172485352,\n",
              " 10.52320671081543,\n",
              " 10.361044883728027,\n",
              " 10.199304580688477,\n",
              " 10.046380996704102,\n",
              " 9.688304901123047,\n",
              " 9.563981056213379,\n",
              " 9.311548233032227,\n",
              " 8.995036125183105,\n",
              " 8.709113121032715,\n",
              " 8.350419998168945,\n",
              " 8.1212158203125,\n",
              " 7.880978584289551,\n",
              " 7.6278791427612305,\n",
              " 7.702040195465088,\n",
              " 7.477540969848633,\n",
              " 7.219671726226807,\n",
              " 7.276883602142334,\n",
              " 7.116346836090088,\n",
              " 6.888298034667969,\n",
              " 6.862778663635254,\n",
              " 6.7902445793151855,\n",
              " 6.750735282897949,\n",
              " 6.8259453773498535,\n",
              " 6.785239219665527,\n",
              " 6.698254585266113,\n",
              " 6.700711727142334,\n",
              " 6.77982759475708,\n",
              " 6.759353160858154,\n",
              " 6.729983329772949]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "YlGoYaEv4d4d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Start Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d593f83f-ac1e-4ad5-83ff-64e92409c7a9",
        "id": "_mYK7qLG0C8q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "loss_list=[]\n",
        "#learning_rate=learning_rate*0.5\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "trainIters(start_epoch, criterion, encoder, decoder, encoder_optimizer, decoder_optimizer, n_iters, loss_list, print_every=5, plot_every=1000000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Loss: 3m 59s (- 399765m 12s) (1 0%) 10.6917\n",
            "Iteration: 1\n",
            "Loss: 7m 49s (- 391577m 57s) (2 0%) 10.6401\n",
            "Iteration: 2\n",
            "Loss: 11m 29s (- 382973m 1s) (3 0%) 10.5777\n",
            "Iteration: 3\n",
            "Loss: 15m 22s (- 384411m 42s) (4 0%) 10.5019\n",
            "Iteration: 4\n",
            "Loss: 19m 15s (- 384985m 50s) (5 0%) 10.4159\n",
            "Average Loss: 19m 15s (- 384985m 56s) (5 0%) 10.5655\n",
            "Iteration: 5\n",
            "Loss: 22m 59s (- 383071m 22s) (6 0%) 10.2324\n",
            "Iteration: 6\n",
            "Loss: 26m 45s (- 382258m 24s) (7 0%) 10.0173\n",
            "Iteration: 7\n",
            "Loss: 30m 43s (- 384013m 38s) (8 0%) 9.8241\n",
            "Iteration: 8\n",
            "Loss: 34m 31s (- 383526m 0s) (9 0%) 9.4007\n",
            "Iteration: 9\n",
            "Loss: 38m 23s (- 383915m 39s) (10 0%) 9.2575\n",
            "loss_change:  0.8191112518310533\n",
            "Average Loss: 38m 23s (- 383915m 52s) (10 0%) 9.7464\n",
            "Iteration: 10\n",
            "Loss: 42m 16s (- 384347m 18s) (11 0%) 9.0042\n",
            "Iteration: 11\n",
            "Loss: 46m 9s (- 384661m 20s) (12 0%) 8.7215\n",
            "Iteration: 12\n",
            "Loss: 49m 59s (- 384550m 20s) (13 0%) 8.3480\n",
            "Iteration: 13\n",
            "Loss: 53m 28s (- 381894m 35s) (14 0%) 8.1373\n",
            "Iteration: 14\n",
            "Loss: 57m 25s (- 382751m 38s) (15 0%) 7.9314\n",
            "loss_change:  1.3179030418395996\n",
            "Average Loss: 57m 25s (- 382751m 47s) (15 0%) 8.4285\n",
            "Iteration: 15\n",
            "Loss: 61m 24s (- 383778m 23s) (16 0%) 7.6937\n",
            "Iteration: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HqETPpIHny8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evalutation"
      ]
    },
    {
      "metadata": {
        "id": "0kMYuG5dAVd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_checkpoint(encoder, decoder, encoder_optimizer, decoder_optimizer, iteration_num):\n",
        "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
        "    folder_path = os.getcwd() + '/gdrive/My Drive/NLP_Project/'\n",
        "    start_epoch = 0\n",
        "    filename=folder_path+\"model_saved/state_{}.pt\".format(iteration_num)\n",
        "    if os.path.isfile(filename):\n",
        "        print(\"=> loading checkpoint '{}'\".format(iteration_num))\n",
        "        checkpoint = torch.load(filename, map_location=device)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        #model.load_state_dict(checkpoint['state_dict'])\n",
        "        encoder.load_state_dict(checkpoint[\"encoder_state_dict\"])\n",
        "        decoder.load_state_dict(checkpoint[\"decoder_state_dict\"])\n",
        "        encoder_optimizer.load_state_dict(checkpoint[\"encoder_optimizer\"])\n",
        "        decoder_optimizer.load_state_dict(checkpoint[\"decoder_optimizer\"])\n",
        "        #optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        #losslogger = checkpoint['losslogger']\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(filename, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
        "\n",
        "    return start_epoch, encoder, decoder, encoder_optimizer, decoder_optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgEZtBTossgP",
        "colab_type": "code",
        "outputId": "3e187043-3f92-4712-de6e-9c159ae00ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "start_epoch, encoder, decoder, encoder_optimizer, decoder_optimizer=\\\n",
        "load_checkpoint(encoder, decoder, encoder_optimizer, decoder_optimizer, 190)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-da717e0fc166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m190\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uy1diI64ASWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_randomly(pairs, input_lang, output_lang):\n",
        "    [input_sentence, target_sentence] = random.choice(pairs)\n",
        "    evaluate_and_show_attention(input_sentence, input_lang, output_lang, target_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pRqWnSsHATib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_attention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    show_plot_visdom()\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oANXKAONAVoo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_and_show_attention(input_sentence, input_lang, output_lang, target_sentence=None):\n",
        "    output_words, attentions = evaluate(input_sentence, input_lang, output_lang)\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    print('>', input_sentence)\n",
        "    if target_sentence is not None:\n",
        "        print('=', target_sentence)\n",
        "    print('<', output_sentence)\n",
        "    \n",
        "#     show_attention(input_sentence, output_words, attentions)\n",
        "    \n",
        "#     # Show input, target, output text in visdom\n",
        "#     win = 'evaluted (%s)' % hostname\n",
        "#     text = '<p>&gt; %s</p><p>= %s</p><p>&lt; %s</p>' % (input_sentence, target_sentence, output_sentence)\n",
        "#     vis.text(text, win=win, opts={'title': win})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4UW222G7AnCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def indexes_from_sentence(lang, sentence):\n",
        "    index_list = []\n",
        "    for word in sentence.split(' '):\n",
        "      if (word in lang.word2index.keys()):\n",
        "        index = lang.word2index[word] \n",
        "      else:\n",
        "        index = UNK_IDX\n",
        "      index_list.append(index)\n",
        "    \n",
        "    return index_list + [EOS_token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXexOcvaAWxj",
        "colab_type": "code",
        "outputId": "f202e99b-30cd-4ca8-94da-6a1e9e3e67e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1881
        }
      },
      "cell_type": "code",
      "source": [
        "evaluate_randomly(train_pairs, train_input_lang, train_output_lang)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "那 是 妳 的 一部 一部分 部分\n",
            "tensor([[ 110],\n",
            "        [   9],\n",
            "        [8050],\n",
            "        [   5],\n",
            "        [   3],\n",
            "        [6929],\n",
            "        [ 286],\n",
            "        [   1]])\n",
            "[17]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-6d6c2678e3d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_randomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-124-6e0e502e984b>\u001b[0m in \u001b[0;36mevaluate_randomly\u001b[0;34m(pairs, input_lang, output_lang)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_randomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluate_and_show_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-123-0ec2bb566402>\u001b[0m in \u001b[0;36mevaluate_and_show_attention\u001b[0;34m(input_sentence, input_lang, output_lang, target_sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_and_show_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_sentence\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-122-1f06e8c269c0>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(input_seq, input_lang, output_lang, max_length)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Run through encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Create starting vectors for decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-c256712bdd7e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seqs, input_len, hidden)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mflat_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cannot unsqueeze empty tensor"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xEgPGz6kGbky",
        "colab_type": "code",
        "outputId": "8e06228b-0e2f-4508-a5e0-8f8a3840499d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "AlXBk0f1AZ0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(input_seq, input_lang, output_lang, max_length=MAX_LENGTH):\n",
        "\n",
        "    \n",
        "    \n",
        "    input_seqs = [indexesFromSentence(input_lang, input_seq)]\n",
        "    \n",
        "    input_lengths = [len(input_seq.split())]\n",
        "    input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
        "    \n",
        "    input_batches = input_batches.to(device)\n",
        "\n",
        "    # Set to not-training mode to disable dropout\n",
        "    encoder.train(False)\n",
        "    decoder.train(False)\n",
        "    # Run through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
        "   \n",
        "    \n",
        "\n",
        "    # Create starting vectors for decoder\n",
        "    decoder_input = Variable(torch.LongTensor([SOS_token]), volatile=True) # SOS\n",
        "    print (encoder_hidden.shape)\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
        "    \n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Store output words and attention states\n",
        "    decoded_words = []\n",
        "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
        "    #return decoder_input, decoder_attentions\n",
        "    # Run through decoder\n",
        "#     print(decoder_input)\n",
        "#     print(decoder_hidden.shape)\n",
        "    \n",
        "    for di in range(max_length):\n",
        "      \n",
        "        print(decoder_input)\n",
        "        print(decoder_hidden.shape)\n",
        "        \n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "            decoder_input, decoder_hidden, encoder_outputs\n",
        "        )\n",
        "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
        "\n",
        "        # Choose top word from output\n",
        "        topv, topi = decoder_output.data.topk(1)\n",
        "        ni = topi[0][0]\n",
        "        print(ni.data.tolist())\n",
        "        if ni == EOS_token:\n",
        "            decoded_words.append('<EOS>')\n",
        "            break\n",
        "        else:\n",
        "            decoded_words.append(output_lang.index2word[ni.data.tolist()])\n",
        "            \n",
        "        # Next input is chosen word\n",
        "        decoder_input = Variable(torch.LongTensor([ni]))\n",
        "        decoder_input = decoder_input.to(device)\n",
        "    # Set back to training mode\n",
        "    encoder.train(True)\n",
        "    decoder.train(True)\n",
        "    \n",
        "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdZC3C7SZX85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(64):\n",
        "  [input_sentence, target_sentence] = random.choice(train_pairs)\n",
        "  input_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuvyoZVEGFpD",
        "colab_type": "code",
        "outputId": "4342d657-68cd-451d-9fa3-a09288d1c905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "#[input_sentence, target_sentence] = random.choice(train_pairs)\n",
        "input_sentence=\"我 爱 你\"\n",
        "input_batches, input_lengths=evaluate(input_sentence, train_input_lang, train_output_lang, beam_size=3, max_length=MAX_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-87138c4f88b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"我 爱 你\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: evaluate() got an unexpected keyword argument 'beam_size'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kJfuedE4AFlq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def old_evaluate(input_seq, input_lang, output_lang, max_length=MAX_LENGTH):\n",
        "    print (input_seq)\n",
        "    input_lengths = [len(input_seq)]\n",
        "    input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
        "    input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
        "    \n",
        "    input_batches = input_batches.to(device)\n",
        "        \n",
        "    # Set to not-training mode to disable dropout\n",
        "    encoder.train(False)\n",
        "    decoder.train(False)\n",
        "    print (input_batches)\n",
        "    print (input_lengths)\n",
        "    # Run through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
        "\n",
        "    # Create starting vectors for decoder\n",
        "    decoder_input = Variable(torch.LongTensor([SOS_token]), volatile=True) # SOS\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
        "    \n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Store output words and attention states\n",
        "    decoded_words = []\n",
        "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
        "    \n",
        "    # Run through decoder\n",
        "    for di in range(max_length):\n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "            decoder_input, decoder_hidden, encoder_outputs\n",
        "        )\n",
        "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
        "\n",
        "        # Choose top word from output\n",
        "        topv, topi = decoder_output.data.topk(1)\n",
        "        ni = topi[0][0]\n",
        "        if ni == EOS_token:\n",
        "            decoded_words.append('<EOS>')\n",
        "            break\n",
        "        else:\n",
        "            decoded_words.append(output_lang.index2word[ni])\n",
        "            \n",
        "        # Next input is chosen word\n",
        "        decoder_input = Variable(torch.LongTensor([ni]))\n",
        "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
        "\n",
        "    # Set back to training mode\n",
        "    encoder.train(True)\n",
        "    decoder.train(True)\n",
        "    \n",
        "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkGFBQryG6bJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input_seq = \"你\"\n",
        "# input_lang = train_input_lang \n",
        "# output_lang = train_output_lang \n",
        "# max_length = 1\n",
        "# beam_size = 10\n",
        "\n",
        "def to_output_lang(output_list):\n",
        "  result=[]\n",
        "  for token_index in output_list:\n",
        "    token=output_lang.index2word[token_index]\n",
        "    result.append(token)\n",
        "  return result\n",
        "\n",
        "def evaluate_beam_search(encoder, decoder, input_seq, input_lang, output_lang, max_length=MAX_LENGTH, beam_size = 10):\n",
        "  with torch.no_grad():\n",
        "\n",
        "    input_seqs = [indexesFromSentence(input_lang, input_seq)]\n",
        "    #print (input_seqs)\n",
        "    input_lengths = [len(input_seq.split())]\n",
        "    input_batches = Variable(torch.LongTensor(input_seqs)).transpose(0, 1)\n",
        "\n",
        "    input_batches = input_batches.to(device)\n",
        "\n",
        "    # Set to not-training mode to disable dropout\n",
        "    encoder.train(False)\n",
        "    decoder.train(False)\n",
        "    # Run through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
        "\n",
        "\n",
        "\n",
        "    # Create starting vectors for decoder\n",
        "    #decoder_input = Variable(torch.LongTensor([SOS_token])) # SOS\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
        "\n",
        "    sequences=[[[SOS_token], 1.0]]\n",
        "    decoder_attentions = torch.zeros(max_length, max_length)\n",
        "    for di in range(max_length):\n",
        "\n",
        "      for sequence in sequences:\n",
        "        sequence_list, score = sequence\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        for word in sequence_list:\n",
        "          #print (\"word:\", word)\n",
        "          word = Variable(torch.LongTensor([word])).to(device)\n",
        "          decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "          word, decoder_hidden, encoder_outputs\n",
        "        )\n",
        "        \n",
        "        #decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
        "\n",
        "        #print (\"decoder_output.shape\", decoder_output.shape)\n",
        "        output_prob=F.softmax(decoder_output.data)\n",
        "        topv, topi = output_prob.topk(30000)\n",
        "        candidates=[]\n",
        "        for i in range (30000):\n",
        "          prob = topv[0][i].data.tolist()\n",
        "          toekn = [topi[0][i].data.tolist()]\n",
        "          candidates.append([sequence_list+toekn, prob*score])\n",
        "\n",
        "        sequences=sorted(candidates, key=lambda tup: tup[1], reverse=True)[0:beam_size]\n",
        "        sequences_word=[[to_output_lang(x[0]), x[1]] for x in sequences]\n",
        "  return sequences_word\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1vO6C8Hgwiv0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence.split(' ')] + [EOS_token]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gDWrJ6PsA43",
        "colab_type": "code",
        "outputId": "433f435d-9123-4f22-a2e1-7ae465dce627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "cell_type": "code",
      "source": [
        "input_seq = \"我 讨厌 你\"\n",
        "input_lang = train_input_lang \n",
        "output_lang = train_output_lang \n",
        "max_length = 7\n",
        "beam_size = 3\n",
        "encoder.batch_size=1\n",
        "decoder.batch_size=1\n",
        "evaluate_beam_search(encoder, decoder, input_seq, input_lang, output_lang, max_length=5, beam_size = 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['<EOS>', 'they', 'they', 'they', 'they', 'a'], 1.3731330188136913e-05],\n",
              " [['<EOS>', 'they', 'they', 'they', 'they', '<PAD>'], 4.5850020912157005e-06],\n",
              " [['<EOS>', 'they', 'they', 'they', 'they', 'they'], 4.5684426458255714e-06]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "JXkVZRsd8K07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_and_show_attention(input_sentence, input_lang, output_lang, target_sentence=None):\n",
        "    print('>', input_sentence)\n",
        "    \n",
        "    if target_sentence is not None:\n",
        "        print('=', target_sentence)\n",
        "    \n",
        "    sequences_word = evaluate_beam_search(encoder, decoder, input_sentence, input_lang, output_lang, max_length=10, beam_size = 4)\n",
        "    \n",
        "    output_sentence = ' '.join(sequences_word[0][0])\n",
        "\n",
        "    print('<', output_sentence)\n",
        "    \n",
        "#     show_attention(input_sentence, output_words, attentions)\n",
        "    \n",
        "#     # Show input, target, output text in visdom\n",
        "#     win = 'evaluted (%s)' % hostname\n",
        "#     text = '<p>&gt; %s</p><p>= %s</p><p>&lt; %s</p>' % (input_sentence, target_sentence, output_sentence)\n",
        "#     vis.text(text, win=win, opts={'title': win})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TE8sI5RTKct6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_randomly(pairs, input_lang, output_lang):\n",
        "    [input_sentence, target_sentence] = random.choice(pairs)\n",
        "    evaluate_and_show_attention(input_sentence, input_lang, output_lang, target_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KeAqmvA18mGL",
        "colab_type": "code",
        "outputId": "239a428b-31a5-433a-eccd-95838c7ca5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "cell_type": "code",
      "source": [
        "evaluate_randomly(train_pairs, train_input_lang, train_output_lang)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 他们 会 变成 这样 的 消费 消费者    和 你 我 一样   一无所知 无所 所知 的 消费 消费者\n",
            "= They d go back to being consumers clueless consumers like we are most of the time .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "< <SOS> of of of of of of of of of a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aCpeGthD8rCy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "from detok import detok\n",
        "import numpy as np\n",
        "\n",
        "def bleu(itos, translation_output, reference):\n",
        "    '''\n",
        "    Args:\n",
        "        arg.vocab.itos: a list the match indices to string.\n",
        "        translation_output: 2D tensor of tranlation output. shape: N x B\n",
        "        reference: 1D list of reference sentences (words, not indices). len(reference) = B\n",
        "    '''\n",
        "    EN_ind2word = np.array(itos)\n",
        "    detok_translation = detok(translation_output, EN_ind2word)\n",
        "    bleu_score = sacrebleu.raw_corpus_bleu(detok_translation, [reference], .01).score\n",
        "    \n",
        "\n",
        "    return bleu_score\n",
        "\n",
        "def bleu_epoch(itos, translation_outputs, reference):\n",
        "    '''\n",
        "    Args:\n",
        "        trg.vocab.itos: a list the match indices to string.\n",
        "        translation_output: 2D tensor of tranlation output. shape: N x B\n",
        "        reference: 1D list of reference sentences (words, not indices). len(reference) = B\n",
        "    '''\n",
        "    EN_ind2word = np.array(itos)\n",
        "    detok_translation = []\n",
        "    for translation_output in translation_outputs:\n",
        "        detok_translation.extend(detok(translation_output, EN_ind2word))\n",
        "    bleu_score = sacrebleu.raw_corpus_bleu(detok_translation, [reference], .01).score\n",
        "    \n",
        "\n",
        "    return bleu_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFgahQuvfyzn",
        "colab_type": "code",
        "outputId": "6172bf01-b7df-44ff-8079-cefd1ab5039f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "def tokenize_13a(line):\n",
        "    \"\"\"\n",
        "    Tokenizes an input line using a relatively minimal tokenization that is however equivalent to mteval-v13a, used by WMT.\n",
        "    :param line: a segment to tokenize\n",
        "    :return: the tokenized line\n",
        "    \"\"\"\n",
        "\n",
        "    norm = line\n",
        "\n",
        "    # language-independent part:\n",
        "    norm = norm.replace('<skipped>', '')\n",
        "    norm = norm.replace('-\\n', '')\n",
        "    norm = norm.replace('\\n', ' ')\n",
        "    norm = norm.replace('&quot;', '\"')\n",
        "    norm = norm.replace('&amp;', '&')\n",
        "    norm = norm.replace('&lt;', '<')\n",
        "    norm = norm.replace('&gt;', '>')\n",
        "\n",
        "    # language-dependent part (assuming Western languages):\n",
        "    norm = \" {} \".format(norm)\n",
        "    norm = re.sub(r'([\\{-\\~\\[-\\` -\\&\\(-\\+\\:-\\@\\/])', ' \\\\1 ', norm)\n",
        "    norm = re.sub(r'([^0-9])([\\.,])', '\\\\1 \\\\2 ', norm)  # tokenize period and comma unless preceded by a digit\n",
        "    norm = re.sub(r'([\\.,])([^0-9])', ' \\\\1 \\\\2', norm)  # tokenize period and comma unless followed by a digit\n",
        "    norm = re.sub(r'([0-9])(-)', '\\\\1 \\\\2 ', norm)  # tokenize dash when preceded by a digit\n",
        "    norm = re.sub(r'\\s+', ' ', norm)  # one space only between words\n",
        "    norm = re.sub(r'^\\s+', '', norm)  # no leading space\n",
        "    norm = re.sub(r'\\s+$', '', norm)  # no trailing space\n",
        "\n",
        "    return norm\n",
        "TOKENIZERS = {\n",
        "    '13a': tokenize_13a,\n",
        "\n",
        "}\n",
        "DEFAULT_TOKENIZER = '13a'\n",
        "\n",
        "def corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n",
        "                tokenize=DEFAULT_TOKENIZER, use_effective_order=False) -> BLEU:\n",
        "    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
        "    :param sys_stream: The system stream (a sequence of segments)\n",
        "    :param ref_streams: A list of one or more reference streams (each a sequence of segments)\n",
        "    :param smooth: The smoothing method to use\n",
        "    :param smooth_floor: For 'floor' smoothing, the floor to use\n",
        "    :param force: Ignore data that looks already tokenized\n",
        "    :param lowercase: Lowercase the data\n",
        "    :param tokenize: The tokenizer to use\n",
        "    :return: a BLEU object containing everything you'd want\n",
        "    \"\"\"\n",
        "\n",
        "    # Add some robustness to the input arguments\n",
        "    if isinstance(sys_stream, str):\n",
        "        sys_stream = [sys_stream]\n",
        "    if isinstance(ref_streams, str):\n",
        "        ref_streams = [[ref_streams]]\n",
        "\n",
        "    sys_len = 0\n",
        "    ref_len = 0\n",
        "\n",
        "    correct = [0 for n in range(NGRAM_ORDER)]\n",
        "    total = [0 for n in range(NGRAM_ORDER)]\n",
        "\n",
        "    # look for already-tokenized sentences\n",
        "    tokenized_count = 0\n",
        "\n",
        "    fhs = [sys_stream] + ref_streams\n",
        "    for lines in zip_longest(*fhs):\n",
        "        if None in lines:\n",
        "            raise EOFError(\"Source and reference streams have different lengths!\")\n",
        "\n",
        "        if lowercase:\n",
        "            lines = [x.lower() for x in lines]\n",
        "\n",
        "        if not (force or tokenize == 'none') and lines[0].rstrip().endswith(' .'):\n",
        "            tokenized_count += 1\n",
        "\n",
        "            if tokenized_count == 100:\n",
        "                logging.warning('That\\'s 100 lines that end in a tokenized period (\\'.\\')')\n",
        "                logging.warning('It looks like you forgot to detokenize your test data, which may hurt your score.')\n",
        "                logging.warning('If you insist your data is detokenized, or don\\'t care, you can suppress this message with \\'--force\\'.')\n",
        "\n",
        "        output, *refs = [TOKENIZERS[tokenize](x.rstrip()) for x in lines]\n",
        "\n",
        "        ref_ngrams, closest_diff, closest_len = ref_stats(output, refs)\n",
        "\n",
        "        sys_len += len(output.split())\n",
        "        ref_len += closest_len\n",
        "\n",
        "        sys_ngrams = extract_ngrams(output)\n",
        "        for ngram in sys_ngrams.keys():\n",
        "            n = len(ngram.split())\n",
        "            correct[n-1] += min(sys_ngrams[ngram], ref_ngrams.get(ngram, 0))\n",
        "            total[n-1] += sys_ngrams[ngram]\n",
        "\n",
        "    return compute_bleu(correct, total, sys_len, ref_len, smooth, smooth_floor, use_effective_order)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-5d62eba7cd67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m def corpus_bleu(sys_stream, ref_streams, smooth='exp', smooth_floor=0.0, force=False, lowercase=False,\n\u001b[0;32m---> 37\u001b[0;31m                 tokenize=DEFAULT_TOKENIZER, use_effective_order=False) -> BLEU:\n\u001b[0m\u001b[1;32m     38\u001b[0m     \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0msys_stream\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0msystem\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mof\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BLEU' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "A6RvLRZVf00V",
        "colab_type": "code",
        "outputId": "b87d8a6c-8789-4a38-95ac-30c75b715792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#The BLEU score consists of two parts, modified precision and brevity penalty. Details can be seen in the paper. You can use the nltk.align.bleu_score module inside the NLTK. One code example can be seen as below:\n",
        "\n",
        "import nltk\n",
        "\n",
        "hypothesis = ['It', 'is', 'a', 'cat', 'at', 'room']\n",
        "reference = ['It', 'is', 'a', 'cat', 'inside', 'the', 'room']\n",
        "#there may be several references\n",
        "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis)\n",
        "print (BLEUscore)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4548019047027907\n",
            "0.816496580927726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XiDbzWMwhmuM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}