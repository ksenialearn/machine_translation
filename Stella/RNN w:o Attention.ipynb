{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"j5gEAC1FcE2H","colab_type":"code","outputId":"70acfbae-c684-4f7c-f529-a74b43dfc98d","executionInfo":{"status":"ok","timestamp":1543343162894,"user_tz":300,"elapsed":37455,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["!pip install -q torch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1073750016 bytes == 0x59506000 @  0x7fb25ce662a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"],"name":"stdout"}]},{"metadata":{"id":"AFDLkS4Jb6jt","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from collections import Counter\n","import pickle as pkl\n","import random\n","import pdb\n","import pandas as pd\n","import string\n","import re\n","import unicodedata\n","import os\n","import time\n","import math\n","\n","import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.utils.data import Dataset\n","from torch.autograd import Variable\n","from torch.nn import functional\n","\n","import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","%matplotlib inline\n","\n","#specify SOS() and EOS(end of sentence)\n","#specify maximum vocabulary size = 50000\n","PAD_IDX = 2\n","UNK_IDX = 3\n","SOS_token = 0\n","EOS_token = 1\n","MAX_VOCAB_SIZE = 50000\n","MAX_LENGTH = 30\n","\n","train_en = 'data/train.tok.en'\n","train_zh = 'data/train.tok.zh'\n","val_en = 'data/dev.tok.en'\n","val_zh = 'data/dev.tok.zh'\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EECPWtJ3ciU_","colab_type":"code","outputId":"23ec6c9e-f819-4dfa-9600-57bd11f1cd69","executionInfo":{"status":"ok","timestamp":1543343170117,"user_tz":300,"elapsed":537,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#user GPU if possible\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if device.type == \"cuda\":\n","  print(\"Currently using GPU\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Currently using GPU\n"],"name":"stdout"}]},{"metadata":{"id":"i_tjIMPxcpp5","colab_type":"code","outputId":"98c957df-8cd2-493e-aeff-51927949abad","executionInfo":{"status":"ok","timestamp":1543343192308,"user_tz":300,"elapsed":21221,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"C98AhPAudHCx","colab_type":"code","colab":{}},"cell_type":"code","source":["folder_path = os.getcwd() + '/gdrive/My Drive/NLP/Project/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XXkMXRPRVkXq","colab_type":"text"},"cell_type":"markdown","source":["Load Pre-Trained Embedding Matrix"]},{"metadata":{"id":"94g-RecrVkCd","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_emb_matrix(language):\n","    #load fasttext word vectors\n","    words_to_load = MAX_VOCAB_SIZE\n","    if language == 'english':\n","      file = 'wiki-news-300d-1M-subword.vec'\n","    if language == 'chinese':\n","      file = 'cc.zh.300.vec'\n","    \n","\n","    with open(folder_path + 'data/' + file) as f:\n","        #remove the first line\n","        firstLine = f.readline()\n","        loaded_embeddings = np.zeros((words_to_load + 4, 300))\n","        words2id = {}\n","        idx2words = {}\n","        #ordered_words = []\n","        for i, line in enumerate(f):\n","            if i >= words_to_load: \n","                break\n","            s = line.split()\n","            loaded_embeddings[i + 4 , :] = np.asarray(s[1:])\n","            words2id['<SOS>'] = SOS_token\n","            words2id['<EOS>'] = EOS_token\n","            words2id['<pad>'] = PAD_IDX\n","            words2id['<unk>'] = UNK_IDX\n","            words2id[s[0]] = i + 4\n","            \n","            idx2words[0] = '<SOS>'\n","            idx2words[1] = '<EOD>'\n","            idx2words[2] = '<pad>'\n","            idx2words[3] = '<unk>'\n","            \n","            idx2words[i + 4] = s[0]\n","   \n","\n","    return words2id,idx2words,loaded_embeddings"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zbr8-z74VnQM","colab_type":"code","colab":{}},"cell_type":"code","source":["def generate_weights_matrix(idx2words,loaded_embeddings):\n","   \n","    matrix_len = len(idx2words)\n","    weights_matrix = np.zeros((matrix_len, 300))\n","    \n","    for key in idx2words.keys():\n","        try: \n","            weights_matrix[key] = loaded_embeddings[key]\n","        except KeyError:\n","            weights_matrix[key] = np.random.normal(scale=0.6, size=(emb_dim, ))\n","    return weights_matrix"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d1Lgh3zqVq_Y","colab_type":"code","colab":{}},"cell_type":"code","source":["words2id_eng,idx2words_eng,loaded_embeddings_eng = load_emb_matrix('english')\n","words2id_zh,idx2words_zh,loaded_embeddings_zh = load_emb_matrix('chinese')\n","\n","pkl.dump(words2id_eng, open(folder_path + 'data/words2id_eng.pkl', 'wb'))\n","pkl.dump(idx2words_eng, open(folder_path +'data/idx2words_eng.pkl', 'wb'))\n","pkl.dump(loaded_embeddings_eng, open(folder_path +'data/embedding_matrix_eng.pkl', 'wb'))\n","\n","pkl.dump(words2id_zh, open(folder_path + 'data/words2id_zh.pkl', 'wb'))\n","pkl.dump(idx2words_zh, open(folder_path + 'data/idx2words_zh.pkl', 'wb'))\n","pkl.dump(loaded_embeddings_zh, open(folder_path +'data/embedding_matrix_zh.pkl', 'wb'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ymuMyCSDVu1k","colab_type":"code","colab":{}},"cell_type":"code","source":["# words2id_eng = pkl.load(open(folder_path + \"data/words2id_eng.pkl\", \"rb\"))\n","# idx2words_eng = pkl.load(open(folder_path +\"data/idx2words_eng.pkl\", \"rb\"))\n","# loaded_embeddings_eng = pkl.load(open(folder_path +\"data/embedding_matrix_eng.pkl\", \"rb\"))\n","# words2id_zh = pkl.load(open(folder_path + \"data/words2id_zh.pkl\", \"rb\"))\n","# idx2words_zh = pkl.load(open(folder_path +\"data/idx2words_zh.pkl\", \"rb\"))\n","# loaded_embeddings_zh = pkl.load(open(folder_path +\"data/embedding_matrix_zh.pkl\", \"rb\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tfc1Gl2NVxbB","colab_type":"code","colab":{}},"cell_type":"code","source":["weights_matrix_eng = generate_weights_matrix(idx2words_eng,loaded_embeddings_eng)\n","pkl.dump(weights_matrix_eng, open(folder_path + 'data/weights_matrix_eng.pkl', 'wb'))\n","weights_matrix_eng = torch.from_numpy(weights_matrix_eng).to(device)\n","\n","weights_matrix_zh = generate_weights_matrix(idx2words_zh,loaded_embeddings_zh)\n","pkl.dump(weights_matrix_zh, open(folder_path + 'data/weights_matrix_zh.pkl', 'wb'))\n","weights_matrix_zh = torch.from_numpy(weights_matrix_zh).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wy5jaTwObHpC","colab_type":"code","colab":{}},"cell_type":"code","source":["# weights_matrix_eng = pkl.load(open(folder_path +\"data/weights_matrix_eng.pkl\", \"rb\"))\n","# weights_matrix_zh = pkl.load(open(folder_path +\"data/weights_matrix_zh.pkl\", \"rb\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jWY3vZhmV3Ll","colab_type":"text"},"cell_type":"markdown","source":["Read Languages"]},{"metadata":{"id":"4MeYaL3mdVOm","colab_type":"code","colab":{}},"cell_type":"code","source":["#define a class of language\n","class Language:\n","    def __init__(self, name,word2index,index2word):\n","        self.name = name\n","        self.word2index = word2index\n","        #self.word2count = {}\n","        self.index2word = index2word\n","        self.n_words = len(word2index)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yFXU99BHdqsr","colab_type":"code","colab":{}},"cell_type":"code","source":["# Turn a Unicode string to plain ASCII, thanks to\n","# http://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","\n","def normalizeString(s):\n","    s = s.replace(r\"&quot;\",\"\")\n","    s = s.replace(r\"&apos;\",\"'\")\n","    s = unicodeToAscii(s.strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s\n","  \n","  \n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pb4ofVFnds6b","colab_type":"code","colab":{}},"cell_type":"code","source":["#To read the data file we will split the file into lines, and then split lines into pairs. \n","\n","def readLanguages(input_lang,target_lang):\n","    print(\"\\nReading lines...\")\n","\n","    # Read the file and split into lines\n","    input_lines = open(folder_path + input_lang, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","    target_lines = open(folder_path + target_lang, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Split every line and normalize\n","    #for chinese input, strip the space at the begining and end of the sentence\n","    #for english output, use normalizeString function\n","    input_lines_norm = [l.strip() for l in input_lines]\n","    target_lines_norm = [normalizeString(l) for l in target_lines]\n","    \n","    #build pairs\n","    #drop pair if both zh and en are empty strings\n","    pairs = [[item[0],item[1]] for item in zip(input_lines_norm,target_lines_norm) if len(item[0])+len(item[1]) != 0]\n","    \n","    input_lines = Language(\"zh\",words2id_zh,idx2words_zh)\n","    target_lines = Language(\"en\",words2id_eng,idx2words_eng)\n","\n","    return input_lines, target_lines, pairs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f0iZ-uz6Vmm6","colab_type":"code","colab":{}},"cell_type":"code","source":["#To read the data file we will split the file into lines, and then split lines into pairs. \n","\n","# def readLanguages_sample(input_lang,target_lang):\n","#     print(\"\\nReading lines...\")\n","\n","#     # Read the file and split into lines\n","#     input_lines = open(folder_path + input_lang, encoding='utf-8').\\\n","#         read().strip().split('\\n')\n","#     target_lines = open(folder_path + target_lang, encoding='utf-8').\\\n","#         read().strip().split('\\n')\n","\n","#     # Split every line and normalize\n","#     #for chinese input, strip the space at the begining and end of the sentence\n","#     #for english output, use normalizeString function\n","#     sample_input = input_lines[:10000]\n","#     sample_target = target_lines[:10000]\n","    \n","#     input_lines_norm = [l.strip() for l in sample_input]\n","#     target_lines_norm = [normalizeString(l) for l in sample_target]\n","    \n","#     #build pairs\n","#     #drop pair if both zh and en are empty strings\n","#     pairs = [[item[0],item[1]] for item in zip(input_lines_norm,target_lines_norm) if len(item[0])+len(item[1]) != 0]\n","    \n","#     input_lines = Language(\"zh\")\n","#     target_lines = Language(\"en\")\n","\n","#     return input_lines, target_lines, pairs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l4_2uJByV6os","colab_type":"code","colab":{}},"cell_type":"code","source":["# def prepareData_sample(input_lang, target_lang):\n","#     input_lang, output_lang, pairs = readLanguages_sample(input_lang, target_lang)\n","#     print(\"Read %s sentence pairs\" % len(pairs))\n","#     pairs = filterPairs(pairs)\n","#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","#     print(\"Counting words...\")\n","#     for pair in pairs:\n","#         input_lang.addSentence(pair[0])\n","#         output_lang.addSentence(pair[1])\n","#     print(\"Counted words:\")\n","#     print(input_lang.name, input_lang.n_words)\n","#     print(output_lang.name, output_lang.n_words)\n","    \n","#     return input_lang, output_lang, pairs\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gr2qskuYduXj","colab_type":"code","colab":{}},"cell_type":"code","source":["def prepareData(input_lang, target_lang):\n","    input_lang, output_lang, pairs = readLanguages(input_lang, target_lang)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","#     for pair in pairs:\n","#         input_lang.addSentence(pair[0])\n","#         output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    \n","    return input_lang, output_lang, pairs\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qTNg71nSd2yN","colab_type":"text"},"cell_type":"markdown","source":["\n","Preparing Data\n","========"]},{"metadata":{"id":"Ezo0-c2dd02j","colab_type":"code","outputId":"68f3fb37-bdef-4d5f-8b15-aae1c45dc49e","executionInfo":{"status":"ok","timestamp":1543343312363,"user_tz":300,"elapsed":14250,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"cell_type":"code","source":["train_input_lang, train_output_lang, train_pairs = prepareData(train_zh, train_en)\n","print(\"print a random pair of training pairs:\")\n","print(random.choice(train_pairs))\n","\n","\n","\n","# val_input_lang, val_output_lang, val_pairs = prepareData(val_zh, val_en)\n","# print(\"print a random pair of validation pairs:\")\n","# print(random.choice(val_pairs))\n","\n","\n","# pkl.dump(train_input, open(folder_path +'data/train_input.pkl', 'wb'))\n","# pkl.dump(train_output, open(folder_path +'data/train_output.pkl', 'wb'))\n","# pkl.dump(train_pairs, open(folder_path +'data/train_pairs.pkl', 'wb'))\n","# pkl.dump(val_input, open(folder_path +'data/val_input.pkl', 'wb'))\n","# pkl.dump(val_output, open(folder_path +'data/val_output.pkl', 'wb'))\n","# pkl.dump(val_pairs, open(folder_path +'data/val_pairs.pkl', 'wb'))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\n","Reading lines...\n","Read 213237 sentence pairs\n","Trimmed to 156070 sentence pairs\n","Counting words...\n","Counted words:\n","zh 50004\n","en 50004\n","print a random pair of training pairs:\n","['我 想要 成为 更好   去 学习 任何 我 能 获得 的 东西', 'So I wanted to become much better at it and learn anything I could .']\n"],"name":"stdout"}]},{"metadata":{"id":"Kw_apu2OVam5","colab_type":"text"},"cell_type":"markdown","source":["Get a sample dataset"]},{"metadata":{"id":"cDX9E0M1VaNm","colab_type":"code","outputId":"f0765ca4-78a1-40ba-b7c5-aaee68a690a7","executionInfo":{"status":"ok","timestamp":1543183124091,"user_tz":300,"elapsed":3376,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"cell_type":"code","source":["# train_input_lang_sample, train_output_lang_sample, train_pairs_sample = prepareData_sample(train_zh, train_en)\n","# print(\"print a random pair of training pairs:\")\n","# print(random.choice(train_pairs_sample))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Reading lines...\n","Read 10000 sentence pairs\n","Trimmed to 7289 sentence pairs\n","Counting words...\n","Counted words:\n","zh 13387\n","en 8814\n","print a random pair of training pairs:\n","['我 对 作弊 的 兴趣 从   美国 国安 安然 公司 突然 爆发 丑闻 开始   我 开始 思考 考究 究竟 发生 了 什么 事情', 'So my interest in cheating started when Enron came on the scene exploded all of a sudden and I started thinking about what is happening here .']\n"],"name":"stdout"}]},{"metadata":{"id":"O9mT_hRjtjtZ","colab_type":"code","colab":{}},"cell_type":"code","source":["# train_pairs =  pkl.load(open(folder_path +'data/train_pairs.pkl', \"rb\"))\n","# val_pairs =  pkl.load(open(folder_path +'data/val_pairs.pkl', \"rb\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kv_hg5RgCIUG","colab_type":"text"},"cell_type":"markdown","source":["## Build DataLoader for minibatch"]},{"metadata":{"id":"gtrpmYwcXSEj","colab_type":"code","colab":{}},"cell_type":"code","source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] if word in lang.word2index else UNK_IDX for word in sentence.split(' ')] + [EOS_token]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CRXUY_jGCK_Z","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 32\n","\n","class VocabDataset(Dataset):\n","    \"\"\"\n","    Note that this class inherits torch.utils.data.Dataset\n","    \"\"\"\n","\n","    def __init__(self, pairs,input_language, output_language):\n","        \"\"\"\n","        @param pairs: pairs of input and target sentences(raw text sentences)\n","        @param input_language: Class Lang of input languages (zh in this case)\n","        @param output_language: Class Lang of output languages (en in this case)\n","\n","        \"\"\"\n","        self.pairs = pairs\n","        self.inputs = [pair[0] for pair in pairs]\n","        self.input_lang = input_language\n","        self.output_lang = output_language\n","        self.outputs = [pair[1] for pair in pairs]\n","        \n","        \n","        #assert self.input_lang == self.target_lang\n","       \n","    def __len__(self):\n","         return len(self.pairs)\n","\n","    def __getitem__(self, key):\n","        \"\"\"\n","        Triggered when you call dataset[i]\n","        \"\"\"\n","        \n","        #turn raw text sentecens into indices\n","        input_ = indexesFromSentence(self.input_lang, self.inputs[key])\n","        output = indexesFromSentence(self.output_lang, self.outputs[key])\n","        \n","        #print both the length of the source sequence and the target sequence\n","        return [input_,len(input_),output,len(output)]\n","    \n","    \n","    def __gettext__(self,key):\n","      return [self.inputs[key],self.outputs[key]]\n","\n","def vocab_collate_func(batch):\n","    \"\"\"\n","    Customized function for DataLoader that dynamically pads the batch so that all\n","    data have the same length\n","    \"\"\"\n","    input_data_list = []\n","    output_data_list = []\n","   \n","    \n","    for datum in batch:\n","      input_data_list.append(datum[0])\n","      output_data_list.append(datum[2])\n","      \n","      \n","    # Zip into pairs, sort by length (descending), unzip\n","    seq_pairs = sorted(zip(input_data_list, output_data_list), key=lambda p: len(p[0]), reverse=True)\n","    input_seqs, output_seqs = zip(*seq_pairs)\n","    \n","    #store the length of the sequences \n","    input_data_len = [len(p) for p in input_seqs]\n","    output_data_len = [len(p) for p in output_seqs]\n","    \n","    #padding\n","    padded_vec_input = [np.pad(np.array(p),\n","                                 pad_width=((0,MAX_LENGTH-len(p))),\n","                                 mode=\"constant\", constant_values=0) for p in input_seqs]\n","        \n","    padded_vec_output = [np.pad(np.array(p),\n","                                 pad_width=((0,MAX_LENGTH-len(p))),\n","                                 mode=\"constant\", constant_values=0) for p in output_seqs]      \n","    \n","    \n","    input_var = Variable(torch.LongTensor(padded_vec_input))\n","    output_var = Variable(torch.LongTensor(padded_vec_output))\n","    input_data_len = Variable(torch.LongTensor(input_data_len))\n","    output_data_len = Variable(torch.LongTensor(output_data_len))\n","    \n","    \n","    return [input_var,input_data_len,output_var,output_data_len]\n","   \n","\n","   "],"execution_count":0,"outputs":[]},{"metadata":{"id":"era1TecuBkbZ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Build train and valid dataloaders\n","\n","train_dataset = VocabDataset(train_pairs,train_input_lang, train_output_lang)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=BATCH_SIZE,\n","                                           collate_fn=vocab_collate_func,\n","                                           shuffle=True,\n","                                           drop_last = True)\n","\n","\n","# val_dataset = VocabDataset(val_pairs,val_input_lang,val_output_lang)\n","# val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n","#                                            batch_size=BATCH_SIZE,\n","#                                            collate_fn=vocab_collate_func,\n","#                                            shuffle=True)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HrbwAaZdWQxL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Build sample train and valid dataloaders \n","\n","# train_dataset_sample = VocabDataset(train_pairs_sample,train_input_lang_sample, train_output_lang_sample)\n","# train_loader_sample = torch.utils.data.DataLoader(dataset=train_dataset_sample,\n","#                                            batch_size=BATCH_SIZE,\n","#                                            collate_fn=vocab_collate_func,\n","#                                            shuffle=True,\n","#                                            drop_last = True)\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZMW25gxlegOI","colab_type":"text"},"cell_type":"markdown","source":["Building Neural Networks (Encoder & Decoder)\n","-----------"]},{"metadata":{"id":"J8wHM-C_eiZe","colab_type":"text"},"cell_type":"markdown","source":["The Encoder\n","-----------\n","\n","The encoder of a seq2seq network is a RNN that outputs some value for\n","every word from the input sentence. For every input word the encoder\n","outputs a vector and a hidden state, and uses the hidden state for the\n","next input word."]},{"metadata":{"id":"mM7ZZ-Rxd7eI","colab_type":"code","colab":{}},"cell_type":"code","source":["class EncoderRNN(nn.Module):\n","    def __init__(self, weights_matrix, input_size, hidden_size,n_layers=1):\n","        super(EncoderRNN, self).__init__()\n","     \n","        \n","        self.hidden_size = hidden_size\n","        self.input_size = input_size\n","        self.n_layers = n_layers\n","        self.batch_size = BATCH_SIZE\n","        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n","        \n","        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n","        self.embedding.weight.data.copy_(weights_matrix)\n","        self.embedding.weight.requires_grad = False\n","\n","        \n","        self.gru = nn.GRU(self.embedding_dim, hidden_size, n_layers, bidirectional=True)\n","        \n","\n","    def forward(self, input_seqs, input_len, hidden=None):\n","\n","       \n","        embedded = self.embedding(input_seqs)\n","        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_len)\n","        output, hidden = self.gru(packed, hidden)\n","\n","        output, output_len = torch.nn.utils.rnn.pad_packed_sequence(output)\n","        output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:]\n","        \n","        return output,hidden\n","      \n","\n","   "],"execution_count":0,"outputs":[]},{"metadata":{"id":"lDXqaOcIemxJ","colab_type":"text"},"cell_type":"markdown","source":["Decoder w/o Attention\n","------------------------\n","In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n","\n","At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder's last hidden state)."]},{"metadata":{"id":"RH3TuHMBek6l","colab_type":"code","colab":{}},"cell_type":"code","source":["class DecoderRNN(nn.Module):\n","    def __init__(self, weights_matrix, hidden_size, output_size,n_layers=1):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.batch_size = BATCH_SIZE\n","        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n","        \n","        #self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n","        self.embedding.weight.data.copy_(weights_matrix)\n","        self.embedding.weight.requires_grad = False\n","        \n","        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n","        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n","        \n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input_seq, hidden):\n","        \n","        embedded = self.embedding(input_seq) # dim = Batch_Size x embedding_dim\n","        embedded = embedded.view(1, self.batch_size, self.embedding_dim) # S=1 x Batch_Size x embedding_dim\n","        \n","        rnn_output, hidden = self.gru1(embedded, hidden)\n","        output = F.relu(rnn_output)\n","        \n","        output, hidden = self.gru2(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        \n","        return output,hidden\n","\n","\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kf0XoyhCKnbD","colab_type":"text"},"cell_type":"markdown","source":["Attention Decoder\n","----------------\n","\n","If only the context vector is passed betweeen the encoder and decoder,\n","that single vector carries the burden of encoding the entire sentence.\n","\n","Attention allows the decoder network to \"focus\" on a different part of\n","the encoder's outputs for every step of the decoder's own outputs. First\n","we calculate a set of *attention weights*. These will be multiplied by\n","the encoder output vectors to create a weighted combination. The result\n","(called ``attn_applied`` in the code) should contain information about\n","that specific part of the input sequence, and thus help the decoder\n","choose the right output words.\n","\n","Calculating the attention weights is done with another feed-forward\n","layer ``attn``, using the decoder's input and hidden state as inputs.\n","Because there are sentences of all sizes in the training data, to\n","actually create and train this layer we have to choose a maximum\n","sentence length (input length, for encoder outputs) that it can apply\n","to. Sentences of the maximum length will use all the attention weights,\n","while shorter sentences will only use the first few.\n"]},{"metadata":{"id":"Yxx9mcl-KigJ","colab_type":"code","colab":{}},"cell_type":"code","source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, weights_matrix, hidden_size, output_size, n_layers=1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.max_length = max_length\n","        self.batch_size = BATCH_SIZE\n","        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n","\n","        #self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n","        self.embedding.weight.data.copy_(weights_matrix)\n","        self.embedding.weight.requires_grad = False\n","        \n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","       \n","        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n","        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n","        \n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input_seq, hidden, encoder_outputs):\n","        embedded = self.embedding(input_seq).view(1, 1, -1)\n"," \n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0kI360o3xu5K","colab_type":"code","colab":{}},"cell_type":"code","source":["class Attn(nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        \n","        self.method = method\n","        self.hidden_size = hidden_size\n","        \n","        if self.method == 'general':\n","            self.attn = nn.Linear(self.hidden_size, hidden_size)\n","\n","        elif self.method == 'concat':\n","            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n","     \n","    def forward(self, hidden, encoder_outputs):\n","        max_len = encoder_outputs.size(0)\n","        this_batch_size = encoder_outputs.size(1)\n","\n","        # Create variable to store attention energies\n","        attn_energies = Variable(torch.zeros(this_batch_size, max_len)).to(device) # Batch_Size x Seq_Length\n","\n","        \n","#         # For each batch of encoder outputs\n","        for b in range(this_batch_size):\n","            # Calculate energy for each encoder output\n","            for i in range(max_len):\n","                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n","\n","        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n","        return F.softmax(attn_energies,dim=1).unsqueeze(1)\n","      \n","    def score(self, hidden, encoder_output):\n","        \n","        if self.method == 'dot':\n","            energy = hidden.dot(encoder_output)\n","            return energy\n","        \n","        elif self.method == 'general':\n","            energy = self.attn(encoder_output)\n","            energy = torch.mm(hidden, energy.transpose(0,1))\n","            return energy\n","        \n","        elif self.method == 'concat':\n","            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n","            energy = self.v.dot(energy)\n","            return energy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e5vIr_QVxJ8y","colab_type":"code","colab":{}},"cell_type":"code","source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, weights_matrix, hidden_size, output_size, n_layers=1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.batch_size = BATCH_SIZE\n","        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n","\n","\n","        # Define layers\n","        #self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n","        self.embedding.weight.data.copy_(weights_matrix)\n","        self.embedding.weight.requires_grad = False\n","        \n","        \n","        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n","        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n","        \n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        \n","        # Choose attention model\n","        if attn_model != 'none':\n","            self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_seq, last_hidden, encoder_outputs):\n","        # Note: we run this one step at a time\n","\n","        # Get the embedding of the current input word (last output word)\n","\n","        embedded = self.embedding(input_seq) # dim = Batch_Size x embedding_dim\n","        embedded = embedded.view(1, self.batch_size, self.embedding_dim) # S=1 x Batch_Size x embedding_dim\n","\n","        # Get current hidden state from input word and last hidden state\n","        # rnn_output : [1 x batch_size x hidden_size]\n","        # hidden: [layer x batch_size x hidden_size]\n","        rnn_output, hidden = self.gru1(embedded, last_hidden)\n","        \n","        # Calculate attention from current RNN state and all encoder outputs;\n","        # apply to encoder outputs to get weighted average\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n","\n","        # Attentional vector using the RNN hidden state and context vector\n","        # concatenated together (Luong eq. 5)\n","        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n","        context = context.squeeze(1)       # B x S=1 x N -> B x N\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","\n","        # Finally predict next token (Luong eq. 6, without softmax)\n","        output = self.out(concat_output)\n","\n","        #Return final output, hidden state, and attention weights (for visualization)\n","        return output, hidden, attn_weights\n","        #return attn_weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nn0Z9iWBxNpB","colab_type":"code","colab":{}},"cell_type":"code","source":["class BahdanauAttnDecoderRNN(nn.Module):\n","    def __init__(self, weights_matrix, hidden_size, output_size, n_layers=1):\n","        super(BahdanauAttnDecoderRNN, self).__init__()\n","        \n","        # Define parameters\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.max_length = max_length\n","        self.batch_size = BATCH_SIZE\n","        self.num_embeddings, self.embedding_dim = weights_matrix.size()\n","        \n","        \n","        # Define layers\n","        #self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n","        self.embedding.weight.data.copy_(weights_matrix)\n","        self.embedding.weight.requires_grad = False\n","        \n","        self.attn = Attn('concat', hidden_size)\n","        self.gru1 = nn.GRU(self.embedding_dim, hidden_size,n_layers)\n","        self.gru2 = nn.GRU(hidden_size, hidden_size,n_layers)\n","        self.out = nn.Linear(hidden_size, output_size)\n","    \n","    def forward(self, word_input, last_hidden, encoder_outputs):\n","        # Note: we run this one step at a time\n","        # TODO: FIX BATCHING\n","        \n","        # Get the embedding of the current input word (last output word)\n","        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n","        \n","        # Calculate attention weights and apply to encoder outputs\n","        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n","        context = context.transpose(0, 1) # 1 x B x N\n","        \n","        # Combine embedded input word and attended context, run through RNN\n","        rnn_input = torch.cat((word_embedded, context), 2)\n","        output, hidden = self.gru(rnn_input, last_hidden)\n","        \n","        # Final output layer\n","        output = output.squeeze(0) # B x N\n","        output = F.log_softmax(self.out(torch.cat((output, context), 1)),dim=1)\n","        \n","        # Return final output, hidden state, and attention weights (for visualization)\n","        return output, hidden, attn_weights\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OGcsiLGper6v","colab_type":"text"},"cell_type":"markdown","source":["Training\n","========"]},{"metadata":{"id":"D3_iRFeze-1-","colab_type":"code","colab":{}},"cell_type":"code","source":["#record the run time\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zBNDURhNfFrx","colab_type":"code","colab":{}},"cell_type":"code","source":["def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7Ii-mwm4fOt5","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH,if_attention = False):\n","    \"\"\"\n","    Function that generate translation.\n","    First, feed the source sentence into the encoder and obtain the hidden states from encoder.\n","    Secondly, feed the hidden states into the decoder and unfold the outputs from the decoder.\n","    Lastly, for each outputs from the decoder, collect the corresponding words in the target language's vocabulary.\n","    And collect the attention for each output words.\n","    @param encoder: the encoder network\n","    @param decoder: the decoder network\n","    @param sentence: string, a sentence in source language to be translated\n","    @param max_length: the max # of words that the decoder can return\n","    @output decoded_words: a list of words in target language\n","    @output decoder_attentions: a list of vector, each of which sums up to 1.0\n","    \"\"\"    \n","    # process input sentence\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(train_input, sentence)\n","        input_length = input_tensor.size()[0]\n","        # encode the source lanugage\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","        # decode the context vector\n","        decoder_hidden = encoder_hidden # decoder starts from the last encoding sentence\n","        # output of this function\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            if if_attention == True:\n","            # for each time step, the decoder network takes two inputs: previous outputs and the previous hidden states\n","              decoder_output, decoder_hidden, decoder_attention = decoder(\n","                  decoder_input, decoder_hidden, encoder_outputs)\n","              decoder_attentions[di] = decoder_attention.data\n","            else:\n","              decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","              \n","            \n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(train_output.index2word[topi.item()])\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]\n","     "],"execution_count":0,"outputs":[]},{"metadata":{"id":"NGtaOifdfQXm","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluateRandomly(encoder, decoder, data_pair,n=10):\n","    \"\"\"\n","    Randomly select a English sentence from the dataset and try to produce its French translation.\n","    Note that you need a correct implementation of evaluate() in order to make this function work.\n","    \"\"\"    \n","    for i in range(n):\n","        pair = random.choice(data_pair)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, data_pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DkAy8YisWxBo","colab_type":"code","colab":{}},"cell_type":"code","source":["def sequence_mask(sequence_length, max_len=None):\n","    if max_len is None:\n","        max_len = sequence_length.data.max()\n","    batch_size = BATCH_SIZE\n","    seq_range = torch.arange(0, max_len).long()\n","    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n","    seq_range_expand = Variable(seq_range_expand)\n","    \n","    seq_range_expand = seq_range_expand.to(device)\n","    seq_length_expand = (sequence_length.unsqueeze(1)\n","                         .expand_as(seq_range_expand))\n","    return seq_range_expand < seq_length_expand\n","\n","\n","def masked_cross_entropy(logits, target, length):\n","    length = Variable(torch.LongTensor(length)).to(device)\n","\n","    \"\"\"\n","    Args:\n","        logits: A Variable containing a FloatTensor of size\n","            (batch, max_len, num_classes) which contains the\n","            unnormalized probability for each class.\n","        target: A Variable containing a LongTensor of size\n","            (batch, max_len) which contains the index of the true\n","            class for each corresponding step.\n","        length: A Variable containing a LongTensor of size (batch,)\n","            which contains the length of each data in a batch.\n","    Returns:\n","        loss: An average loss value masked by the length.\n","    \"\"\"\n","    \n","    # logits_flat: (batch * max_len, num_classes)\n","    logits_flat = logits.view(-1, logits.size(-1))\n","    # log_probs_flat: (batch * max_len, num_classes)\n","    log_probs_flat = F.log_softmax(logits_flat,dim=1)\n","    \n","    # target_flat: (batch * max_len, 1)\n","    target_flat = target.view(-1, 1)\n","    \n","    # losses_flat: (batch * max_len, 1)\n","    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n","    # losses: (batch, max_len)\n","    losses = losses_flat.view(*target.size())\n","    # mask: (batch, max_len)\n","    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n","    losses = losses * mask.float()\n","    loss = losses.sum() / length.float().sum()\n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hx1FtRrWhOXj","colab_type":"text"},"cell_type":"markdown","source":["##Train Model"]},{"metadata":{"id":"-sSkci42fSlv","colab_type":"code","colab":{}},"cell_type":"code","source":["hidden_size = 500\n","\n","encoder1 = EncoderRNN(weights_matrix_zh, train_input_lang.n_words, hidden_size,n_layers = 2).to(device)\n","#decoder1 = LuongAttnDecoderRNN('general', weights_matrix, hidden_size, train_output_lang_sample.n_words,n_layers = 2).to(device)\n","decoder1 = DecoderRNN(weights_matrix_eng, hidden_size, train_output_lang.n_words,n_layers = 2).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wETx_u3TojB5","colab_type":"code","colab":{}},"cell_type":"code","source":["# encoder1 = EncoderRNN(train_input.n_words, hidden_size).to(device)\n","# decoder1 = DecoderRNN(hidden_size,train_output.n_words).to(device)\n","# encoder1.load_state_dict(torch.load(folder_path + \"encoder1.pt\"))\n","# decoder1.load_state_dict(torch.load(folder_path +\"decoder1.pt\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WcDCsUc7bMfp","colab_type":"text"},"cell_type":"markdown","source":["Testing small batches with teaching force"]},{"metadata":{"id":"FBgS14qQQFRP","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder_optimizer = optim.SGD(encoder1.parameters(), lr=0.1)\n","decoder_optimizer = optim.SGD(decoder1.parameters(), lr=0.1)\n","criterion = nn.NLLLoss()\n","teacher_forcing_ratio = 0.5\n","learning_rate = 0.0001\n","\n","running_loss = 0\n","for i, (input_var,input_data_len,output_var,output_data_len) in enumerate(train_loader):\n","\n","  input_batch = input_var.transpose(0,1).to(device)\n","  output_batch = output_var.transpose(0,1).to(device)\n","\n","  loss = train(input_batch,input_data_len,output_batch,output_data_len, encoder1,\n","                 decoder1, encoder_optimizer, decoder_optimizer, criterion)\n","  print(loss)\n","  running_loss += loss\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_oFpX3pHea0d","colab_type":"code","outputId":"694748b3-72ca-4d9d-cc75-5654095a7b97","executionInfo":{"status":"ok","timestamp":1543277006361,"user_tz":300,"elapsed":561,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["running_loss / len(train_loader.dataset)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["218.58528626361235"]},"metadata":{"tags":[]},"execution_count":38}]},{"metadata":{"id":"q0XUhHfW8s4J","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder_optimizer = optim.SGD(encoder1.parameters(), lr=0.1)\n","decoder_optimizer = optim.SGD(decoder1.parameters(), lr=0.1)\n","criterion = nn.NLLLoss()\n","\n","for l, (input_var,input_data_len,output_var,output_data_len) in enumerate(train_loader):\n","    input_batch = input_var.transpose(0,1).to(device)\n","    output_batch = output_var.transpose(0,1).to(device)\n","    encoder_outputs, encoder_hidden = encoder1(input_batch, input_data_len, None)\n","  \n","    max_target_length = MAX_LENGTH\n","    # Prepare decoder input and outputs\n","    decoder_input = Variable(torch.LongTensor([SOS_token] * BATCH_SIZE)).to(device)\n","    decoder_hidden = encoder_hidden[:decoder1.n_layers] # Use last (forward) hidden state from encoder\n","    all_decoder_outputs = Variable(torch.zeros(max_target_length, BATCH_SIZE, decoder1.output_size)).to(device)\n"," \n","  \n","    # Run through decoder one time step at a time\n","    for t in range(max_target_length):\n","        decoder_output,decoder_hidden = decoder1(\n","        decoder_input, decoder_hidden\n","    )\n","        \n","        topv, topi = decoder_output.topk(1)\n","        decoder_input = topi.squeeze().detach()  # detach from history as input\n","        all_decoder_outputs[t] = decoder_output # Store this step's outputs\n","    \n","    # Test masked cross entropy loss\n","    loss = masked_cross_entropy(\n","        all_decoder_outputs.transpose(0, 1).contiguous(),\n","        output_batch.transpose(0, 1).contiguous(),\n","        output_data_len)\n","\n","    if l >= 20:\n","        break\n","  \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3REdfQ8iYBcn","colab_type":"code","outputId":"d9a401a1-f562-4c3a-a075-a77289eb493a","executionInfo":{"status":"ok","timestamp":1543241740446,"user_tz":300,"elapsed":1038,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["loss"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(10.8263, device='cuda:0', grad_fn=<DivBackward1>)"]},"metadata":{"tags":[]},"execution_count":74}]},{"metadata":{"id":"fDnQbc6IbER9","colab_type":"text"},"cell_type":"markdown","source":["Testing without teaching force"]},{"metadata":{"id":"sRF9fgto9wcY","colab_type":"code","colab":{}},"cell_type":"code","source":["encoder_optimizer = optim.SGD(encoder1.parameters(), lr=0.1)\n","decoder_optimizer = optim.SGD(decoder1.parameters(), lr=0.1)\n","criterion = nn.NLLLoss()\n","\n","for l, (input_var,input_data_len,output_var,output_data_len) in enumerate(train_loader):\n","    input_batch = input_var.transpose(0,1).to(device)\n","    output_batch = output_var.transpose(0,1).to(device)\n","    encoder_outputs, encoder_hidden = encoder1(input_batch, input_data_len, None)\n","  \n","    max_target_length = MAX_LENGTH\n","    # Prepare decoder input and outputs\n","    decoder_input = Variable(torch.LongTensor([SOS_token] * BATCH_SIZE)).to(device)\n","    decoder_hidden = encoder_hidden[:decoder1.n_layers] # Use last (forward) hidden state from encoder\n","    all_decoder_outputs = Variable(torch.zeros(max_target_length, BATCH_SIZE, decoder1.output_size)).to(device)\n","    loss = 0\n","  \n","    # Run through decoder one time step at a time\n","    for t in range(max_target_length):\n","        decoder_output, decoder_hidden = decoder1(\n","        decoder_input, decoder_hidden\n","    )\n","        \n","        topv, topi = decoder_output.topk(1)\n","        decoder_input = topi.squeeze().detach()  # detach from history as input\n","        all_decoder_outputs[t] = decoder_output # Store this step's outputs\n","    \n","    # Test masked cross entropy loss\n","    loss = masked_cross_entropy(\n","        all_decoder_outputs.transpose(0, 1).contiguous(),\n","        output_batch.transpose(0, 1).contiguous(),\n","        output_data_len)\n","\n","    if l >= 1:\n","        break\n","\n","  \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9Le4FT-xYGPh","colab_type":"code","outputId":"4211551c-a484-42c4-b512-8f45be3b8e98","executionInfo":{"status":"ok","timestamp":1543241757110,"user_tz":300,"elapsed":1248,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["loss"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(10.8258, device='cuda:0', grad_fn=<DivBackward1>)"]},"metadata":{"tags":[]},"execution_count":76}]},{"metadata":{"id":"xeFgXvhnDsVr","colab_type":"code","colab":{}},"cell_type":"code","source":["#the train function is now taking a batch at a time\n","def train(input_batch, input_lengths, output_batch, output_lengths, encoder, decoder, encoder_optimizer, \n","          decoder_optimizer, criterion, max_length=MAX_LENGTH, if_attention = False):\n","    \n","    encoder_outputs, encoder_hidden = encoder(input_batch, input_lengths, None)\n","  \n","\n","    # Prepare decoder input and outputs\n","    decoder_input = Variable(torch.LongTensor([SOS_token] * BATCH_SIZE)).to(device)\n","    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n","    all_decoder_outputs = Variable(torch.zeros(max_length, BATCH_SIZE, decoder.output_size)).to(device)\n","    \n","    # Run through decoder one time step at a time\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","    \n","    # Teacher forcing: Feed the target as the next input\n","    if use_teacher_forcing:\n","        # Run through decoder one time step at a time\n","        for di in range(max_length):\n","            if if_attention == True:\n","                decoder_output, decoder_hidden, decoder_attn = decoder(\n","                    decoder_input, decoder_hidden, encoder_outputs)\n","            else:\n","\n","                decoder_output, decoder_hidden = decoder(\n","                    decoder_input, decoder_hidden)\n","                \n","            all_decoder_outputs[di] = decoder_output # Store this step's outputs\n","            decoder_input = output_batch[di] # Next input is current target\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(max_length):\n","            if if_attention == True:\n","                decoder_output, decoder_hidden, decoder_attn = decoder(\n","                  decoder_input, decoder_hidden, encoder_outputs)\n","            else:\n","\n","                decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","                \n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","            all_decoder_outputs[di] = decoder_output\n","\n","    \n","    # Loss calculation and backpropagation\n","    loss = masked_cross_entropy(\n","            all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n","            output_batch.transpose(0, 1).contiguous(), # -> batch x seq\n","            output_lengths)    \n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","      \n","\n","\n","    return loss.item()\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"0mk71hSJEdQP","colab_type":"code","colab":{}},"cell_type":"code","source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss()\n","    iters = 0\n","    \n","    while iters <= n_iters:\n","      \n","      \n","      \n","      for i, (input_var,input_data_len,output_var,output_data_len) in enumerate(train_loader):\n","        iters += 1\n","        input_batch = input_var.transpose(0,1).to(device)\n","        output_batch = output_var.transpose(0,1).to(device)\n","        \n","        loss = train(input_batch,input_data_len,output_batch,output_data_len, encoder,\n","                       decoder, encoder_optimizer, decoder_optimizer, criterion)\n","       \n","        \n","        # Keep track of loss\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","\n","        if iters % print_every == 0:\n","          print_loss_avg = print_loss_total / print_every\n","          print_loss_total = 0\n","          print('%s (%d %d%%) %.4f' % (timeSince(start, iters / n_iters),\n","                                           iters, iters / n_iters * 100, print_loss_avg))\n","\n","        if iters % plot_every == 0:\n","          plot_loss_avg = plot_loss_total / plot_every\n","          plot_losses.append(plot_loss_avg)\n","          plot_loss_total = 0\n","\n","    showPlot(plot_losses)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ovx0SoEEPO8d","colab_type":"text"},"cell_type":"markdown","source":["Training model on sample data, without attention mechanism. Using pre-trained word embedding for both languages, and not updating the weights"]},{"metadata":{"id":"OGPQL7G2bvxB","colab_type":"code","colab":{}},"cell_type":"code","source":["# Configure models\n","hidden_size = 500\n","layers = 2\n","teacher_forcing_ratio = 0.5\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","n_iters = 10000\n","\n","# Initialize models\n","encoder = EncoderRNN(weights_matrix_zh, train_input_lang.n_words, hidden_size, n_layers = layers).to(device)\n","decoder = DecoderRNN(weights_matrix_eng, hidden_size, train_output_lang.n_words, n_layers = layers).to(device)\n","\n","# Initialize optimizers and criterion\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","criterion = nn.CrossEntropyLoss()\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"26p7Y6QjQFyH","colab_type":"code","outputId":"20c8e387-7c41-4c32-a2bc-7c65ba7d9e0a","executionInfo":{"status":"ok","timestamp":1543287669979,"user_tz":300,"elapsed":1494098,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}},"colab":{"base_uri":"https://localhost:8080/","height":2765}},"cell_type":"code","source":["trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, learning_rate=learning_rate)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1m 11s (- 117m 56s) (100 1%) 10.8178\n","2m 22s (- 116m 30s) (200 2%) 10.7931\n","3m 33s (- 114m 56s) (300 3%) 10.7411\n","4m 43s (- 113m 27s) (400 4%) 10.6561\n","5m 54s (- 112m 11s) (500 5%) 10.5224\n","7m 4s (- 110m 51s) (600 6%) 10.2594\n","8m 14s (- 109m 32s) (700 7%) 9.5737\n","9m 25s (- 108m 19s) (800 8%) 9.3512\n","10m 35s (- 107m 6s) (900 9%) 9.1628\n","11m 45s (- 105m 48s) (1000 10%) 8.9847\n","12m 54s (- 104m 29s) (1100 11%) 8.6063\n","14m 4s (- 103m 15s) (1200 12%) 8.1901\n","15m 14s (- 102m 1s) (1300 13%) 8.1998\n","16m 25s (- 100m 51s) (1400 14%) 8.0658\n","17m 35s (- 99m 40s) (1500 15%) 8.1448\n","18m 45s (- 98m 30s) (1600 16%) 8.0000\n","19m 55s (- 97m 18s) (1700 17%) 7.7528\n","21m 5s (- 96m 6s) (1800 18%) 7.7712\n","22m 15s (- 94m 54s) (1900 19%) 7.7044\n","23m 25s (- 93m 43s) (2000 20%) 7.5315\n","24m 36s (- 92m 32s) (2100 21%) 7.5286\n","25m 45s (- 91m 21s) (2200 22%) 7.4363\n","26m 56s (- 90m 10s) (2300 23%) 7.3637\n","28m 6s (- 89m 0s) (2400 24%) 7.3265\n","29m 16s (- 87m 49s) (2500 25%) 7.2505\n","30m 26s (- 86m 38s) (2600 26%) 7.1977\n","31m 36s (- 85m 27s) (2700 27%) 7.1186\n","32m 46s (- 84m 15s) (2800 28%) 7.0837\n","33m 56s (- 83m 5s) (2900 28%) 6.9774\n","35m 5s (- 81m 53s) (3000 30%) 6.8977\n","36m 16s (- 80m 43s) (3100 31%) 6.8924\n","37m 26s (- 79m 33s) (3200 32%) 6.8301\n","38m 36s (- 78m 23s) (3300 33%) 6.7288\n","39m 46s (- 77m 12s) (3400 34%) 6.6643\n","40m 56s (- 76m 1s) (3500 35%) 6.6063\n","42m 6s (- 74m 51s) (3600 36%) 6.6339\n","43m 16s (- 73m 41s) (3700 37%) 6.5782\n","44m 27s (- 72m 31s) (3800 38%) 6.5772\n","45m 36s (- 71m 20s) (3900 39%) 6.5051\n","46m 47s (- 70m 10s) (4000 40%) 6.4634\n","47m 57s (- 69m 0s) (4100 41%) 6.4331\n","49m 6s (- 67m 49s) (4200 42%) 6.4026\n","50m 16s (- 66m 39s) (4300 43%) 6.3954\n","51m 26s (- 65m 28s) (4400 44%) 6.3502\n","52m 36s (- 64m 18s) (4500 45%) 6.3462\n","53m 46s (- 63m 8s) (4600 46%) 6.3285\n","54m 56s (- 61m 57s) (4700 47%) 6.2628\n","56m 6s (- 60m 47s) (4800 48%) 6.2683\n","57m 16s (- 59m 36s) (4900 49%) 6.2711\n","58m 26s (- 58m 26s) (5000 50%) 6.2631\n","59m 36s (- 57m 16s) (5100 51%) 6.2900\n","60m 46s (- 56m 5s) (5200 52%) 6.2209\n","61m 55s (- 54m 55s) (5300 53%) 6.2595\n","63m 5s (- 53m 44s) (5400 54%) 6.2546\n","64m 15s (- 52m 34s) (5500 55%) 6.2188\n","65m 25s (- 51m 23s) (5600 56%) 6.2538\n","66m 34s (- 50m 13s) (5700 56%) 6.2175\n","67m 44s (- 49m 3s) (5800 57%) 6.2380\n","68m 54s (- 47m 53s) (5900 59%) 6.2324\n","70m 4s (- 46m 43s) (6000 60%) 6.2450\n","71m 14s (- 45m 33s) (6100 61%) 6.2483\n","72m 25s (- 44m 23s) (6200 62%) 6.1890\n","73m 35s (- 43m 13s) (6300 63%) 6.1894\n","74m 45s (- 42m 3s) (6400 64%) 6.1158\n","75m 55s (- 40m 53s) (6500 65%) 6.1374\n","77m 6s (- 39m 43s) (6600 66%) 6.1498\n","78m 16s (- 38m 33s) (6700 67%) 6.1026\n","79m 25s (- 37m 22s) (6800 68%) 6.0912\n","80m 36s (- 36m 12s) (6900 69%) 6.0974\n","81m 46s (- 35m 2s) (7000 70%) 6.0743\n","82m 56s (- 33m 52s) (7100 71%) 6.0917\n","84m 5s (- 32m 42s) (7200 72%) 6.0600\n","85m 15s (- 31m 32s) (7300 73%) 6.0289\n","86m 25s (- 30m 21s) (7400 74%) 6.1064\n","87m 35s (- 29m 11s) (7500 75%) 6.0489\n","88m 45s (- 28m 1s) (7600 76%) 6.0421\n","89m 55s (- 26m 51s) (7700 77%) 6.0543\n","91m 5s (- 25m 41s) (7800 78%) 6.0191\n","92m 15s (- 24m 31s) (7900 79%) 6.0426\n","93m 25s (- 23m 21s) (8000 80%) 6.0328\n","94m 35s (- 22m 11s) (8100 81%) 5.9869\n","95m 45s (- 21m 1s) (8200 82%) 6.0368\n","96m 55s (- 19m 51s) (8300 83%) 6.1112\n","98m 5s (- 18m 40s) (8400 84%) 6.0580\n","99m 15s (- 17m 30s) (8500 85%) 6.0423\n","100m 25s (- 16m 20s) (8600 86%) 5.9553\n","101m 34s (- 15m 10s) (8700 87%) 5.9491\n","102m 44s (- 14m 0s) (8800 88%) 5.9738\n","103m 54s (- 12m 50s) (8900 89%) 5.9943\n","105m 4s (- 11m 40s) (9000 90%) 5.9746\n","106m 14s (- 10m 30s) (9100 91%) 5.9442\n","107m 23s (- 9m 20s) (9200 92%) 5.9390\n","108m 33s (- 8m 10s) (9300 93%) 5.9877\n","109m 43s (- 7m 0s) (9400 94%) 5.8900\n","110m 53s (- 5m 50s) (9500 95%) 5.9604\n","112m 3s (- 4m 40s) (9600 96%) 5.9519\n","113m 12s (- 3m 30s) (9700 97%) 5.9573\n","114m 22s (- 2m 20s) (9800 98%) 5.8912\n","115m 32s (- 1m 10s) (9900 99%) 5.9181\n","116m 42s (- 0m 0s) (10000 100%) 5.9118\n","117m 52s (- -2m 49s) (10100 101%) 5.9077\n","119m 2s (- -3m 39s) (10200 102%) 5.9103\n","120m 12s (- -4m 29s) (10300 103%) 5.8501\n","121m 22s (- -5m 19s) (10400 104%) 5.8110\n","122m 32s (- -6m 9s) (10500 105%) 5.8773\n","123m 42s (- -8m 59s) (10600 106%) 5.8792\n","124m 52s (- -9m 49s) (10700 107%) 5.8437\n","126m 2s (- -10m 39s) (10800 108%) 5.7995\n","127m 12s (- -11m 29s) (10900 109%) 5.7884\n","128m 22s (- -12m 19s) (11000 110%) 5.7948\n","129m 32s (- -13m 9s) (11100 111%) 5.7684\n","130m 43s (- -15m 59s) (11200 112%) 5.7963\n","131m 53s (- -16m 49s) (11300 112%) 5.7918\n","133m 3s (- -17m 39s) (11400 113%) 5.8104\n","134m 13s (- -18m 29s) (11500 114%) 5.7741\n","135m 24s (- -19m 19s) (11600 115%) 5.7854\n","136m 34s (- -20m 9s) (11700 117%) 5.7835\n","137m 44s (- -22m 59s) (11800 118%) 5.7497\n","138m 54s (- -23m 49s) (11900 119%) 5.7286\n","140m 5s (- -24m 39s) (12000 120%) 5.7333\n","141m 15s (- -25m 29s) (12100 121%) 5.7124\n","142m 25s (- -26m 19s) (12200 122%) 5.7476\n","143m 35s (- -27m 8s) (12300 123%) 5.7207\n","144m 45s (- -29m 58s) (12400 124%) 5.7152\n","145m 55s (- -30m 48s) (12500 125%) 5.6836\n","147m 5s (- -31m 38s) (12600 126%) 5.6900\n","148m 15s (- -32m 28s) (12700 127%) 5.7776\n","149m 25s (- -33m 18s) (12800 128%) 5.7167\n","150m 35s (- -34m 8s) (12900 129%) 5.7251\n","151m 45s (- -36m 58s) (13000 130%) 5.7240\n","152m 55s (- -37m 48s) (13100 131%) 5.7260\n","154m 5s (- -38m 38s) (13200 132%) 5.7315\n","155m 15s (- -39m 28s) (13300 133%) 5.6795\n","156m 25s (- -40m 18s) (13400 134%) 5.6951\n","157m 34s (- -41m 8s) (13500 135%) 5.6449\n","158m 44s (- -43m 58s) (13600 136%) 5.7107\n","159m 54s (- -44m 48s) (13700 137%) 5.6710\n","161m 4s (- -45m 38s) (13800 138%) 5.6954\n","162m 14s (- -46m 28s) (13900 139%) 5.6618\n","163m 24s (- -47m 18s) (14000 140%) 5.6472\n","164m 34s (- -48m 8s) (14100 141%) 5.6468\n","165m 44s (- -50m 58s) (14200 142%) 5.5968\n","166m 54s (- -51m 48s) (14300 143%) 5.6225\n","168m 4s (- -52m 38s) (14400 144%) 5.6435\n","169m 14s (- -53m 28s) (14500 145%) 5.6440\n","170m 24s (- -54m 18s) (14600 146%) 5.6407\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<matplotlib.figure.Figure at 0x7ff938286940>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3Rhj4pAN7sYYE4f+P9fOseASc92uAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7ff93fe10a58>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"pAagmAsMi_av","colab_type":"code","colab":{}},"cell_type":"code","source":["torch.save(encoder.state_dict(), folder_path + 'encoder2.pt')\n","torch.save(decoder.state_dict(), folder_path + 'decoder2.pt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fkuvajOIHuOQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Configure models\n","hidden_size = 500\n","layers = 2\n","teacher_forcing_ratio = 0.5\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","n_iters = 10000\n","\n","encoder2 = EncoderRNN(weights_matrix_zh, train_input_lang.n_words, hidden_size, n_layers = layers).to(device)\n","decoder2 = DecoderRNN(weights_matrix_eng, hidden_size, train_output_lang.n_words, n_layers = layers).to(device)\n","encoder2.load_state_dict(torch.load(folder_path + \"encoder2.pt\"))\n","decoder2.load_state_dict(torch.load(folder_path +\"decoder2.pt\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4V26aPkkb0fw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1190},"outputId":"85264637-45e2-4c26-e56a-6b7adf507f0c"},"cell_type":"code","source":["trainIters(encoder2, decoder2, n_iters, print_every=100, plot_every=100, learning_rate=learning_rate)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1m 10s (- 115m 51s) (100 1%) 5.6332\n","2m 20s (- 114m 31s) (200 2%) 5.5690\n","3m 30s (- 113m 11s) (300 3%) 5.5241\n","4m 39s (- 111m 54s) (400 4%) 5.5147\n","5m 49s (- 110m 44s) (500 5%) 5.5323\n","6m 59s (- 109m 29s) (600 6%) 5.4979\n","8m 9s (- 108m 23s) (700 7%) 5.5398\n","9m 19s (- 107m 14s) (800 8%) 5.5508\n","10m 29s (- 106m 6s) (900 9%) 5.5754\n","11m 39s (- 104m 59s) (1000 10%) 5.5534\n","12m 50s (- 103m 51s) (1100 11%) 5.5696\n","14m 0s (- 102m 42s) (1200 12%) 5.5182\n","15m 10s (- 101m 33s) (1300 13%) 5.5546\n","16m 20s (- 100m 25s) (1400 14%) 5.5223\n","17m 31s (- 99m 16s) (1500 15%) 5.5071\n","18m 41s (- 98m 7s) (1600 16%) 5.5397\n","19m 51s (- 96m 58s) (1700 17%) 5.5641\n","21m 1s (- 95m 47s) (1800 18%) 5.5113\n","22m 12s (- 94m 38s) (1900 19%) 5.5538\n","23m 21s (- 93m 27s) (2000 20%) 5.4470\n","24m 32s (- 92m 18s) (2100 21%) 5.5394\n","25m 42s (- 91m 7s) (2200 22%) 5.5107\n","26m 52s (- 89m 57s) (2300 23%) 5.5034\n","28m 2s (- 88m 48s) (2400 24%) 5.5233\n","29m 12s (- 87m 38s) (2500 25%) 5.4621\n","30m 22s (- 86m 28s) (2600 26%) 5.4587\n","31m 33s (- 85m 18s) (2700 27%) 5.5668\n","32m 43s (- 84m 9s) (2800 28%) 5.5156\n","33m 54s (- 83m 0s) (2900 28%) 5.4835\n","35m 4s (- 81m 50s) (3000 30%) 5.4313\n","36m 14s (- 80m 40s) (3100 31%) 5.5593\n","37m 25s (- 79m 31s) (3200 32%) 5.5394\n","38m 35s (- 78m 21s) (3300 33%) 5.4870\n","39m 46s (- 77m 12s) (3400 34%) 5.5413\n","40m 56s (- 76m 1s) (3500 35%) 5.5330\n","42m 6s (- 74m 51s) (3600 36%) 5.5016\n","43m 16s (- 73m 41s) (3700 37%) 5.5196\n","44m 27s (- 72m 31s) (3800 38%) 5.5123\n","45m 37s (- 71m 21s) (3900 39%) 5.4966\n","46m 47s (- 70m 11s) (4000 40%) 5.5942\n","47m 57s (- 69m 1s) (4100 41%) 5.5370\n","49m 8s (- 67m 51s) (4200 42%) 5.5788\n","50m 18s (- 66m 40s) (4300 43%) 5.5525\n","51m 28s (- 65m 30s) (4400 44%) 5.5345\n","52m 38s (- 64m 20s) (4500 45%) 5.5524\n","53m 49s (- 63m 10s) (4600 46%) 5.4842\n","54m 59s (- 62m 0s) (4700 47%) 5.5238\n","56m 9s (- 60m 49s) (4800 48%) 5.5506\n","57m 19s (- 59m 39s) (4900 49%) 5.4684\n","58m 29s (- 58m 29s) (5000 50%) 5.5486\n","59m 39s (- 57m 19s) (5100 51%) 5.5290\n","60m 50s (- 56m 9s) (5200 52%) 5.5590\n","62m 0s (- 54m 59s) (5300 53%) 5.5185\n","63m 10s (- 53m 49s) (5400 54%) 5.5425\n","64m 20s (- 52m 38s) (5500 55%) 5.5184\n","65m 30s (- 51m 28s) (5600 56%) 5.5512\n","66m 40s (- 50m 18s) (5700 56%) 5.4321\n","67m 50s (- 49m 7s) (5800 57%) 5.4830\n","69m 0s (- 47m 57s) (5900 59%) 5.4571\n","70m 11s (- 46m 47s) (6000 60%) 5.4544\n","71m 21s (- 45m 37s) (6100 61%) 5.4581\n","72m 31s (- 44m 26s) (6200 62%) 5.4992\n","73m 41s (- 43m 16s) (6300 63%) 5.4718\n","74m 51s (- 42m 6s) (6400 64%) 5.4762\n","76m 2s (- 40m 56s) (6500 65%) 5.5254\n","77m 12s (- 39m 46s) (6600 66%) 5.5197\n","78m 22s (- 38m 36s) (6700 67%) 5.5106\n","79m 33s (- 37m 26s) (6800 68%) 5.4749\n","80m 43s (- 36m 16s) (6900 69%) 5.4465\n"],"name":"stdout"}]},{"metadata":{"id":"UfMBWygEb78h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164},"outputId":"5c479a62-3e55-4f4d-80ca-fe9863868de4","executionInfo":{"status":"error","timestamp":1543357825849,"user_tz":300,"elapsed":634,"user":{"displayName":"Stella Sun","photoUrl":"https://lh4.googleusercontent.com/-8D6tLuChkp4/AAAAAAAAAAI/AAAAAAAAACE/6v3LX_1YY_c/s64/photo.jpg","userId":"16303575836792726022"}}},"cell_type":"code","source":["torch.save(encoder2.state_dict(), folder_path + 'encoder3.pt')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-96e2611017fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'encoder3.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"metadata":{"id":"78-2CC2BS4Ar","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}